# jemdoc: title{Chunhua Shen}, addcss{css/full_publication.css}
= Publications (Full List)
== Categorised [fullpaper2.html by venue {{<i class='fa fa-location-arrow' aria-hidden='true'></i>}}],  [fullpaper.html by year {{<i class='fa fa-clock-o' aria-hidden='true'></i>}}]. *442*  papers.  

[https://scholar.google.com/citations?hl=en&user=Ljk2BvIAAAAJ&view_op=list_works&pagesize=100 Google scholar (75075 citations)  {{<i class='ai ai-google-scholar'   aria-hidden='true'></i>}}],
[https://dblp.org/pid/56/1673.html    DBLP {{<i class='ai ai-dblp ai-1x'></i>}}],
[https://arxiv.org/a/shen_c_1.html    arXiv {{<i class='ai ai-arxiv ai-1x'></i>}}].
{{<div id="citation_plot_holder"></div>}}


= 2024
== Journal
. *Scaling up multi-domain semantic segmentation with sentence embeddings*   
\n$\cdot$ /W. Yin, Y. Liu, C. Shen, B. Sun, A. van den Hengel/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2024/.
\n$\cdot$ [data/bibtex/Yin2024SIW.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Scaling+Up+Multi-domain+Semantic+Segmentation+with+Sentence+Embeddings+Yin,+Wei+and+Liu,+Yifan+and+Shen,+Chunhua+and+Sun,+Baichuan+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Scaling+Up+Multi-domain+Semantic+Segmentation+with+Sentence+Embeddings semantic scholar]
. *Towards robust monocular depth estimation: a new baseline and benchmark*   
\n$\cdot$ /K. Xian, Z. Cao, C. Shen, G. Lin/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2024/.
\n$\cdot$ [data/bibtex/Depth2024Xian.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Towards+robust+monocular+depth+estimation:+a+new+baseline+and+benchmark+Xian,+Ke+and+Cao,+Zhiguo+and+Shen,+Chunhua+and+Lin,+Guosheng google scholar][https://www.semanticscholar.org/search?q=Towards+robust+monocular+depth+estimation:+a+new+baseline+and+benchmark semantic scholar]
. *End-to-end video text spotting with Transformer*   
\n$\cdot$ /W. Wu, C. Shen, Y. Cai, D. Zhang, Y. Fu, P. Luo, H. Zhou/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2024/.
\n$\cdot$ [data/bibtex/Wu2022transdetr.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=End-to-End+Video+Text+Spotting+with+{T}ransformer+Wu,+Weijia+and+Shen,+Chunhua+and+Cai,+Yuanqiang+and+Zhang,+Debing+and+Fu,+Ying+and+Luo,+Ping+and+Zhou,+Hong google scholar][https://www.semanticscholar.org/search?q=End-to-End+Video+Text+Spotting+with+{T}ransformer semantic scholar]
. *Masked channel modeling for bootstrapping visual pre-training*   
\n$\cdot$ /Y. Liu, X. Wang, M. Zhu, Y. Cao, T. Huang, C. Shen/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2024/.
\n$\cdot$ [data/bibtex/Liuyang2024Masked.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Masked+Channel+Modeling+for+Bootstrapping+Visual+Pre-training+Liu,+Yang+and+Wang,+Xinlong+and+Zhu,+Muzhi+and+Cao,+Yue+and+Huang,+Tiejun+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Masked+Channel+Modeling+for+Bootstrapping+Visual+Pre-training semantic scholar]
. *Self-supervised 3d scene flow estimation and motion prediction using local rigidity prior*   
\n$\cdot$ /R. Li, C. Zhang, Z. Wang, C. Shen, G. Lin/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2024/.
\n$\cdot$ [http://arxiv.org/abs/2310.11284    arXiv][data/bibtex/Ruibo2024TPAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Self-Supervised+3D+Scene+Flow+Estimation+and+Motion+Prediction+using+Local+Rigidity+Prior+Li,+Ruibo+and+Zhang,+Chi+and+Wang,+Zhe+and+Shen,+Chunhua+and+Lin,+Guosheng google scholar][https://www.semanticscholar.org/search?q=Self-Supervised+3D+Scene+Flow+Estimation+and+Motion+Prediction+using+Local+Rigidity+Prior semantic scholar]
== Conference
. *PointAttN: you only need attention for point cloud completion*   
\n$\cdot$ /J. Wang, Y. Cui, D. Guo, J. Li, Q. Liu, C. Shen/.
\n$\cdot$ /Proc. AAAI Conference on Artificial Intelligence (AAAI'24), 2024/.
\n$\cdot$ [data/bibtex/Wang2024AAAI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={PointAttN}:+You+Only+Need+Attention+for+Point+Cloud+Completion+Wang,+Jun+and+Cui,+Ying+and+Guo,+Dongyan+and+Li,+Junxia+and+Liu,+Qingshan+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={PointAttN}:+You+Only+Need+Attention+for+Point+Cloud+Completion semantic scholar]
. *Retrieval-augmented primitive representations for compositional zero-shot learning*   
\n$\cdot$ /C. Jing, Y. Li, H. Chen, C. Shen/.
\n$\cdot$ /Proc. AAAI Conference on Artificial Intelligence (AAAI'24), 2024/.
\n$\cdot$ [data/bibtex/Jing2024AAAI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Retrieval-augmented+Primitive+Representations+for+Compositional+Zero-shot+Learning+Jing,+Chenchen+and+Li,+Yukun+and+Chen,+Hao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Retrieval-augmented+Primitive+Representations+for+Compositional+Zero-shot+Learning semantic scholar]
. *LoRAPrune: structured pruning meets low-rank parameter-efficient fine-tuning*   
\n$\cdot$ /M. Zhang, H. Chen, C. Shen, Z. Yang, L. Ou, X. Yu, B. Zhuang/.
\n$\cdot$ /Proc. Findings of the Association for Computational Linguistics (EACL'24), 2024/.
\n$\cdot$ [data/bibtex/LoRAPrune2024ACL.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={LoRAPrune}:+Structured+Pruning+Meets+Low-Rank+Parameter-Efficient+Fine-Tuning+Zhang,+Mingyang+and+Chen,+Hao+and+Shen,+Chunhua+and+Yang,+Zhen+and+Ou,+Linlin+and+Yu,+Xinyi+and+Zhuang,+Bohan google scholar][https://www.semanticscholar.org/search?q={LoRAPrune}:+Structured+Pruning+Meets+Low-Rank+Parameter-Efficient+Fine-Tuning semantic scholar]
. *StableLLaVA: enhanced visual instruction tuning with synthesized image-dialogue data*   
\n$\cdot$ /Y. Li, C. Zhang, G. Yu, Z. Wang, B. Fu, G. Lin, C. Shen, L. Chen, Y. Wei/.
\n$\cdot$ /Proc. Findings of the Association for Computational Linguistics (EACL'24), 2024/.
\n$\cdot$ [data/bibtex/Chi2024ACL.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={StableLLaVA}:+Enhanced+Visual+Instruction+Tuning+with+Synthesized+Image-Dialogue+Data+Li,+Yanda+and+Zhang,+Chi+and+Yu,+Gang+and+Wang,+Zhibin+and+Fu,+Bin+and+Lin,+Guosheng+and+Shen,+Chunhua+and+Chen,+Ling+and+Wei,+Yunchao google scholar][https://www.semanticscholar.org/search?q={StableLLaVA}:+Enhanced+Visual+Instruction+Tuning+with+Synthesized+Image-Dialogue+Data semantic scholar]
. *Traffic scene parsing through the tsp6k dataset*   
\n$\cdot$ /P. Jiang, Y. Yang, Y. Cao, Q. Hou, M. Cheng, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'24), 2024/.
\n$\cdot$ [data/bibtex/JiangCVPR2024.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Traffic+Scene+Parsing+through+the+TSP6K+Dataset+Jiang,+Peng-Tao+and+Yang,+Yuqi+and+Cao,+Yang+and+Hou,+Qibin+and+Cheng,+Ming-Ming+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Traffic+Scene+Parsing+through+the+TSP6K+Dataset semantic scholar]
. *DiverGen: improving instance segmentation by learning wider data distribution with more diverse generative data*   
\n$\cdot$ /C. Fan, M. Zhu, H. Chen, Y. Liu, W. Wu, H. Zhang, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'24), 2024/.
\n$\cdot$ [data/bibtex/FanCVPR2024.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={DiverGen}:+Improving+Instance+Segmentation+by+Learning+Wider+Data+Distribution+with+More+Diverse+Generative+Data+Fan,+Chengxiang+and+Zhu,+Muzhi+and+Chen,+Hao+and+Liu,+Yang+and+Wu,+Weijia+and+Zhang,+Huaqi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={DiverGen}:+Improving+Instance+Segmentation+by+Learning+Wider+Data+Distribution+with+More+Diverse+Generative+Data semantic scholar]
. *FreeCustom: tuning-free customized image generation for multi-concept composition*   
\n$\cdot$ /G. Ding, C. Zhao, W. Wang, Z. Yang, Z. Liu, H. Chen, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'24), 2024/.
\n$\cdot$ [data/bibtex/DingCVPR2024.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={FreeCustom}:+Tuning-Free+Customized+Image+Generation+for+Multi-Concept+Composition+Ding,+Ganggui+and+Zhao,+Canyu+and+Wang,+Wen+and+Yang,+Zhen+and+Liu,+Zide+and+Chen,+Hao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={FreeCustom}:+Tuning-Free+Customized+Image+Generation+for+Multi-Concept+Composition semantic scholar]
. *VisionLLaMA: a unified llama backbone for vision tasks*   
\n$\cdot$ /X. Chu, J. Su, B. Zhang, C. Shen/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'24), 2024/.
\n$\cdot$ [http://arxiv.org/abs/2403.00522    arXiv][data/bibtex/VisionLLaMA2024.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={VisionLLaMA}:+A+Unified+LLaMA+Backbone+for+Vision+Tasks+Chu,+Xiangxiang+and+Su,+Jianlin+and+Zhang,+Bo+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={VisionLLaMA}:+A+Unified+LLaMA+Backbone+for+Vision+Tasks semantic scholar][https://github.com/Meituan-AutoML/VisionLLaMA   project webpage]
. *FreeCompose: generic zero-shot image composition with diffusion prior*   
\n$\cdot$ /Z. Chen, W. Wang, Z. Yang, Z. Yuan, H. Chen, C. Shen/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'24), 2024/.
\n$\cdot$ [http://arxiv.org/abs/2407.04947    arXiv][data/bibtex/FreeComp2024Chen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={FreeCompose}:+Generic+Zero-Shot+Image+Composition+with+Diffusion+Prior+Chen,+Zhekai+and+Wang,+Wen+and+Yang,+Zhen+and+Yuan,+Zeqing+and+Chen,+Hao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={FreeCompose}:+Generic+Zero-Shot+Image+Composition+with+Diffusion+Prior semantic scholar]
. *Object-aware inversion and reassembly for image editing*   
\n$\cdot$ /Z. Yang, D. Gui, W. Wang, H. Chen, B. Zhuang, C. Shen/.
\n$\cdot$ /Proc. International Conference on Learning Representations (ICLR'24), 2024/.
\n$\cdot$ [http://arxiv.org/abs/2310.12149    arXiv][https://openreview.net/forum?id=dpcVXiMlcv  link][data/bibtex/Yang2024ICLR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Object-aware+Inversion+and+Reassembly+for+Image+Editing+Yang,+Zhen+and+Gui,+Dinggang+and+Wang,+Wen+and+Chen,+Hao+and+Zhuang,+Bohan+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Object-aware+Inversion+and+Reassembly+for+Image+Editing semantic scholar][https://aim-uofa.github.io/OIR-Diffusion/   project webpage]
. *De novo protein design using geometric vector field networks*   
\n$\cdot$ /W. Mao, M. Zhu, Z. Sun, S. Shen, L. Wu, H. Chen, C. Shen/.
\n$\cdot$ /Proc. International Conference on Learning Representations (ICLR'24), 2024/.
\n$\cdot$ [http://arxiv.org/abs/2310.11802    arXiv][https://openreview.net/forum?id=9UIGyJJpay  link][data/bibtex/Mao2024ICLR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=De+novo+protein+design+using+geometric+vector+field+networks+Mao,+Weian+and+Zhu,+Muzhi+and+Sun,+Zheng+and+Shen,+Shuaike+and+Wu,+Lin+Yuanbo+and+Chen,+Hao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=De+novo+protein+design+using+geometric+vector+field+networks semantic scholar]
        .. Spotlight presentation.
. *Matcher: segment anything with one shot using all-purpose feature matching*   
\n$\cdot$ /Y. Liu, M. Zhu, H. Li, H. Chen, X. Wang, C. Shen/.
\n$\cdot$ /Proc. International Conference on Learning Representations (ICLR'24), 2024/.
\n$\cdot$ [http://arxiv.org/abs/2305.13310    arXiv][https://openreview.net/forum?id=yzRXdhk2he  link][data/bibtex/Liu2024ICLR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Matcher:+Segment+Anything+with+One+Shot+Using+All-Purpose+Feature+Matching+Liu,+Yang+and+Zhu,+Muzhi+and+Li,+Hengtao+and+Chen,+Hao+and+Wang,+Xinlong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Matcher:+Segment+Anything+with+One+Shot+Using+All-Purpose+Feature+Matching semantic scholar]
. *Generative active learning for long-tailed instance segmentation*   
\n$\cdot$ /M. Zhu, C. Fan, H. Chen, Y. Liu, W. Mao, X. Xu, C. Shen/.
\n$\cdot$ /Proc. International Conference on Machine Learning (ICML'24), 2024/.
\n$\cdot$ [data/bibtex/Zhu2024ICML.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Generative+Active+Learning+for+Long-tailed+Instance+Segmentation+Zhu,+Muzhi+and+Fan,+Chengxiang+and+Chen,+Hao+and+Liu,+Yang+and+Mao,+Weian+and+Xu,+Xiaogang+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Generative+Active+Learning+for+Long-tailed+Instance+Segmentation semantic scholar]
. *Floating anchor diffusion model for multi-motif scaffolding*   
\n$\cdot$ /K. Liu, S. Shen, W. Mao, X. Jiao, Z. Sun, H. Chen, C. Shen/.
\n$\cdot$ /Proc. International Conference on Machine Learning (ICML'24), 2024/.
\n$\cdot$ [data/bibtex/Liu2024ICML.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Floating+Anchor+Diffusion+Model+for+Multi-motif+Scaffolding+Liu,+Ke+and+Shen,+Shuaike+and+Mao,+Weian+and+Jiao,+Xiaoran+and+Sun,+Zheng+and+Chen,+Hao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Floating+Anchor+Diffusion+Model+for+Multi-motif+Scaffolding semantic scholar]
. *On the trajectory regularity of ODE-based diffusion sampling*   
\n$\cdot$ /D. Chen, Z. Zhou, C. Wang, C. Shen, S. Lyu/.
\n$\cdot$ /Proc. International Conference on Machine Learning (ICML'24), 2024/.
\n$\cdot$ [data/bibtex/Chen2024ICML.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=On+the+Trajectory+Regularity+of+{ODE}-based+Diffusion+Sampling+Chen,+Defang+and+Zhou,+Zhenyu+and+Wang,+Can+and+Shen,+Chunhua+and+Lyu,+Siwei google scholar][https://www.semanticscholar.org/search?q=On+the+Trajectory+Regularity+of+{ODE}-based+Diffusion+Sampling semantic scholar]

= 2023
== Journal
. {{<img class="imgP  right"   src="data/thumbnail/Zhang2023SegVITv2xxxarXiv.jpg">}}*SegViT v2: exploring efficient and continual semantic segmentation with plain vision transformers*   
\n$\cdot$ /B. Zhang, L. Liu, M. Phan, Z. Tian, C. Shen, Y. Liu/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2306.06289    arXiv][data/bibtex/Zhang2023SegVITv2.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SegViT}+v2:+Exploring+Efficient+and+Continual+Semantic+Segmentation+with+Plain+Vision+Transformers+Zhang,+Bowen+and+Liu,+Liyang+and+Phan,+Minh+Hieu+and+Tian,+Zhi+and+Shen,+Chunhua+and+Liu,+Yifan google scholar][https://www.semanticscholar.org/search?q={SegViT}+v2:+Exploring+Efficient+and+Continual+Semantic+Segmentation+with+Plain+Vision+Transformers semantic scholar][https://github.com/zbwxp/SegVit   project webpage]
. *SPL-Net: spatial-semantic patch learning network for facial attribute recognition with limited labeled data*   
\n$\cdot$ /Y. Yan, Y. Shu, S. Chen, J. Xue, C. Shen, H. Wang/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2023/.
\n$\cdot$ [data/bibtex/YAN2023IJCVSPL.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SPL-Net}:+Spatial-Semantic+Patch+Learning+Network+for+Facial+Attribute+Recognition+with+Limited+Labeled+Data+Yan,+Yan+and+Shu,+Ying+and+Chen,+Si+and+Xue,+Jing-Hao+and+Shen,+Chunhua+and+Wang,+Hanzi google scholar][https://www.semanticscholar.org/search?q={SPL-Net}:+Spatial-Semantic+Patch+Learning+Network+for+Facial+Attribute+Recognition+with+Limited+Labeled+Data semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Lu2023IJCVCountingxxxarXiv.jpg">}}*From open set to closed set: supervised spatial divide-and-conquer for object counting*   
\n$\cdot$ /H. Xiong, H. Lu, C. Liu, L. Liu, C. Shen, Z. Cao/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2001.01886    arXiv][data/bibtex/Lu2023IJCVCounting.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=From+Open+Set+to+Closed+Set:+Supervised+Spatial+Divide-and-Conquer+for+Object+Counting+Xiong,+Haipeng+and+Lu,+Hao+and+Liu,+Chengxin+and+Liu,+Liang+and+Shen,+Chunhua+and+Cao,+Zhiguo google scholar][https://www.semanticscholar.org/search?q=From+Open+Set+to+Closed+Set:+Supervised+Spatial+Divide-and-Conquer+for+Object+Counting semantic scholar]
. *A dynamic feature interaction framework for multi-task visual perception*   
\n$\cdot$ /Y. Xi, H. Chen, N. Wang, P. Wang, Y. Zhang, C. Shen, Y. Liu/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2023/.
\n$\cdot$ [data/bibtex/XiY2023IJCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Dynamic+Feature+Interaction+Framework+for+Multi-task+Visual+Perception+Xi,+Yuling+and+Chen,+Hao+and+Wang,+Ning+and+Wang,+Peng+and+Zhang,+Yanning+and+Shen,+Chunhua+and+Liu,+Yifan google scholar][https://www.semanticscholar.org/search?q=A+Dynamic+Feature+Interaction+Framework+for+Multi-task+Visual+Perception semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Lin2023IJCVSuperxxxarXiv.jpg">}}*Super vision transformer*   
\n$\cdot$ /M. Lin, M. Chen, Y. Zhang, C. Shen, R. Ji, L. Cao/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2205.11397    arXiv][data/bibtex/Lin2023IJCVSuper.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Super+Vision+Transformer+Lin,+Mingbao+and+Chen,+Mengzhao+and+Zhang,+Yuxin+and+Shen,+Chunhua+and+Ji,+Rongrong+and+Cao,+Liujuan google scholar][https://www.semanticscholar.org/search?q=Super+Vision+Transformer semantic scholar][https://github.com/lmbxmu/SuperViT   project webpage]
. *SAI: an efficient and user-friendly tool for measurement of stomatal pores and density using deep computer vision*   
\n$\cdot$ /N. Sai, J. Bockman, H. Chen, N. Watson-Haigh, B. Xu, X. Feng, A. Piechatzek, C. Shen, M. Gilliham/.
\n$\cdot$ /New Phytologist (NPH), 2023/.
\n$\cdot$ [https://doi.org/10.1101/2022.02.07.479482  link][data/bibtex/Sai2023NPJ.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SAI}:+An+efficient+and+user-friendly+tool+for+measurement+of+stomatal+pores+and+density+using+deep+computer+vision+Sai,+Na+and+Bockman,+James+Paul+and+Chen,+Hao+and+Watson-Haigh,+Nathan+and+Xu,+Bo+and+Feng,+Xueying+and+Piechatzek,+Adriane+and+Shen,+Chunhua+and+Gilliham,+Matthew google scholar][https://www.semanticscholar.org/search?q={SAI}:+An+efficient+and+user-friendly+tool+for+measurement+of+stomatal+pores+and+density+using+deep+computer+vision semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Xie2023DodNetxxxarXiv.jpg">}}*Learning from partially labeled data for multi-organ and tumor segmentation*   
\n$\cdot$ /Y. Xie, J. Zhang, Y. Xia, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2211.06894    arXiv][data/bibtex/Xie2023DodNet.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+from+partially+labeled+data+for+multi-organ+and+tumor+segmentation+Xie,+Yutong+and+Zhang,+Jianpeng+and+Xia,+Yong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Learning+from+partially+labeled+data+for+multi-organ+and+tumor+segmentation semantic scholar][https://git.io/DoDNet   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Sun2023TPAMIxxxarXiv.jpg">}}*SC-DepthV3: robust self-supervised monocular depth estimation for dynamic scenes*   
\n$\cdot$ /L. Sun, J. Bian, H. Zhan, W. Yin, I. Reid, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2211.03660    arXiv][data/bibtex/Sun2023TPAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SC-DepthV3}:+Robust+Self-supervised+Monocular+Depth+Estimation+for+Dynamic+Scenes+Sun,+Libo+and+Bian,+Jia-Wang+and+Zhan,+Huangying+and+Yin,+Wei+and+Reid,+Ian+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={SC-DepthV3}:+Robust+Self-supervised+Monocular+Depth+Estimation+for+Dynamic+Scenes semantic scholar][https://github.com/JiawangBian/sc_depth_pl   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/SPTSv2xxxarXiv.jpg">}}*SPTS v2: single-point scene text spotting*   
\n$\cdot$ /Y. Liu, J. Zhang, D. Peng, M. Huang, X. Wang, J. Tang, C. Huang, D. Lin, C. Shen, X. Bai, L. Jin/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2301.01635    arXiv][data/bibtex/SPTSv2.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SPTS+v2}:+Single-Point+Scene+Text+Spotting+Liu,+Yuliang+and+Zhang,+Jiaxin+and+Peng,+Dezhi+and+Huang,+Mingxin+and+Wang,+Xinyu+and+Tang,+Jingqun+and+Huang,+Can+and+Lin,+Dahua+and+Shen,+Chunhua+and+Bai,+Xiang+and+Jin,+Lianwen google scholar][https://www.semanticscholar.org/search?q={SPTS+v2}:+Single-Point+Scene+Text+Spotting semantic scholar][https://github.com/Yuliang-Liu/SPTSv2   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Liu2023TPAMIxxxarXiv.jpg">}}*Single-path bit sharing for automatic loss-aware model compression*   
\n$\cdot$ /J. Liu, B. Zhuang, P. Chen, C. Shen, J. Cai, M. Tan/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2101.04935    arXiv][data/bibtex/Liu2023TPAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Single-path+Bit+Sharing+for+Automatic+Loss-aware+Model+Compression+Liu,+Jing+and+Zhuang,+Bohan+and+Chen,+Peng+and+Shen,+Chunhua+and+Cai,+Jianfei+and+Tan,+Mingkui google scholar][https://www.semanticscholar.org/search?q=Single-path+Bit+Sharing+for+Automatic+Loss-aware+Model+Compression semantic scholar]
== Conference
. *FoPro: few-shot guided robust webly-supervised prototypical learning*   
\n$\cdot$ /Y. Qin, X. Chen, C. Chen, Y. Shen, B. Ren, Y. Gu, J. Yang, C. Shen/.
\n$\cdot$ /Proc. AAAI Conference on Artificial Intelligence (AAAI'23), 2023/.
\n$\cdot$ [data/bibtex/FoPro2023AAAI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={FoPro}:+Few-Shot+Guided+Robust+Webly-Supervised+Prototypical+Learning+Qin,+Yulei+and+Chen,+Xinyu+and+Chen,+Chao+and+Shen,+Yunhang+and+Ren,+Bo+and+Gu,+Yun+and+Yang,+Jie+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={FoPro}:+Few-Shot+Guided+Robust+Webly-Supervised+Prototypical+Learning semantic scholar]
. *Point-Teaching: weakly semi-supervised object detection with point annotations*   
\n$\cdot$ /Y. Ge, Q. Zhou, X. Wang, Z. Wang, H. Li, C. Shen/.
\n$\cdot$ /Proc. AAAI Conference on Artificial Intelligence (AAAI'23), 2023/.
\n$\cdot$ [data/bibtex/PointTeaching2023AAAI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={Point-Teaching}:+Weakly+Semi-Supervised+Object+Detection+with+Point+Annotations+Ge,+Yongtao+and+Zhou,+Qiang+and+Wang,+Xinlong+and+Wang,+Zhibin+and+Li,+Hao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={Point-Teaching}:+Weakly+Semi-Supervised+Object+Detection+with+Point+Annotations semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/CVPR2023aWangxxxarXiv.jpg">}}*Images speak in images: a generalist painter for in-context visual learning*   
\n$\cdot$ /X. Wang, W. Wang, Y. Cao, C. Shen, T. Huang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'23), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2212.02499    arXiv][data/bibtex/CVPR2023aWang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Images+Speak+in+Images:+A+Generalist+Painter+for+In-Context+Visual+Learning+Wang,+Xinlong+and+Wang,+Wen+and+Cao,+Yue+and+Shen,+Chunhua+and+Huang,+Tiejun google scholar][https://www.semanticscholar.org/search?q=Images+Speak+in+Images:+A+Generalist+Painter+for+In-Context+Visual+Learning semantic scholar][https://github.com/baaivision/Painter   project webpage]
. *Learning conditional attributes for compositional zero-shot learning*   
\n$\cdot$ /Q. Wang, L. Liu, C. Jing, H. Chen, G. Liang, P. Wang, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'23), 2023/.
\n$\cdot$ [data/bibtex/CVPR2023B.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Conditional+Attributes+for+Compositional+Zero-Shot+Learning+Wang,+Qingsheng+and+Liu,+Lingqiao+and+Jing,+Chenchen+and+Chen,+Hao+and+Liang,+Guoqiang+and+Wang,+Peng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Learning+Conditional+Attributes+for+Compositional+Zero-Shot+Learning semantic scholar]
. *Segprompt: boosting open-world segmentation via category-level prompt learning*   
\n$\cdot$ /M. Zhu, H. Li, H. Chen, C. Fan, W. Mao, C. Jing, Y. Liu, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'23), 2023/.
\n$\cdot$ [data/bibtex/Zhu2023ICCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=SegPrompt:+Boosting+Open-World+Segmentation+via+Category-level+Prompt+Learning+Zhu,+Muzhi+and+Li,+Hengtao+and+Chen,+Hao+and+Fan,+Chengxiang+and+Mao,+Weian+and+Jing,+Chenchen+and+Liu,+Yifan+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=SegPrompt:+Boosting+Open-World+Segmentation+via+Category-level+Prompt+Learning semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/YZhao2023ICCVxxxarXiv.jpg">}}*Generative prompt model for weakly supervised object localization*   
\n$\cdot$ /Y. Zhao, Q. Ye, W. Wu, C. Shen, F. Wan/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'23), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2307.09756    arXiv][data/bibtex/YZhao2023ICCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Generative+Prompt+Model+for+Weakly+Supervised+Object+Localization+Zhao,+Yuzhong+and+Ye,+Qixiang+and+Wu,+Weijia+and+Shen,+Chunhua+and+Wan,+Fang google scholar][https://www.semanticscholar.org/search?q=Generative+Prompt+Model+for+Weakly+Supervised+Object+Localization semantic scholar]
. *Robust geometry-preserving depth estimation using differentiable rendering*   
\n$\cdot$ /C. Zhang, W. Yin, G. Yu, Z. Wang, T. Chen, B. Fu, J. Zhou, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'23), 2023/.
\n$\cdot$ [data/bibtex/ZhangC2023ICCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Robust+Geometry-Preserving+Depth+Estimation+Using+Differentiable+Rendering+Zhang,+Chi+and+Yin,+Wei+and+Yu,+Gang+and+Wang,+Zhibin+and+Chen,+Tao+and+Fu,+Bin+and+Zhou,+Joey+Tianyi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Robust+Geometry-Preserving+Depth+Estimation+Using+Differentiable+Rendering semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/KYQZ2023ICCVxxxarXiv.jpg">}}*CTVIS: consistent training for online video instance segmentation*   
\n$\cdot$ /K. Ying, Q. Zhong, W. Mao, Z. Wang, H. Chen, L. Wu, Y. Liu, C. Fan, Y. Zhuge, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'23), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2307.12616    arXiv][data/bibtex/KYQZ2023ICCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={CTVIS}:+Consistent+Training+for+Online+Video+Instance+Segmentation+Ying,+Kaining+and+Zhong,+Qing+and+Mao,+Weian+and+Wang,+Zhenhua+and+Chen,+Hao+and+Wu,+Lin+Yuanbo+and+Liu,+Yifan+and+Fan,+Chengxiang+and+Zhuge,+Yunzhi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={CTVIS}:+Consistent+Training+for+Online+Video+Instance+Segmentation semantic scholar][https://github.com/KainingYing/CTVIS   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Yinwei2023ICCVxxxarXiv.jpg">}}*Metric3D: towards zero-shot metric 3d prediction from a single image*   
\n$\cdot$ /W. Yin, C. Zhang, H. Chen, Z. Cai, G. Yu, K. Wang, X. Chen, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'23), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2307.10984    arXiv][data/bibtex/Yinwei2023ICCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={Metric3D}:+Towards+Zero-shot+Metric+3D+Prediction+from+A+Single+Image+Yin,+Wei+and+Zhang,+Chi+and+Chen,+Hao+and+Cai,+Zhipeng+and+Yu,+Gang+and+Wang,+Kaixuan+and+Chen,+Xiaozhi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={Metric3D}:+Towards+Zero-shot+Metric+3D+Prediction+from+A+Single+Image semantic scholar]
. *Pose-free 3d scene reconstruction with frozen depth models*   
\n$\cdot$ /G. Xu, W. Yin, H. Chen, C. Shen, K. Cheng, F. Zhao/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'23), 2023/.
\n$\cdot$ [data/bibtex/XuG2023ICCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Pose-free+3D+Scene+Reconstruction+with+Frozen+Depth+Models+Xu,+Guangkai+and+Yin,+Wei+and+Chen,+Hao+and+Shen,+Chunhua+and+Cheng,+Kai+and+Zhao,+Feng google scholar][https://www.semanticscholar.org/search?q=Pose-free+3D+Scene+Reconstruction+with+Frozen+Depth+Models semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/DiffuMask2023ICCVxxxarXiv.jpg">}}*Diffumask: synthesizing images with pixel-level annotations for semantic segmentation using diffusion models*   
\n$\cdot$ /W. Wu, Y. Zhao, M. Shou, H. Zhou, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'23), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2303.11681    arXiv][data/bibtex/DiffuMask2023ICCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Diffumask:+Synthesizing+images+with+pixel-level+annotations+for+semantic+segmentation+using+diffusion+models+Wu,+Weijia+and+Zhao,+Yuzhong+and+Shou,+Mike+Zheng+and+Zhou,+Hong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Diffumask:+Synthesizing+images+with+pixel-level+annotations+for+semantic+segmentation+using+diffusion+models semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/SegGPT2023ICCVxxxarXiv.jpg">}}*SegGPT: towards segmenting everything in context*   
\n$\cdot$ /X. Wang, X. Zhang, Y. Cao, W. Wang, C. Shen, T. Huang/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'23), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2304.03284    arXiv][data/bibtex/SegGPT2023ICCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SegGPT}:+Towards+Segmenting+Everything+In+Context+Wang,+Xinlong+and+Zhang,+Xiaosong+and+Cao,+Yue+and+Wang,+Wen+and+Shen,+Chunhua+and+Huang,+Tiejun google scholar][https://www.semanticscholar.org/search?q={SegGPT}:+Towards+Segmenting+Everything+In+Context semantic scholar]
. *Zolly: zoom focal length correctly for perspective-distorted human mesh reconstruction*   
\n$\cdot$ /W. Wang, Y. Ge, H. Mei, Z. Cai, Q. Sun, C. Shen, Y. Wang, L. Yang, T. Komura/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'23), 2023/.
\n$\cdot$ [data/bibtex/WangW2023ICCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Zolly:+Zoom+Focal+Length+Correctly+for+Perspective-Distorted+Human+Mesh+Reconstruction+Wang,+Wenjia+and+Ge,+Yongtao+and+Mei,+Haiyi+and+Cai,+Zhongang+and+Sun,+Qingping+and+Shen,+Chunhua+and+Wang,+Yanjun+and+Yang,+Lei+and+Komura,+Taku google scholar][https://www.semanticscholar.org/search?q=Zolly:+Zoom+Focal+Length+Correctly+for+Perspective-Distorted+Human+Mesh+Reconstruction semantic scholar]
        .. Oral presentation.
. {{<img class="imgP  right"   src="data/thumbnail/CPE2023ICLRxxxarXiv.jpg">}}*Conditional positional encodings for vision transformers*   
\n$\cdot$ /X. Chu, Z. Tian, B. Zhang, X. Wang, X. Wei, H. Xia, C. Shen/.
\n$\cdot$ /Proc. International Conference on Learning Representations (ICLR'23), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2102.10882    arXiv][data/bibtex/CPE2023ICLR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Conditional+Positional+Encodings+for+Vision+Transformers+Chu,+Xiangxiang+and+Tian,+Zhi+and+Zhang,+Bo+and+Wang,+Xinlong+and+Wei,+Xiaolin+and+Xia,+Huaxia+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Conditional+Positional+Encodings+for+Vision+Transformers semantic scholar]
. *Deep weakly-supervised anomaly detection*   
\n$\cdot$ /G. Pang, C. Shen, H. Jin, A. van den Hengel/.
\n$\cdot$ /Proc. ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'23), 2023/.
\n$\cdot$ [data/bibtex/Pang2023KDD.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+Weakly-supervised+Anomaly+Detection+Pang,+Guansong+and+Shen,+Chunhua+and+Jin,+Huidong+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Deep+Weakly-supervised+Anomaly+Detection semantic scholar][https://github.com/mala-lab/PReNet   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Weijia2023DDMxxxarXiv.jpg">}}*DatasetDM: synthesizing data with perception annotations using diffusion models*   
\n$\cdot$ /W. Wu, Y. Zhao, H. Chen, Y. Gu, R. Zhao, Y. He, H. Zhou, M. Shou, C. Shen/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'23), 2023/.
\n$\cdot$ [http://arxiv.org/abs/2308.06160    arXiv][data/bibtex/Weijia2023DDM.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={DatasetDM}:+Synthesizing+Data+with+Perception+Annotations+Using+Diffusion+Models+Wu,+Weijia+and+Zhao,+Yuzhong+and+Chen,+Hao+and+Gu,+Yuchao+and+Zhao,+Rui+and+He,+Yefei+and+Zhou,+Hong+and+Shou,+Mike+Zheng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={DatasetDM}:+Synthesizing+Data+with+Perception+Annotations+Using+Diffusion+Models semantic scholar][https://weijiawu.github.io/DatasetDM_page/   project webpage]

= 2022
== Journal
. *Effective eyebrow matting with domain adaptation*   
\n$\cdot$ /L. Wang, H. Zhang, Q. Xiao, H. Xu, C. Shen, X. Jin/.
\n$\cdot$ /Computer Graphics Forum (CGF), 2022/.
\n$\cdot$ [data/bibtex/Wang2022CGF.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Effective+Eyebrow+Matting+with+Domain+Adaptation+Wang,+Luyuan+and+Zhang,+Hanyuan+and+Xiao,+Qinjie+and+Xu,+Hao+and+Shen,+Chunhua+and+Jin,+Xiaogang google scholar][https://www.semanticscholar.org/search?q=Effective+Eyebrow+Matting+with+Domain+Adaptation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Zhuang2022IJCVxxxarXiv.jpg">}}*Structured binary neural networks for image recognition*   
\n$\cdot$ /B. Zhuang, C. Shen, M. Tan, P. Chen, L. Liu, I. Reid/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2022/.
\n$\cdot$ [http://arxiv.org/abs/1909.09934    arXiv][data/bibtex/Zhuang2022IJCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Structured+Binary+Neural+Networks+for+Image+Recognition+Zhuang,+Bohan+and+Shen,+Chunhua+and+Tan,+Mingkui+and+Chen,+Peng+and+Liu,+Lingqiao+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Structured+Binary+Neural+Networks+for+Image+Recognition semantic scholar]
. *Arbitrarily shaped scene text detection with dynamic convolution*   
\n$\cdot$ /Y. Cai, Y. Liu, C. L. Jin, Y. Li, D. Ergu/.
\n$\cdot$ /Pattern Recognition (PR), 2022/.
\n$\cdot$ [data/bibtex/Cai2022PR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Arbitrarily+shaped+scene+text+detection+with+dynamic+convolution+Cai,+Ying+and+Liu,+Yuliang+and+ChunhuaShen+and+Jin,+Lianwen+and+Li,+Yidong+and+Ergu,+Daji google scholar][https://www.semanticscholar.org/search?q=Arbitrarily+shaped+scene+text+detection+with+dynamic+convolution semantic scholar]
. *TSGB: target-selective gradient backprop for probing CNN visual saliency*   
\n$\cdot$ /L. Cheng, P. Fang, Y. Liang, L. Zhang, C. Shen, H. Wang/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2022/.
\n$\cdot$ [data/bibtex/TSGB2022TIP.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={TSGB}:+Target-selective+gradient+backprop+for+probing+{CNN}+visual+saliency+Cheng,+Lin+and+Fang,+Pengfei+and+Liang,+Yanjie+and+Zhang,+Liao+and+Shen,+Chunhua+and+Wang,+Hanzi google scholar][https://www.semanticscholar.org/search?q={TSGB}:+Target-selective+gradient+backprop+for+probing+{CNN}+visual+saliency semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Chi2022TPAMIxxxarXiv.jpg">}}*DeepEMD: differentiable earth mover's distance for few-shot learning*   
\n$\cdot$ /C. Zhang, Y. Cai, G. Lin, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022/.
\n$\cdot$ [http://arxiv.org/abs/2003.06777    arXiv][data/bibtex/Chi2022TPAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={DeepEMD}:+Differentiable+Earth+Mover's+Distance+for+Few-Shot+Learning+Zhang,+Chi+and+Cai,+Yujun+and+Lin,+Guosheng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={DeepEMD}:+Differentiable+Earth+Mover's+Distance+for+Few-Shot+Learning semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Weiyin2022TPAMIxxxarXiv.jpg">}}*Towards accurate reconstruction of 3D scene shape from a single monocular image*   
\n$\cdot$ /W. Yin, J. Zhang, O. Wang, S. Niklaus, S. Chen, Y. Liu, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022/.
\n$\cdot$ [http://arxiv.org/abs/2208.13241    arXiv][data/bibtex/Weiyin2022TPAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Towards+Accurate+Reconstruction+of+{3D}+Scene+Shape+from+A+Single+Monocular+Image+Yin,+Wei+and+Zhang,+Jianming+and+Wang,+Oliver+and+Niklaus,+Simon+and+Chen,+Simon+and+Liu,+Yifan+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Towards+Accurate+Reconstruction+of+{3D}+Scene+Shape+from+A+Single+Monocular+Image semantic scholar][https://github.com/aim-uofa/depth/   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/CondInst2022TianxxxarXiv.jpg">}}*Instance and panoptic segmentation using conditional convolutions*   
\n$\cdot$ /Z. Tian, B. Zhang, H. Chen, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022/.
\n$\cdot$ [http://arxiv.org/abs/2102.03026    arXiv][data/bibtex/CondInst2022Tian.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Instance+and+Panoptic+Segmentation+Using+Conditional+Convolutions+Tian,+Zhi+and+Zhang,+Bowen+and+Chen,+Hao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Instance+and+Panoptic+Segmentation+Using+Conditional+Convolutions semantic scholar][https://github.com/aim-uofa/AdelaiDet/   project webpage]
. *FCOS: a simple and strong anchor-free object detector*   
\n$\cdot$ /Z. Tian, C. Shen, H. Chen, T. He/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022/.
\n$\cdot$ [https://doi.org/10.1109/TPAMI.2020.3032166  link][data/bibtex/TianSCH22.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={FCOS:}+A+Simple+and+Strong+Anchor-Free+Object+Detector+Tian,+Zhi+and+Shen,+Chunhua+and+Chen,+Hao+and+He,+Tong google scholar][https://www.semanticscholar.org/search?q={FCOS:}+A+Simple+and+Strong+Anchor-Free+Object+Detector semantic scholar][https://github.com/aim-uofa/AdelaiDet/   project webpage]
. *Dynamic convolution for 3D point cloud instance segmentation*   
\n$\cdot$ /T. He, C. Shen, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022/.
\n$\cdot$ [http://arxiv.org/abs/2107.08392    arXiv][data/bibtex/Tong2022TPAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Dynamic+Convolution+for+{3D}+Point+Cloud+Instance+Segmentation+He,+Tong+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Dynamic+Convolution+for+{3D}+Point+Cloud+Instance+Segmentation semantic scholar]
. *Improving monocular visual odometry using learned depth*   
\n$\cdot$ /L. Sun, W. Yin, E. Xie, Z. Li, C. Sun, C. Shen/.
\n$\cdot$ /IEEE Transactions on Robotics (TRO), 2022/.
\n$\cdot$ [data/bibtex/Sun2022TRO.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Improving+Monocular+Visual+Odometry+Using+Learned+Depth+Sun,+Libo+and+Yin,+Wei+and+Xie,+Enze+and+Li,+Zhengrong+and+Sun,+Changming+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Improving+Monocular+Visual+Odometry+Using+Learned+Depth semantic scholar]
. *DenseCL: a simple framework for self-supervised dense visual pre-training*   
\n$\cdot$ /X. Wang, R. Zhang, C. Shen, T. Kong/.
\n$\cdot$ /Visual Informatics (VI), 2022/.
\n$\cdot$ [data/bibtex/Wang2022VI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={DenseCL}:+A+simple+framework+for+self-supervised+dense+visual+pre-training+Wang,+Xinlong+and+Zhang,+Rufeng+and+Shen,+Chunhua+and+Kong,+Tao google scholar][https://www.semanticscholar.org/search?q={DenseCL}:+A+simple+framework+for+self-supervised+dense+visual+pre-training semantic scholar]
== Conference
. {{<img class="imgP  right"   src="data/thumbnail/Peng2022MMxxxarXiv.jpg">}}*SPTS: single-point text spotting*   
\n$\cdot$ /D. Peng, X. Wang, Y. Liu, J. Zhang, M. Huang, S. Lai, S. Zhu, J. Li, D. Lin, C. Shen, X. Bai, L. Jin/.
\n$\cdot$ /Proc. ACM International Conference on Multimedia (ACMMM'22), 2022/.
\n$\cdot$ [http://arxiv.org/abs/2112.07917    arXiv][data/bibtex/Peng2022MM.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SPTS}:+Single-Point+Text+Spotting+Peng,+Dezhi+and+Wang,+Xinyu+and+Liu,+Yuliang+and+Zhang,+Jiaxin+and+Huang,+Mingxin+and+Lai,+Songxuan+and+Zhu,+Shenggao+and+Li,+Jing+and+Lin,+Dahua+and+Shen,+Chunhua+and+Bai,+Xiang+and+Jin,+Lianwen google scholar][https://www.semanticscholar.org/search?q={SPTS}:+Single-Point+Text+Spotting semantic scholar]
. *TopFormer: token pyramid transformer for mobile semantic segmentation*   
\n$\cdot$ /W. Zhang, Z. Huang, G. Yu, T. Chen, G. Luo, X. Wang, W. Liu, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'22), 2022/.
\n$\cdot$ [data/bibtex/Topformer2022.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={TopFormer}:+Token+Pyramid+Transformer+for+Mobile+Semantic+Segmentation+Zhang,+Wenqiang+and+Huang,+Zilong+and+Yu,+Gang+and+Chen,+Tao+and+Luo,+Guozhong+and+Wang,+Xinggang+and+Liu,+Wenyu+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={TopFormer}:+Token+Pyramid+Transformer+for+Mobile+Semantic+Segmentation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Wang2022SoloxxxarXiv.jpg">}}*FreeSOLO: learning to segment objects without annotations*   
\n$\cdot$ /X. Wang, Z. Yu, S. De Mello, J. Kautz, A. Anandkumar, C. Shen, J. Alvarez/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'22), 2022/.
\n$\cdot$ [http://arxiv.org/abs/2202.12181    arXiv][data/bibtex/Wang2022Solo.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={FreeSOLO}:+Learning+to+Segment+Objects+without+Annotations+Wang,+Xinlong+and+Yu,+Zhiding+and+{De+Mello},+Shalini+and+Kautz,+Jan+and+Anandkumar,+Anima+and+Shen,+Chunhua+and+Alvarez,+Jose google scholar][https://www.semanticscholar.org/search?q={FreeSOLO}:+Learning+to+Segment+Objects+without+Annotations semantic scholar][https://git.io/AdelaiDet   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Long2022RACxxxarXiv.jpg">}}*Retrieval augmented classification for long-tail visual recognition*   
\n$\cdot$ /A. Long, W. Yin, T. Ajanthan, V. Nguyen, P. Purkait, R. Garg, A. Blair, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'22), 2022/.
\n$\cdot$ [http://arxiv.org/abs/2202.11233    arXiv][data/bibtex/Long2022RAC.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Retrieval+Augmented+Classification+for+Long-Tail+Visual+Recognition+Long,+Alexander+and+Yin,+Wei+and+Ajanthan,+Thalaiyasingam+and+Nguyen,+Vu+and+Purkait,+Pulak+and+Garg,+Ravi+and+Blair,+Alan+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Retrieval+Augmented+Classification+for+Long-Tail+Visual+Recognition semantic scholar]
. *RigidFlow: self-supervised scene flow learning on point clouds by local rigidity prior*   
\n$\cdot$ /R. Li, C. Zhang, G. Lin, Z. Wang, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'22), 2022/.
\n$\cdot$ [data/bibtex/Li2022Rigid.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={RigidFlow}:+Self-Supervised+Scene+Flow+Learning+on+Point+Clouds+by+Local+Rigidity+Prior+Li,+Ruibo+and+Zhang,+Chi+and+Lin,+Guosheng+and+Wang,+Zhe+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={RigidFlow}:+Self-Supervised+Scene+Flow+Learning+on+Point+Clouds+by+Local+Rigidity+Prior semantic scholar]
. *Catching both gray and black swans: open-set supervised anomaly detection*   
\n$\cdot$ /C. Ding, G. Pan, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'22), 2022/.
\n$\cdot$ [data/bibtex/Ding2022Catching.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Catching+Both+Gray+and+Black+Swans:+Open-set+Supervised+Anomaly+Detection+Ding,+Choubo+and+Pan,+Guansong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Catching+Both+Gray+and+Black+Swans:+Open-set+Supervised+Anomaly+Detection semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Dai2022MattingxxxarXiv.jpg">}}*Boosting robustness of image matting with context assembling and strong data augmentation*   
\n$\cdot$ /Y. Dai, B. Price, H. Zhang, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'22), 2022/.
\n$\cdot$ [http://arxiv.org/abs/2201.06889    arXiv][data/bibtex/Dai2022Matting.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Boosting+Robustness+of+Image+Matting+with+Context+Assembling+and+Strong+Data+Augmentation+Dai,+Yutong+and+Price,+Brian+and+Zhang,+He+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Boosting+Robustness+of+Image+Matting+with+Context+Assembling+and+Strong+Data+Augmentation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Poseur2022DetectionxxxarXiv.jpg">}}*Poseur: direct human pose regression with transformers*   
\n$\cdot$ /W. Mao, Y. Ge, C. Shen, Z. Tian, X. Wang, Z. Wang, A. van den Hengel/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'22), 2022/.
\n$\cdot$ [http://arxiv.org/abs/2201.07412    arXiv][data/bibtex/Poseur2022Detection.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={Poseur}:+Direct+Human+Pose+Regression+with+Transformers+Mao,+Weian+and+Ge,+Yongtao+and+Shen,+Chunhua+and+Tian,+Zhi+and+Wang,+Xinlong+and+Wang,+Zhibin+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q={Poseur}:+Direct+Human+Pose+Regression+with+Transformers semantic scholar][https://github.com/aim-uofa/Poseur   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Tong2022DetectionxxxarXiv.jpg">}}*PointInst3D: segmenting 3D instances by points*   
\n$\cdot$ /T. He, W. Yin, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'22), 2022/.
\n$\cdot$ [http://arxiv.org/abs/2204.11402    arXiv][data/bibtex/Tong2022Detection.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={PointInst3D}:+Segmenting+{3D}+Instances+by+Points+He,+Tong+and+Yin,+Wei+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q={PointInst3D}:+Segmenting+{3D}+Instances+by+Points semantic scholar]
. *DisCo: remedying self-supervised learning on lightweight models with distilled contrastive learning*   
\n$\cdot$ /Y. Gao, J. Zhuang, S. Lin, H. Cheng, X. Sun, K. Li, C. Shen/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'22), 2022/.
\n$\cdot$ [data/bibtex/Gao2022DisCO.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={DisCo}:+Remedying+Self-supervised+Learning+on+Lightweight+Models+with+Distilled+Contrastive+Learning+Gao,+Yuting+and+Zhuang,+Jia-Xin+and+Lin,+Shaohui+and+Cheng,+Hao+and+Sun,+Xing+and+Li,+Ke+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={DisCo}:+Remedying+Self-supervised+Learning+on+Lightweight+Models+with+Distilled+Contrastive+Learning semantic scholar][https://github.com/Yuting-Gao/DisCo-pytorch   project webpage]
        .. Oral presentation.
. {{<img class="imgP  right"   src="data/thumbnail/Peixian2022DetectionxxxarXiv.jpg">}}*Efficient decoder-free object detection with transformers*   
\n$\cdot$ /P. Chen, M. Zhang, Y. Shen, K. Sheng, Y. Gao, X. Sun, K. Li, C. Shen/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'22), 2022/.
\n$\cdot$ [http://arxiv.org/abs/2206.06829    arXiv][data/bibtex/Peixian2022Detection.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Efficient+Decoder-free+Object+Detection+with+Transformers+Chen,+Peixian+and+Zhang,+Mengdan+and+Shen,+Yunhang+and+Sheng,+Kekai+and+Gao,+Yuting+and+Sun,+Xing+and+Li,+Ke+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Efficient+Decoder-free+Object+Detection+with+Transformers semantic scholar]
. *DENSE: data-free one-shot federated learning*   
\n$\cdot$ /J. Zhang, C. Chen, B. Li, L. Lyu, S. Wu, S. Ding, C. Shen, C. Wu/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'22), 2022/.
\n$\cdot$ [data/bibtex/Zhang2022DENSE.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={DENSE}:+Data-Free+One-Shot+Federated+Learning+Zhang,+Jie+and+Chen,+Chen+and+Li,+Bo+and+Lyu,+Lingjuan+and+Wu,+Shuang+and+Ding,+Shouhong+and+Shen,+Chunhua+and+Wu,+Chao google scholar][https://www.semanticscholar.org/search?q={DENSE}:+Data-Free+One-Shot+Federated+Learning semantic scholar]
. *Hierarchical normalization for robust monocular depth estimation*   
\n$\cdot$ /C. Zhang, W. Yin, Z. Wang, G. Yu, B. Fu, C. Shen/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'22), 2022/.
\n$\cdot$ [data/bibtex/Chi2022Depth.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Hierarchical+Normalization+for+Robust+Monocular+Depth+Estimation+Zhang,+Chi+and+Yin,+Wei+and+Wang,+Zhibin+and+Yu,+Gang+and+Fu,+Bin+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Hierarchical+Normalization+for+Robust+Monocular+Depth+Estimation semantic scholar]
. *SegViT: semantic segmentation with plain vision transformers*   
\n$\cdot$ /B. Zhang, Z. Tian, Q. Tang, X. Chu, X. Wei, C. Shen, Y. Liu/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'22), 2022/.
\n$\cdot$ [data/bibtex/Zhang2022ViTb.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SegViT}:+Semantic+Segmentation+with+Plain+Vision+Transformers+Zhang,+Bowen+and+Tian,+Zhi+and+Tang,+Quan+and+Chu,+Xiangxiang+and+Wei,+Xiaolin+and+Shen,+Chunhua+and+Liu,+Yifan google scholar][https://www.semanticscholar.org/search?q={SegViT}:+Semantic+Segmentation+with+Plain+Vision+Transformers semantic scholar]
. *Fully convolutional one-stage 3D object detection on LiDAR range images*   
\n$\cdot$ /Z. Tian, X. Chu, X. Wang, X. Wei, C. Shen/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'22), 2022/.
\n$\cdot$ [data/bibtex/Tian2022FCOSLidar.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fully+Convolutional+One-Stage+{3D}+Object+Detection+on+{LiDAR}+Range+Images+Tian,+Zhi+and+Chu,+Xiangxiang+and+Wang,+Xiaoming+and+Wei,+Xiaolin+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Fully+Convolutional+One-Stage+{3D}+Object+Detection+on+{LiDAR}+Range+Images semantic scholar]
. *Text-adaptive multiple visual prototype matching for video-text retrieval*   
\n$\cdot$ /C. Lin, A. Wu, J. Liang, J. Zhang, W. Ge, W. Zheng, C. Shen/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'22), 2022/.
\n$\cdot$ [data/bibtex/Lin2022TVRc.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Text-Adaptive+Multiple+Visual+Prototype+Matching+for+Video-Text+Retrieval+Lin,+Chengzhi+and+Wu,+Ancong+and+Liang,+Junwei+and+Zhang,+Jun+and+Ge,+Wenhang+and+Zheng,+Wei-Shi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Text-Adaptive+Multiple+Visual+Prototype+Matching+for+Video-Text+Retrieval semantic scholar]
. *Multi-dataset training of transformers for robust action recognition*   
\n$\cdot$ /J. Liang, E. Zhang, J. Zhang, C. Shen/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'22), 2022/.
\n$\cdot$ [data/bibtex/Liang2022Action.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Multi-dataset+Training+of+Transformers+for+Robust+Action+Recognition+Liang,+Junwei+and+Zhang,+Enwei+and+Zhang,+Jun+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Multi-dataset+Training+of+Transformers+for+Robust+Action+Recognition semantic scholar]
. *Adv-attribute: inconspicuous and transferable adversarial attack on face recognition*   
\n$\cdot$ /S. Jia, B. Yin, T. Yao, S. Ding, C. Shen, X. Yang, C. Ma/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'22), 2022/.
\n$\cdot$ [data/bibtex/Jia2022AdvA.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Adv-Attribute:+Inconspicuous+and+Transferable+Adversarial+Attack+on+Face+Recognition+Jia,+Shuai+and+Yin,+Bangjie+and+Yao,+Taiping+and+Ding,+Shouhong+and+Shen,+Chunhua+and+Yang,+Xiaokang+and+Ma,+Chao google scholar][https://www.semanticscholar.org/search?q=Adv-Attribute:+Inconspicuous+and+Transferable+Adversarial+Attack+on+Face+Recognition semantic scholar]
. *PyramidCLIP: hierarchical feature alignment for vision-language model pretraining*   
\n$\cdot$ /Y. Gao, J. Liu, Z. Xu, J. Zhang, K. Li, R. Ji, C. Shen/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'22), 2022/.
\n$\cdot$ [data/bibtex/Gao2022CLIP.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={PyramidCLIP}:+Hierarchical+Feature+Alignment+for+Vision-language+Model+Pretraining+Gao,+Yuting+and+Liu,+Jinfeng+and+Xu,+Zihan+and+Zhang,+Jun+and+Li,+Ke+and+Ji,+Rongrong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={PyramidCLIP}:+Hierarchical+Feature+Alignment+for+Vision-language+Model+Pretraining semantic scholar]

= 2021
== Journal
. {{<img class="imgP  right"   src="data/thumbnail/Haokui2021NASxxxarXiv.jpg">}}*Memory-efficient hierarchical neural architecture search for image restoration*   
\n$\cdot$ /H. Zhang, Y. Li, H. Chen, C. Gong, Z. Bai, C. Shen/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2012.13212    arXiv][data/bibtex/Haokui2021NAS.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Memory-Efficient+Hierarchical+Neural+Architecture+Search+for+Image+Restoration+Zhang,+Haokui+and+Li,+Ying+and+Chen,+Hao+and+Gong,+Chengrong+and+Bai,+Zongwen+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Memory-Efficient+Hierarchical+Neural+Architecture+Search+for+Image+Restoration semantic scholar][https://github.com/hkzhang91/HiNAS   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Yu2021BiSegV2xxxarXiv.jpg">}}*BiSeNet v2: bilateral network with guided aggregation for real-time semantic segmentation*   
\n$\cdot$ /C. Yu, C. Gao, J. Wang, G. Yu, C. Shen, N. Sang/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2004.02147    arXiv][data/bibtex/Yu2021BiSegV2.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={BiSeNet}+v2:+Bilateral+Network+with+Guided+Aggregation+for+Real-time+Semantic+Segmentation+Yu,+Changqian+and+Gao,+Changxin+and+Wang,+Jingbo+and+Yu,+Gang+and+Shen,+Chunhua+and+Sang,+Nong google scholar][https://www.semanticscholar.org/search?q={BiSeNet}+v2:+Bilateral+Network+with+Guided+Aggregation+for+Real-time+Semantic+Segmentation semantic scholar]
. *A dual-attention-guided network for ghost-free high dynamic range imaging*   
\n$\cdot$ /Q. Yan, D. Gong, Q. Shi, A. van den Hengel, C. Shen, I. Reid, Y. Zhang/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2021/.
\n$\cdot$ [data/bibtex/Yan2021Ghostfree.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Dual-Attention-guided+network+for+ghost-free+high+dynamic+range+imaging+Yan,+Qingsen+and+Gong,+Dong+and+Shi,+Qinfeng+and+{van+den+Hengel},+Anton+and+Shen,+Chunhua+and+Reid,+Ian+and+Zhang,+Yanning google scholar][https://www.semanticscholar.org/search?q=A+Dual-Attention-guided+network+for+ghost-free+high+dynamic+range+imaging semantic scholar][https://github.com/qingsenyangit/AHDRNet   project webpage]
. *NAS-FCOS: efficient search for object detection architectures*   
\n$\cdot$ /N. Wang, Y. Gao, H. Chen, P. Wang, Z. Tian, C. Shen, Y. Zhang/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2021/.
\n$\cdot$ [data/bibtex/Wang2021IJCV_NAS.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={NAS-FCOS}:+Efficient+Search+for+Object+Detection+Architectures+Wang,+Ning+and+Gao,+Yang+and+Chen,+Hao+and+Wang,+Peng+and+Tian,+Zhi+and+Shen,+Chunhua+and+Zhang,+Yanning google scholar][https://www.semanticscholar.org/search?q={NAS-FCOS}:+Efficient+Search+for+Object+Detection+Architectures semantic scholar][https://github.com/Lausannen/NAS-FCOS   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/IJCV2021LiuylxxxarXiv.jpg">}}*Exploring the capacity of an orderless box discretization network for multi-orientation scene text detection*   
\n$\cdot$ /Y. Liu, T. He, H. Chen, X. Wang, C. Luo, S. Zhang, C. Shen, L. Jin/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2021/.
\n$\cdot$ [http://arxiv.org/abs/1912.09629    arXiv][data/bibtex/IJCV2021Liuyl.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Exploring+the+Capacity+of+an+Orderless+Box+Discretization+Network+for+Multi-orientation+Scene+Text+Detection+Liu,+Yuliang+and+He,+Tong+and+Chen,+Hao+and+Wang,+Xinyu+and+Luo,+Canjie+and+Zhang,+Shuaitao+and+Shen,+Chunhua+and+Jin,+Lianwen google scholar][https://www.semanticscholar.org/search?q=Exploring+the+Capacity+of+an+Orderless+Box+Discretization+Network+for+Multi-orientation+Scene+Text+Detection semantic scholar][https://git.io/TextDet   project webpage]
. *Joint classification and regression for visual tracking with fully convolutional Siamese networks*   
\n$\cdot$ /Y. Cui, D. Guo, Y. Shao, Z. Wang, C. Shen, L. Zhang, S. Chen/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2021/.
\n$\cdot$ [data/bibtex/Cui2021Joint.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Joint+classification+and+regression+for+visual+tracking+with+fully+convolutional+{S}iamese+networks+Cui,+Ying+and+Guo,+Dongyan+and+Shao,+Yanyan+and+Wang,+Zhenhua+and+Shen,+Chunhua+and+Zhang,+Liyan+and+Chen,+Shengyong google scholar][https://www.semanticscholar.org/search?q=Joint+classification+and+regression+for+visual+tracking+with+fully+convolutional+{S}iamese+networks semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2105.11610.pdf"><img class="imgP  right"   src="data/thumbnail/Bian2021IJCVxxxarXiv.jpg"></a>}}*Unsupervised scale-consistent depth learning from video*   
\n$\cdot$ /J. Bian, H. Zhan, N. Wang, Z. Li, L. Zhang, C. Shen, M. Cheng, I. Reid/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2105.11610    arXiv][data/bibtex/Bian2021IJCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Unsupervised+Scale-consistent+Depth+Learning+from+Video+Bian,+Jia-Wang+and+Zhan,+Huangying+and+Wang,+Naiyan+and+Li,+Zhichao+and+Zhang,+Le+and+Shen,+Chunhua+and+Cheng,+Ming-Ming+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Unsupervised+Scale-consistent+Depth+Learning+from+Video semantic scholar][https://github.com/JiawangBian/SC-SfMLearner-Release   project webpage]
. *Learning discriminative region representation for person retrieval*   
\n$\cdot$ /Y. Zhao, X. Yu, Y. Gao, C. Shen/.
\n$\cdot$ /Pattern Recognition (PR), 2021/.
\n$\cdot$ [data/bibtex/Zhao2021PRLearning.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Discriminative+Region+Representation+for+Person+Retrieval+Zhao,+Yang+and+Yu,+Xiaohan+and+Gao,+Yongsheng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Learning+Discriminative+Region+Representation+for+Person+Retrieval semantic scholar]
. *Learning deep part-aware embedding for person retrieval*   
\n$\cdot$ /Y. Zhao, C. Shen, X. Yu, H. Chen, Y. Gao, S. Xiong/.
\n$\cdot$ /Pattern Recognition (PR), 2021/.
\n$\cdot$ [data/bibtex/Zhao2021PR1.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Deep+Part-Aware+Embedding+for+Person+Retrieval+Zhao,+Yang+and+Shen,+Chunhua+and+Yu,+Xiaohan+and+Chen,+Hao+and+Gao,+Yongsheng+and+Xiong,+Shengwu google scholar][https://www.semanticscholar.org/search?q=Learning+Deep+Part-Aware+Embedding+for+Person+Retrieval semantic scholar]
. *An adversarial human pose estimation network injected with graph structure*   
\n$\cdot$ /L. Tian, P. Wang, G. Liang, C. Shen/.
\n$\cdot$ /Pattern Recognition (PR), 2021/.
\n$\cdot$ [data/bibtex/Tian2021Adversarial.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=An+Adversarial+Human+Pose+Estimation+Network+Injected+with+Graph+Structure+Tian,+Lei+and+Wang,+Peng+and+Liang,+Guoqiang+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=An+Adversarial+Human+Pose+Estimation+Network+Injected+with+Graph+Structure semantic scholar]
. *Intra- and inter-pair consistency for semi-supervised gland segmentation*   
\n$\cdot$ /Y. Xie, J. Zhang, Z. Liao, J. Verjans, C. Shen, Y. Xia/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2021/.
\n$\cdot$ [data/bibtex/Xie2021Intra.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Intra-+and+Inter-pair+Consistency+for+Semi-supervised+Gland+Segmentation+Xie,+Yutong+and+Zhang,+Jianpeng+and+Liao,+Zhibin+and+Verjans,+Johan+and+Shen,+Chunhua+and+Xia,+Yong google scholar][https://www.semanticscholar.org/search?q=Intra-+and+Inter-pair+Consistency+for+Semi-supervised+Gland+Segmentation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Zhuang2021QuantizationxxxarXiv.jpg">}}*Effective training of convolutional neural networks with low-bitwidth weights and activations*   
\n$\cdot$ /B. Zhuang, J. Liu, M. Tan, L. Liu, I. Reid, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021/.
\n$\cdot$ [http://arxiv.org/abs/1908.04680    arXiv][data/bibtex/Zhuang2021Quantization.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Effective+Training+of+Convolutional+Neural+Networks+with+Low-bitwidth+Weights+and+Activations+Zhuang,+Bohan+and+Liu,+Jing+and+Tan,+Mingkui+and+Liu,+Lingqiao+and+Reid,+Ian+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Effective+Training+of+Convolutional+Neural+Networks+with+Low-bitwidth+Weights+and+Activations semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Yin2021PAMIvnxxxarXiv.jpg">}}*Virtual normal: enforcing geometric constraints for accurate and robust depth prediction*   
\n$\cdot$ /W. Yin, Y. Liu, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2103.04216    arXiv][data/bibtex/Yin2021PAMIvn.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Virtual+Normal:+Enforcing+Geometric+Constraints+for+Accurate+and+Robust+Depth+Prediction+Yin,+Wei+and+Liu,+Yifan+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Virtual+Normal:+Enforcing+Geometric+Constraints+for+Accurate+and+Robust+Depth+Prediction semantic scholar][https://git.io/Depth   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/WXL2021SOLOxxxarXiv.jpg">}}*SOLO: a simple framework for instance segmentation*   
\n$\cdot$ /X. Wang, R. Zhang, C. Shen, T. Kong, L. Li/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2106.15947    arXiv][data/bibtex/WXL2021SOLO.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SOLO}:+A+Simple+Framework+for+Instance+Segmentation+Wang,+Xinlong+and+Zhang,+Rufeng+and+Shen,+Chunhua+and+Kong,+Tao+and+Li,+Lei google scholar][https://www.semanticscholar.org/search?q={SOLO}:+A+Simple+Framework+for+Instance+Segmentation semantic scholar][https://git.io/AdelaiDet   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Wang2021PANplusxxxarXiv.jpg">}}*PAN\+\+: towards efficient and accurate end-to-end spotting of arbitrarily-shaped text*   
\n$\cdot$ /W. Wang, E. Xie, X. Li, X. Liu, D. Liang, Z. Yang, T. Lu, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2105.00405    arXiv][data/bibtex/Wang2021PANplus.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={PAN++}:+Towards+Efficient+and+Accurate+End-to-End+Spotting+of+Arbitrarily-Shaped+Text+Wang,+Wenhai+and+Xie,+Enze+and+Li,+Xiang+and+Liu,+Xuebo+and+Liang,+Ding+and+Yang,+Zhibo+and+Lu,+Tong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={PAN++}:+Towards+Efficient+and+Accurate+End-to-End+Spotting+of+Arbitrarily-Shaped+Text semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Li2021TextxxxarXiv.jpg">}}*Towards end-to-end text spotting in natural scenes*   
\n$\cdot$ /P. Wang, H. Li, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021/.
\n$\cdot$ [http://arxiv.org/abs/1906.06013    arXiv][data/bibtex/Li2021Text.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Towards+End-to-End+Text+Spotting+in+Natural+Scenes+Wang,+Peng+and+Li,+Hui+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Towards+End-to-End+Text+Spotting+in+Natural+Scenes semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Liu2021ABCNetv2xxxarXiv.jpg">}}*ABCNet v2: adaptive bezier-curve network for real-time end-to-end text spotting*   
\n$\cdot$ /Y. Liu, C. Shen, L. Jin, T. He, P. Chen, C. Liu, H. Chen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2105.03620    arXiv][data/bibtex/Liu2021ABCNetv2.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={ABCNet}+v2:+Adaptive+Bezier-Curve+Network+for+Real-time+End-to-end+Text+Spotting+Liu,+Yuliang+and+Shen,+Chunhua+and+Jin,+Lianwen+and+He,+Tong+and+Chen,+Peng+and+Liu,+Chongyu+and+Chen,+Hao google scholar][https://www.semanticscholar.org/search?q={ABCNet}+v2:+Adaptive+Bezier-Curve+Network+for+Real-time+End-to-end+Text+Spotting semantic scholar][https://git.io/AdelaiDet   project webpage]
. *Auto-rectify network for unsupervised indoor depth estimation*   
\n$\cdot$ /J. Bian, H. Zhan, N. Wang, T. Chin, C. Shen, I. Reid/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021/.
\n$\cdot$ [data/bibtex/Autorectify2021Bian.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Auto-Rectify+Network+for+Unsupervised+Indoor+Depth+Estimation+Bian,+Jia-Wang+and+Zhan,+Huangying+and+Wang,+Naiyan+and+Chin,+Tat-Jun+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Auto-Rectify+Network+for+Unsupervised+Indoor+Depth+Estimation semantic scholar]
== Conference
. *Diverse knowledge distillation for end-to-end person search*   
\n$\cdot$ /X. Zhang, X. Wang, J. Bian, C. Shen, M. You/.
\n$\cdot$ /Proc. AAAI Conference on Artificial Intelligence (AAAI'21), 2021/.
\n$\cdot$ [data/bibtex/ZhangPerson2021AAAI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Diverse+Knowledge+Distillation+for+End-to-end+Person+Search+Zhang,+Xinyu+and+Wang,+Xinlong+and+Bian,+Jia-Wang+and+Shen,+Chunhua+and+You,+Minyu google scholar][https://www.semanticscholar.org/search?q=Diverse+Knowledge+Distillation+for+End-to-end+Person+Search semantic scholar]
. *SA-BNN: state-aware binary neural network*   
\n$\cdot$ /C. Liu, P. Chen, B. Zhuang, C. Shen, B. Zhang, W. Ding/.
\n$\cdot$ /Proc. AAAI Conference on Artificial Intelligence (AAAI'21), 2021/.
\n$\cdot$ [data/bibtex/LiuBNN2021AAAI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SA-BNN}:+State-Aware+Binary+Neural+Network+Liu,+Chunlei+and+Chen,+Peng+and+Zhuang,+Bohan+and+Shen,+Chunhua+and+Zhang,+Baochang+and+Ding,+Wenrui google scholar][https://www.semanticscholar.org/search?q={SA-BNN}:+State-Aware+Binary+Neural+Network semantic scholar]
. *Deep reasoning network for few-shot semantic segmentation*   
\n$\cdot$ /Y. Zhuge, C. Shen/.
\n$\cdot$ /Proc. ACM International Conference on Multimedia (ACMMM'21), 2021/.
\n$\cdot$ [data/bibtex/MM2021B.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+Reasoning+Network+for+Few-shot+Semantic+Segmentation+Zhuge,+Yuzhi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Deep+Reasoning+Network+for+Few-shot+Semantic+Segmentation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/MM2021AxxxarXiv.jpg">}}*Fully quantized image super-resolution networks*   
\n$\cdot$ /H. Wang, P. Chen, B. Zhuang, C. Shen/.
\n$\cdot$ /Proc. ACM International Conference on Multimedia (ACMMM'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2011.14265    arXiv][data/bibtex/MM2021A.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fully+Quantized+Image+Super-Resolution+Networks+Wang,+Hu+and+Chen,+Peng+and+Zhuang,+Bohan+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Fully+Quantized+Image+Super-Resolution+Networks semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Zhang2021CVPR1xxxarXiv.jpg">}}*DoDNet: learning to segment multi-organ and tumors from multiple partially labeled datasets*   
\n$\cdot$ /J. Zhang, Y. Xie, Y. Xia, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2011.10217    arXiv][data/bibtex/Zhang2021CVPR1.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={DoDNet}:+Learning+to+segment+multi-organ+and+tumors+from+multiple+partially+labeled+datasets+Zhang,+Jianpeng+and+Xie,+Yutong+and+Xia,+Yong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={DoDNet}:+Learning+to+segment+multi-organ+and+tumors+from+multiple+partially+labeled+datasets semantic scholar][https://github.com/aim-uofa/partially-labelled   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Yin2021CVPR6xxxarXiv.jpg">}}*Learning to recover 3D scene shape from a single image*   
\n$\cdot$ /W. Yin, J. Zhang, O. Wang, S. Niklaus, L. Mai, S. Chen, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2012.09365    arXiv][data/bibtex/Yin2021CVPR6.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+to+Recover+{3D}+Scene+Shape+from+a+Single+Image+Yin,+Wei+and+Zhang,+Jianming+and+Wang,+Oliver+and+Niklaus,+Simon+and+Mai,+Long+and+Chen,+Simon+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Learning+to+Recover+{3D}+Scene+Shape+from+a+Single+Image semantic scholar][https://git.io/Depth   project webpage]
        .. Listed as one of the Best Paper Candidates, 32 out of about 6000 submissions.
. {{<img class="imgP  right"   src="data/thumbnail/Wang2021CVPR11xxxarXiv.jpg">}}*End-to-end video instance segmentation with Transformers*   
\n$\cdot$ /Y. Wang, Z. Xu, X. Wang, C. Shen, B. Cheng, H. Shen, H. Xia/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2011.14503    arXiv][data/bibtex/Wang2021CVPR11.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=End-to-End+Video+Instance+Segmentation+with+{T}ransformers+Wang,+Yuqing+and+Xu,+Zhaoliang+and+Wang,+Xinlong+and+Shen,+Chunhua+and+Cheng,+Baoshan+and+Shen,+Hao+and+Xia,+Huaxia google scholar][https://www.semanticscholar.org/search?q=End-to-End+Video+Instance+Segmentation+with+{T}ransformers semantic scholar]
        .. Oral presentation.
. {{<img class="imgP  right"   src="data/thumbnail/Wang2021CVPR13xxxarXiv.jpg">}}*Dense contrastive learning for self-supervised visual pre-training*   
\n$\cdot$ /X. Wang, R. Zhang, C. Shen, T. Kong, L. Li/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2011.09157    arXiv][data/bibtex/Wang2021CVPR13.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Dense+Contrastive+Learning+for+Self-Supervised+Visual+Pre-Training+Wang,+Xinlong+and+Zhang,+Rufeng+and+Shen,+Chunhua+and+Kong,+Tao+and+Li,+Lei google scholar][https://www.semanticscholar.org/search?q=Dense+Contrastive+Learning+for+Self-Supervised+Visual+Pre-Training semantic scholar][https://git.io/AdelaiDet   project webpage]
        .. Oral presentation.
. {{<img class="imgP  right"   src="data/thumbnail/Tian2021CVPR2xxxarXiv.jpg">}}*BoxInst: high-performance instance segmentation with box annotations*   
\n$\cdot$ /Z. Tian, C. Shen, X. Wang, H. Chen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2012.02310    arXiv][data/bibtex/Tian2021CVPR2.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={BoxInst}:+High-Performance+Instance+Segmentation+with+Box+Annotations+Tian,+Zhi+and+Shen,+Chunhua+and+Wang,+Xinlong+and+Chen,+Hao google scholar][https://www.semanticscholar.org/search?q={BoxInst}:+High-Performance+Instance+Segmentation+with+Box+Annotations semantic scholar][https://git.io/AdelaiDet   project webpage]
. *Learning spatial-semantic relationship for facial attribute recognition with limited labeled data*   
\n$\cdot$ /Y. Shu, Y. Yan, S. Chen, J. Xue, C. Shen, H. Wang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [data/bibtex/Shu2021CVPR10.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Spatial-Semantic+Relationship+for+Facial+Attribute+Recognition+with+Limited+Labeled+Data+Shu,+Ying+and+Yan,+Yan+and+Chen,+Si+and+Xue,+Jing-Hao+and+Shen,+Chunhua+and+Wang,+Hanzi google scholar][https://www.semanticscholar.org/search?q=Learning+Spatial-Semantic+Relationship+for+Facial+Attribute+Recognition+with+Limited+Labeled+Data semantic scholar]
. *Feature decomposition and reconstruction learning for effective facial expression recognition*   
\n$\cdot$ /D. Ruan, Y. Yan, S. Lai, Z. Chai, C. Shen, H. Wang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [data/bibtex/Ruan2021CVPR9.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Feature+Decomposition+and+Reconstruction+Learning+for+Effective+Facial+Expression+Recognition+Ruan,+Delian+and+Yan,+Yan+and+Lai,+Shenqi+and+Chai,+Zhenhua+and+Shen,+Chunhua+and+Wang,+Hanzi google scholar][https://www.semanticscholar.org/search?q=Feature+Decomposition+and+Reconstruction+Learning+for+Effective+Facial+Expression+Recognition semantic scholar]
. *FCPose: fully convolutional multi-person pose estimation with dynamic instance-aware convolutions*   
\n$\cdot$ /W. Mao, Z. Tian, X. Wang, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [data/bibtex/Mao2021CVPR4.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={FCPose}:+Fully+Convolutional+Multi-Person+Pose+Estimation+with+Dynamic+Instance-Aware+Convolutions+Mao,+Weian+and+Tian,+Zhi+and+Wang,+Xinlong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={FCPose}:+Fully+Convolutional+Multi-Person+Pose+Estimation+with+Dynamic+Instance-Aware+Convolutions semantic scholar][https://git.io/AdelaiDet   project webpage]
. *Generic perceptual loss for modelling structured output dependencies*   
\n$\cdot$ /Y. Liu, W. Yin, Y. Chen, H. Chen, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [data/bibtex/Liu2021CVPR5.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Generic+Perceptual+Loss+for+Modelling+Structured+Output+Dependencies+Liu,+Yifan+and+Yin,+Wei+and+Chen,+Yu+and+Chen,+Hao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Generic+Perceptual+Loss+for+Modelling+Structured+Output+Dependencies semantic scholar]
. *HCRF-Flow: scene flow from point clouds with continuous high-order CRFs and position-aware flow embedding*   
\n$\cdot$ /R. Li, G. Lin, T. He, F. Liu, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [data/bibtex/Li2021CVPR12.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={HCRF-Flow}:+Scene+Flow+from+Point+Clouds+with+Continuous+High-order+{CRFs}+and+Position-aware+Flow+Embedding+Li,+Ruibo+and+Lin,+Guosheng+and+He,+Tong+and+Liu,+Fayao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={HCRF-Flow}:+Scene+Flow+from+Point+Clouds+with+Continuous+High-order+{CRFs}+and+Position-aware+Flow+Embedding semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/He2021CVPR7xxxarXiv.jpg">}}*DyCo3D: robust instance segmentation of 3d point clouds through dynamic convolution*   
\n$\cdot$ /T. He, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2011.13328    arXiv][data/bibtex/He2021CVPR7.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={DyCo3D}:+Robust+Instance+Segmentation+of+3D+Point+Clouds+through+Dynamic+Convolution+He,+Tong+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q={DyCo3D}:+Robust+Instance+Segmentation+of+3D+Point+Clouds+through+Dynamic+Convolution semantic scholar][https://git.io/DyCo3D   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2011.11204.pdf"><img class="imgP  right"   src="data/thumbnail/Guo2021CVPR14xxxarXiv.jpg"></a>}}*Graph attention tracking*   
\n$\cdot$ /D. Guo, Y. Shao, Y. Cui, Z. Wang, L. Zhang, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2011.11204    arXiv][data/bibtex/Guo2021CVPR14.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Graph+Attention+Tracking+Guo,+Dongyan+and+Shao,+Yanyan+and+Cui,+Ying+and+Wang,+Zhenhua+and+Zhang,+Liyan+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Graph+Attention+Tracking semantic scholar][https://git.io/SiamGAT   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2011.14288.pdf"><img class="imgP  right"   src="data/thumbnail/Dai2021CVPR8xxxarXiv.jpg"></a>}}*Learning affinity-aware upsampling for deep image matting*   
\n$\cdot$ /Y. Dai, H. Lu, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2011.14288    arXiv][data/bibtex/Dai2021CVPR8.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Affinity-Aware+Upsampling+for+Deep+Image+Matting+Dai,+Yutong+and+Lu,+Hao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Learning+Affinity-Aware+Upsampling+for+Deep+Image+Matting semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2007.06919.pdf"><img class="imgP  right"   src="data/thumbnail/Chen2021CVPR3xxxarXiv.jpg"></a>}}*AQD: towards accurate quantized object detection*   
\n$\cdot$ /P. Chen, J. Liu, B. Zhuang, M. Tan, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2007.06919    arXiv][data/bibtex/Chen2021CVPR3.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={AQD}:+Towards+Accurate+Quantized+Object+Detection+Chen,+Peng+and+Liu,+Jing+and+Zhuang,+Bohan+and+Tan,+Mingkui+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={AQD}:+Towards+Accurate+Quantized+Object+Detection semantic scholar]
        .. Oral presentation.
. {{<img class="imgP  right"   src="data/thumbnail/Chizhang2021ICCVMetaxxxarXiv.jpg">}}*Meta navigator: search for a good adaptation policy for few-shot learning*   
\n$\cdot$ /C. Zhang, H. Ding, G. Lin, R. Li, C. Wang, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2109.05749    arXiv][data/bibtex/Chizhang2021ICCVMeta.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Meta+Navigator:+Search+for+a+Good+Adaptation+Policy+for+Few-shot+Learning+Zhang,+Chi+and+Ding,+Henghui+and+Lin,+Guosheng+and+Li,+Ruibo+and+Wang,+Changhu+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Meta+Navigator:+Search+for+a+Good+Adaptation+Policy+for+Few-shot+Learning semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Yuan2021ICCVSimplexxxarXiv.jpg">}}*A simple baseline for semi-supervised semantic segmentation with strong data augmentation*   
\n$\cdot$ /J. Yuan, Y. Liu, C. Shen, Z. Wang, H. Li/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2104.07256    arXiv][data/bibtex/Yuan2021ICCVSimple.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Simple+Baseline+for+Semi-supervised+Semantic+Segmentation+with+Strong+Data+Augmentation+Yuan,+Jianlong+and+Liu,+Yifan+and+Shen,+Chunhua+and+Wang,+Zhibin+and+Li,+Hao google scholar][https://www.semanticscholar.org/search?q=A+Simple+Baseline+for+Semi-supervised+Semantic+Segmentation+with+Strong+Data+Augmentation semantic scholar]
. *BV-Person: a large-scale dataset for bird-view person re-identification*   
\n$\cdot$ /C. Yan, G. Pang, L. Wang, J. Jiao, X. Feng, C. Shen, J. Li/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'21), 2021/.
\n$\cdot$ [data/bibtex/Yan2021ICCVBVPerson.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={BV-Person}:+A+Large-scale+Dataset+for+Bird-view+Person+Re-identification+Yan,+Cheng+and+Pang,+Guansong+and+Wang,+Lei+and+Jiao,+Jile+and+Feng,+Xuetao+and+Shen,+Chunhua+and+Li,+Jingjing google scholar][https://www.semanticscholar.org/search?q={BV-Person}:+A+Large-scale+Dataset+for+Bird-view+Person+Re-identification semantic scholar]
. *Occluded person re-identification with single-scale global representations*   
\n$\cdot$ /C. Yan, G. Pang, J. Jiao, X. Bai, X. Feng, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'21), 2021/.
\n$\cdot$ [data/bibtex/Yan2021ICCVOccl.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Occluded+Person+Re-Identification+with+Single-scale+Global+Representations+Yan,+Cheng+and+Pang,+Guansong+and+Jiao,+Jile+and+Bai,+Xiao+and+Feng,+Xuetao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Occluded+Person+Re-Identification+with+Single-scale+Global+Representations semantic scholar]
        .. Oral presentation.
. {{<img class="imgP  right"   src="data/thumbnail/Shu2021ICCVKDxxxarXiv.jpg">}}*Channel-wise knowledge distillation for dense prediction*   
\n$\cdot$ /C. Shu, Y. Liu, J. Gao, L. Xu, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2011.13256    arXiv][data/bibtex/Shu2021ICCVKD.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Channel-wise+Knowledge+Distillation+for+Dense+Prediction+Shu,+Changyong+and+Liu,+Yifan+and+Gao,+Jianfei+and+Xu,+Lin+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Channel-wise+Knowledge+Distillation+for+Dense+Prediction semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2008.05101.pdf"><img class="imgP  right"   src="data/thumbnail/Chen2021ICCVxxxarXiv.jpg"></a>}}*FATNN: fast and accurate ternary neural networks*   
\n$\cdot$ /P. Chen, B. Zhuang, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2008.05101    arXiv][data/bibtex/Chen2021ICCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={FATNN}:+Fast+and+Accurate+Ternary+Neural+Networks+Chen,+Peng+and+Zhuang,+Bohan+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={FATNN}:+Fast+and+Accurate+Ternary+Neural+Networks semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Kong2021ICRAxxxarXiv.jpg">}}*FastFlowNet: a lightweight network for fast optical flow estimation*   
\n$\cdot$ /L. Kong, C. Shen, J. Yang/.
\n$\cdot$ /Proc. International Conference on Robotics and Automation (ICRA'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2103.04524    arXiv][data/bibtex/Kong2021ICRA.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={FastFlowNet}:+A+Lightweight+Network+for+Fast+Optical+Flow+Estimation+Kong,+Lingtong+and+Shen,+Chunhua+and+Yang,+Jie google scholar][https://www.semanticscholar.org/search?q={FastFlowNet}:+A+Lightweight+Network+for+Fast+Optical+Flow+Estimation semantic scholar][https://git.io/fastflow   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Pang2021KDDxxxarXiv.jpg">}}*Toward deep supervised anomaly detection: reinforcement learning from partially labeled anomaly data*   
\n$\cdot$ /G. Pang, A. van den Hengel, C. Shen, L. Cao/.
\n$\cdot$ /Proc. ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2009.06847    arXiv][data/bibtex/Pang2021KDD.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Toward+Deep+Supervised+Anomaly+Detection:+Reinforcement+Learning+from+Partially+Labeled+Anomaly+Data+Pang,+Guansong+and+{van+den+Hengel},+Anton+and+Shen,+Chunhua+and+Cao,+Longbing google scholar][https://www.semanticscholar.org/search?q=Toward+Deep+Supervised+Anomaly+Detection:+Reinforcement+Learning+from+Partially+Labeled+Anomaly+Data semantic scholar]
. *CoTr: efficient 3D medical image segmentation by bridging CNN and transformer*   
\n$\cdot$ /Y. Xie, J. Zhang, C. Shen, Y. Xia/.
\n$\cdot$ /Proc. International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI'21), 2021/.
\n$\cdot$ [data/bibtex/YXie2021MICCAI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={CoTr}:+Efficient+{3D}+Medical+Image+Segmentation+by+bridging+{CNN}+and+Transformer+Xie,+Yutong+and+Zhang,+Jianpeng+and+Shen,+Chunhua+and+Xia,+Yong google scholar][https://www.semanticscholar.org/search?q={CoTr}:+Efficient+{3D}+Medical+Image+Segmentation+by+bridging+{CNN}+and+Transformer semantic scholar][https://github.com/YtongXie/CoTr   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/DNRD2021ZhangxxxarXiv.jpg">}}*Dynamic neural representational decoders for high-resolution semantic segmentation*   
\n$\cdot$ /B. Zhang, Y. Liu, Z. Tian, C. Shen/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2107.14428    arXiv][data/bibtex/DNRD2021Zhang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Dynamic+Neural+Representational+Decoders+for+High-Resolution+Semantic+Segmentation+Zhang,+Bowen+and+Liu,+Yifan+and+Tian,+Zhi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Dynamic+Neural+Representational+Decoders+for+High-Resolution+Semantic+Segmentation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Twins2021ChuxxxarXiv.jpg">}}*Twins: revisiting the design of spatial attention in vision transformers*   
\n$\cdot$ /X. Chu, Z. Tian, Y. Wang, B. Zhang, H. Ren, X. Wei, H. Xia, C. Shen/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'21), 2021/.
\n$\cdot$ [http://arxiv.org/abs/2104.13840    arXiv][data/bibtex/Twins2021Chu.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Twins:+Revisiting+the+Design+of+Spatial+Attention+in+Vision+Transformers+Chu,+Xiangxiang+and+Tian,+Zhi+and+Wang,+Yuqing+and+Zhang,+Bo+and+Ren,+Haibing+and+Wei,+Xiaolin+and+Xia,+Huaxia+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Twins:+Revisiting+the+Design+of+Spatial+Attention+in+Vision+Transformers semantic scholar][https://github.com/Meituan-AutoML/Twins   project webpage]

= 2020
== Journal
. {{<img class="imgP  right"   src="data/thumbnail/Pan2020ACMSurveyxxxarXiv.jpg">}}*Deep learning for anomaly detection: a review*   
\n$\cdot$ /G. Pang, C. Shen, L. Cao, A. van den Hengel/.
\n$\cdot$ /ACM Computing Surveys (ACMSurvey), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2007.02500    arXiv][data/bibtex/Pan2020ACMSurvey.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+Learning+for+Anomaly+Detection:+A+Review+Pang,+Guansong+and+Shen,+Chunhua+and+Cao,+Longbing+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Deep+Learning+for+Anomaly+Detection:+A+Review semantic scholar]
. *Towards light-weight portrait matting via parameter sharing*   
\n$\cdot$ /Y. Dai, H. Lu, C. Shen/.
\n$\cdot$ /Computer Graphics Forum (CGF), 2020/.
\n$\cdot$ [data/bibtex/Daiyt2020.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Towards+Light-Weight+Portrait+Matting+via+Parameter+Sharing+Dai,+Yutong+and+Lu,+Hao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Towards+Light-Weight+Portrait+Matting+via+Parameter+Sharing semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Luo2020IJCVxxxarXiv.jpg">}}*Separating content from style using adversarial learning for recognizing text in the wild*   
\n$\cdot$ /C. Luo, Q. Lin, Y. Liu, L. Jin, C. Shen/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2001.04189    arXiv][data/bibtex/Luo2020IJCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Separating+Content+from+Style+Using+Adversarial+Learning+for+Recognizing+Text+in+the+Wild+Luo,+Canjie+and+Lin,+Qingxiang+and+Liu,+Yuliang+and+Jin,+Lianwen+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Separating+Content+from+Style+Using+Adversarial+Learning+for+Recognizing+Text+in+the+Wild semantic scholar]
. *TasselNetv2: in-field counting of wheat spikes with context-augmented local regression networks*   
\n$\cdot$ /H. Xiong, Z. Cao, H. Lu, S. Madec, L. Liu, C. Shen/.
\n$\cdot$ /Plant Methods (PLME), 2020/.
\n$\cdot$ [data/bibtex/TasselNet2020.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={TasselNetv2}:+in-field+counting+of+wheat+spikes+with+context-augmented+local+regression+networks+Xiong,+Haipeng+and+Cao,+Zhiguo+and+Lu,+Hao+and+Madec,+Simon+and+Liu,+Liang+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={TasselNetv2}:+in-field+counting+of+wheat+spikes+with+context-augmented+local+regression+networks semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/MobileFAN2020xxxarXiv.jpg">}}*MobileFAN: transferring deep hidden representation for face alignment*   
\n$\cdot$ /Y. Zhao, Y. Liu, C. Shen, Y. Gao, S. Xiong/.
\n$\cdot$ /Pattern Recognition (PR), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1908.03839    arXiv][data/bibtex/MobileFAN2020.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={MobileFAN}:+Transferring+Deep+Hidden+Representation+for+Face+Alignment+Zhao,+Yang+and+Liu,+Yifan+and+Shen,+Chunhua+and+Gao,+Yongsheng+and+Xiong,+Shengwu google scholar][https://www.semanticscholar.org/search?q={MobileFAN}:+Transferring+Deep+Hidden+Representation+for+Face+Alignment semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Zhangx2020T-ITSxxxarXiv.jpg">}}*Part-guided attention learning for vehicle instance retrieval*   
\n$\cdot$ /X. Zhang, R. Zhang, J. Cao, D. Gong, M. You, C. Shen/.
\n$\cdot$ /IEEE Transactions on Intelligent Transportation Systems (T-ITS), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1909.06023    arXiv][data/bibtex/Zhangx2020T-ITS.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Part-Guided+Attention+Learning+for+Vehicle+Instance+Retrieval+Zhang,+Xinyu+and+Zhang,+Rufeng+and+Cao,+Jiewei+and+Gong,+Dong+and+You,+Mingyu+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Part-Guided+Attention+Learning+for+Vehicle+Instance+Retrieval semantic scholar]
. *A robust attentional framework for license plate recognition in the wild*   
\n$\cdot$ /L. Zhang, P. Wang, H. Li, Z. Li, C. Shen, Y. Zhang/.
\n$\cdot$ /IEEE Transactions on Intelligent Transportation Systems (T-ITS), 2020/.
\n$\cdot$ [data/bibtex/Li2020Carlicense.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+robust+attentional+framework+for+license+plate+recognition+in+the+wild+Zhang,+Linjiang+and+Wang,+Peng+and+Li,+Hui+and+Li,+Zhen+and+Shen,+Chunhua+and+Zhang,+Yanning google scholar][https://www.semanticscholar.org/search?q=A+robust+attentional+framework+for+license+plate+recognition+in+the+wild semantic scholar]
. *Real-time high-performance semantic image segmentation of urban street scenes*   
\n$\cdot$ /G. Dong, Y. Yan, C. Shen, H. Wang/.
\n$\cdot$ /IEEE Transactions on Intelligent Transportation Systems (T-ITS), 2020/.
\n$\cdot$ [data/bibtex/Dong2020segmentation.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Real-time+high-performance+semantic+image+segmentation+of+urban+street+scenes+Dong,+Genshun+and+Yan,+Yan+and+Shen,+Chunhua+and+Wang,+Hanzi google scholar][https://www.semanticscholar.org/search?q=Real-time+high-performance+semantic+image+segmentation+of+urban+street+scenes semantic scholar]
. *Towards effective deep embedding for zero-shot learning*   
\n$\cdot$ /L. Zhang, P. Wang, L. Liu, C. Shen, W. Wei, Y. Zhang, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2020/.
\n$\cdot$ [data/bibtex/Zhang2020Zeroshot.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Towards+Effective+Deep+Embedding+for+Zero-Shot+Learning+Zhang,+Lei+and+Wang,+Peng+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+Wei,+Wei+and+Zhang,+Yanning+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Towards+Effective+Deep+Embedding+for+Zero-Shot+Learning semantic scholar]
. *NSSNet: scale-aware object counting with non-scale suppression*   
\n$\cdot$ /L. Liu, Z. Cao, H. Lu, H. Xiong, C. Shen/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2020/.
\n$\cdot$ [data/bibtex/LiuL2020CSVT.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={NSSNet}:+Scale-aware+object+counting+with+non-scale+suppression+Liu,+Liang+and+Cao,+Zhiguo+and+Lu,+Hao+and+Xiong,+Haipeng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={NSSNet}:+Scale-aware+object+counting+with+non-scale+suppression semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Zhang2020CovidxxxarXiv.jpg">}}*Viral pneumonia screening on chest x-ray images using confidence-aware anomaly detection*   
\n$\cdot$ /J. Zhang, Y. Xie, Z. Liao, G. Pang, J. Verjans, W. Li, Z. Sun, J. He, Y. Li, C. Shen, Y. Xia/.
\n$\cdot$ /IEEE Transactions on Medical Imaging (TMI), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2003.12338    arXiv][data/bibtex/Zhang2020Covid.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Viral+Pneumonia+Screening+on+Chest+X-ray+Images+Using+Confidence-Aware+Anomaly+Detection+Zhang,+Jianpeng+and+Xie,+Yutong+and+Liao,+Zhibin+and+Pang,+Guansong+and+Verjans,+Johan+and+Li,+Wenxin+and+Sun,+Zongji+and+He,+Jian+and+Li,+Yi+and+Shen,+Chunhua+and+Xia,+Yong google scholar][https://www.semanticscholar.org/search?q=Viral+Pneumonia+Screening+on+Chest+X-ray+Images+Using+Confidence-Aware+Anomaly+Detection semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Xie2020TMIaxxxarXiv.jpg">}}*A mutual bootstrapping model for automated skin lesion segmentation and classification*   
\n$\cdot$ /Y. Xie, J. Zhang, Y. Xia, C. Shen/.
\n$\cdot$ /IEEE Transactions on Medical Imaging (TMI), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1903.03313    arXiv][data/bibtex/Xie2020TMIa.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Mutual+Bootstrapping+Model+for+Automated+Skin+Lesion+Segmentation+and+Classification+Xie,+Yutong+and+Zhang,+Jianpeng+and+Xia,+Yong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=A+Mutual+Bootstrapping+Model+for+Automated+Skin+Lesion+Segmentation+and+Classification semantic scholar]
. *SESV: accurate medical image segmentation by predicting and correcting errors*   
\n$\cdot$ /Y. Xie, J. Zhang, H. Lu, C. Shen, Y. Xia/.
\n$\cdot$ /IEEE Transactions on Medical Imaging (TMI), 2020/.
\n$\cdot$ [data/bibtex/Xie2020TMIb.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SESV}:+Accurate+Medical+Image+Segmentation+by+Predicting+and+Correcting+Errors+Xie,+Yutong+and+Zhang,+Jianpeng+and+Lu,+Hao+and+Shen,+Chunhua+and+Xia,+Yong google scholar][https://www.semanticscholar.org/search?q={SESV}:+Accurate+Medical+Image+Segmentation+by+Predicting+and+Correcting+Errors semantic scholar]
. *OPMP: an omni-directional pyramid mask proposal network for arbitrary-shape scene text detection*   
\n$\cdot$ /S. Zhang, Y. Liu, L. Jin, Z. Wei, C. Shen/.
\n$\cdot$ /IEEE Transactions on Multimedia (TMM), 2020/.
\n$\cdot$ [data/bibtex/ShengZhang2020TMM.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={OPMP}:+An+Omni-directional+Pyramid+Mask+Proposal+Network+for+Arbitrary-shape+Scene+Text+Detection+Zhang,+Sheng+and+Liu,+Yuliang+and+Jin,+Lianwen+and+Wei,+Zhongrong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={OPMP}:+An+Omni-directional+Pyramid+Mask+Proposal+Network+for+Arbitrary-shape+Scene+Text+Detection semantic scholar]
. *Joint deep learning of facial expression synthesis and recognition*   
\n$\cdot$ /Y. Yan, Y. Huang, S. Chen, C. Shen, H. Wang/.
\n$\cdot$ /IEEE Transactions on Multimedia (TMM), 2020/.
\n$\cdot$ [data/bibtex/Yan2020TMM.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Joint+deep+learning+of+facial+expression+synthesis+and+recognition+Yan,+Yan+and+Huang,+Ying+and+Chen,+Si+and+Shen,+Chunhua+and+Wang,+Hanzi google scholar][https://www.semanticscholar.org/search?q=Joint+deep+learning+of+facial+expression+synthesis+and+recognition semantic scholar]
. *Accurate tensor completion via adaptive low-rank representation*   
\n$\cdot$ /L. Zhang, W. Wei, Q. Shi, C. Shen, A. van den Hengel, Y. Zhang/.
\n$\cdot$ /IEEE Transactions on Neural Networks and Learning Systems (TNN), 2020/.
\n$\cdot$ [data/bibtex/Zhang2020TNNLS.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Accurate+Tensor+Completion+via+Adaptive+Low-Rank+Representation+Zhang,+Lei+and+Wei,+Wei+and+Shi,+Qinfeng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Zhang,+Yanning google scholar][https://www.semanticscholar.org/search?q=Accurate+Tensor+Completion+via+Adaptive+Low-Rank+Representation semantic scholar]
. *Deep clustering with sample-assignment invariance prior*   
\n$\cdot$ /X. Peng, H. Zhu, J. Feng, C. Shen, H. Zhang, J. Zhou/.
\n$\cdot$ /IEEE Transactions on Neural Networks and Learning Systems (TNN), 2020/.
\n$\cdot$ [data/bibtex/Peng2020TNNLS.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+Clustering+with+Sample-Assignment+Invariance+Prior+Peng,+Xi+and+Zhu,+Hongyuan+and+Feng,+Jiashi+and+Shen,+Chunhua+and+Zhang,+Haixian+and+Zhou,+Joey google scholar][https://www.semanticscholar.org/search?q=Deep+Clustering+with+Sample-Assignment+Invariance+Prior semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Gong2020TNNLSxxxarXiv.jpg">}}*Learning deep gradient descent optimization for image deconvolution*   
\n$\cdot$ /D. Gong, Z. Zhang, Q. Shi, A. van den Hengel, C. Shen, Y. Zhang/.
\n$\cdot$ /IEEE Transactions on Neural Networks and Learning Systems (TNN), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1804.03368    arXiv][data/bibtex/Gong2020TNNLS.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Deep+Gradient+Descent+Optimization+for+Image+Deconvolution+Gong,+Dong+and+Zhang,+Zhen+and+Shi,+Qinfeng+and+{van+den+Hengel},+Anton+and+Shen,+Chunhua+and+Zhang,+Yanning google scholar][https://www.semanticscholar.org/search?q=Learning+Deep+Gradient+Descent+Optimization+for+Image+Deconvolution semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Liu2020TOGxxxarXiv.jpg">}}*Real-time image smoothing via iterative least squares*   
\n$\cdot$ /W. Liu, P. Zhang, X. Huang, J. Yang, C. Shen, I. Reid/.
\n$\cdot$ /ACM Transactions on Graphics (TOG), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2003.07504    arXiv][https://doi.org/10.1145/3388887  link][data/bibtex/Liu2020TOG.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Real-time+image+smoothing+via+iterative+least+squares+Liu,+Wei+and+Zhang,+Pingping+and+Huang,+Xiaolin+and+Yang,+Jie+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Real-time+image+smoothing+via+iterative+least+squares semantic scholar][https://github.com/wliusjtu/Real-time-Image-Smoothing-via-Iterative-Least-Squares   project webpage]
. *Plenty is plague: fine-grained learning for visual question answering*   
\n$\cdot$ /Y. Zhou, R. Ji, J. Su, X. Sun, D. Meng, Y. Gao, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020/.
\n$\cdot$ [https://doi.org/10.1109/TPAMI.2019.2956699  link][data/bibtex/Zhou2020TPAMIZhou.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Plenty+Is+Plague:+Fine-Grained+Learning+for+Visual+Question+Answering+Zhou,+Yiyi+and+Ji,+Rongrong+and+Su,+Jinsong+and+Sun,+Xiaoshuai+and+Meng,+Deyu+and+Gao,+Yue+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Plenty+Is+Plague:+Fine-Grained+Learning+for+Visual+Question+Answering semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Zhang2020OrderlessReIDxxxarXiv.jpg">}}*Ordered or orderless: a revisit for video based person re-identification*   
\n$\cdot$ /L. Zhang, Z. Shi, J. Zhou, M. Cheng, Y. Liu, J. Bian, Z. Zeng, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1912.11236    arXiv][https://doi.org/10.1109/TPAMI.2020.2976969  link][data/bibtex/Zhang2020OrderlessReID.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Ordered+or+Orderless:+A+Revisit+for+Video+based+Person+Re-Identification+Zhang,+Le+and+Shi,+Zenglin+and+Zhou,+Joey+Tianyi+and+Cheng,+Ming-Ming+and+Liu,+Yun+and+Bian,+Jia-Wang+and+Zeng,+Zeng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Ordered+or+Orderless:+A+Revisit+for+Video+based+Person+Re-Identification semantic scholar][https://github.com/ZhangLeUestc/VideoReid-TPAMI2020   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Lu2020PAMIIndexNetxxxarXiv.jpg">}}*Index networks*   
\n$\cdot$ /H. Lu, Y. Dai, C. Shen, S. Xu/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1908.09895    arXiv][https://doi.org/10.1109/TPAMI.2020.3004474  link][data/bibtex/Lu2020PAMIIndexNet.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Index+Networks+Lu,+Hao+and+Dai,+Yutong+and+Shen,+Chunhua+and+Xu,+Songcen google scholar][https://www.semanticscholar.org/search?q=Index+Networks semantic scholar][https://git.io/IndexNet   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Liu2020PAMIxxxarXiv.jpg">}}*Structured knowledge distillation for dense prediction*   
\n$\cdot$ /Y. Liu, C. Shun, J. Wang, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1903.04197    arXiv][https://ieeexplore.ieee.org/document/9115859  link][data/bibtex/Liu2020PAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Structured+Knowledge+Distillation+for+Dense+Prediction+Liu,+Yifan+and+Shun,+Changyong+and+Wang,+Jingdong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Structured+Knowledge+Distillation+for+Dense+Prediction semantic scholar][https://github.com/irfanICMLL/structure_knowledge_distillation   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1711.00253.pdf"><img class="imgP  right"   src="data/thumbnail/Chen2019PAMIxxxarXiv.jpg"></a>}}*Adversarial learning of structure-aware fully convolutional networks for landmark localization*   
\n$\cdot$ /Y. Chen, C. Shen, H. Chen, X. Wei, L. Liu, J. Yang/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1711.00253    arXiv][https://doi.org/10.1109/TPAMI.2019.2901875  link][data/bibtex/Chen2019PAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Adversarial+Learning+of+Structure-Aware+Fully+Convolutional+Networks+for+Landmark+Localization+Chen,+Yu+and+Shen,+Chunhua+and+Chen,+Hao+and+Wei,+Xiu-Shen+and+Liu,+Lingqiao+and+Yang,+Jian google scholar][https://www.semanticscholar.org/search?q=Adversarial+Learning+of+Structure-Aware+Fully+Convolutional+Networks+for+Landmark+Localization semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2008.00942.pdf"><img class="imgP  right"   src="data/thumbnail/Cao2020GANxxxarXiv.jpg"></a>}}*Improving generative adversarial networks with local coordinate coding*   
\n$\cdot$ /J. Cao, Y. Guo, Q. Wu, C. Shen, J. Huang, M. Tan/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2008.00942    arXiv][data/bibtex/Cao2020GAN.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Improving+Generative+Adversarial+Networks+with+Local+Coordinate+Coding+Cao,+Jiezhang+and+Guo,+Yong+and+Wu,+Qingyao+and+Shen,+Chunhua+and+Huang,+Junzhou+and+Tan,+Mingkui google scholar][https://www.semanticscholar.org/search?q=Improving+Generative+Adversarial+Networks+with+Local+Coordinate+Coding semantic scholar][https://github.com/SCUTjinchengli/LCCGAN-v2   project webpage]
== Conference
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1909.07701.pdf"><img class="imgP  right"   src="data/thumbnail/AAAI20WangxxxarXiv.jpg"></a>}}*Task-aware monocular depth estimation for 3D object detection*   
\n$\cdot$ /X. Wang, W. Yin, T. Kong, Y. Jiang, L. Li, C. Shen/.
\n$\cdot$ /Proc. AAAI Conference on Artificial Intelligence (AAAI'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1909.07701    arXiv][data/bibtex/AAAI20Wang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Task-Aware+Monocular+Depth+Estimation+for+{3D}+Object+Detection+Wang,+Xinlong+and+Yin,+Wei+and+Kong,+Tao+and+Jiang,+Yuning+and+Li,+Lei+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Task-Aware+Monocular+Depth+Estimation+for+{3D}+Object+Detection semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1907.12271.pdf"><img class="imgP  right"   src="data/thumbnail/AAAI20TeneyxxxarXiv.jpg"></a>}}*V-PROM: a benchmark for visual reasoning using visual progressive matrices*   
\n$\cdot$ /D. Teney, P. Wang, J. Cao, L. Liu, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. AAAI Conference on Artificial Intelligence (AAAI'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1907.12271    arXiv][data/bibtex/AAAI20Teney.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={V-PROM}:+A+Benchmark+for+Visual+Reasoning+Using+Visual+Progressive+Matrices+Teney,+Damien+and+Wang,+Peng+and+Cao,+Jiewei+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q={V-PROM}:+A+Benchmark+for+Visual+Reasoning+Using+Visual+Progressive+Matrices semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1903.11236.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2020Zhuang5xxxarXiv.jpg"></a>}}*Training quantized neural networks with a full-precision auxiliary module*   
\n$\cdot$ /B. Zhuang, L. Liu, M. Tan, C. Shen, I. Reid/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1903.11236    arXiv][data/bibtex/CVPR2020Zhuang5.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Training+Quantized+Neural+Networks+with+a+Full-precision+Auxiliary+Module+Zhuang,+Bohan+and+Liu,+Lingqiao+and+Tan,+Mingkui+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Training+Quantized+Neural+Networks+with+a+Full-precision+Auxiliary+Module semantic scholar]
        .. Oral presentation.
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2003.11712.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2020Zhang3xxxarXiv.jpg"></a>}}*Mask encoding for single shot instance segmentation*   
\n$\cdot$ /R. Zhang, Z. Tian, C. Shen, M. You, Y. Yan/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2003.11712    arXiv][data/bibtex/CVPR2020Zhang3.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Mask+Encoding+for+Single+Shot+Instance+Segmentation+Zhang,+Rufeng+and+Tian,+Zhi+and+Shen,+Chunhua+and+You,+Mingyu+and+Yan,+Youliang google scholar][https://www.semanticscholar.org/search?q=Mask+Encoding+for+Single+Shot+Instance+Segmentation semantic scholar][https://github.com/aim-uofa/AdelaiDet/   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1909.08228.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2020NAS11xxxarXiv.jpg"></a>}}*Memory-efficient hierarchical neural architecture search for image denoising*   
\n$\cdot$ /H. Zhang, Y. Li, H. Chen, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1909.08228    arXiv][data/bibtex/CVPR2020NAS11.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Memory-Efficient+Hierarchical+Neural+Architecture+Search+for+Image+Denoising+Zhang,+Haokui+and+Li,+Ying+and+Chen,+Hao+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Memory-Efficient+Hierarchical+Neural+Architecture+Search+for+Image+Denoising semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2003.06777.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2020EMD9xxxarXiv.jpg"></a>}}*DeepEMD: few-shot image classification with differentiable earth mover's distance and structured classifiers*   
\n$\cdot$ /C. Zhang, Y. Cai, G. Lin, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2003.06777    arXiv][data/bibtex/CVPR2020EMD9.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={DeepEMD}:+Few-Shot+Image+Classification+with+Differentiable+Earth+Mover's+Distance+and+Structured+Classifiers+Zhang,+Chi+and+Cai,+Yujun+and+Lin,+Guosheng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={DeepEMD}:+Few-Shot+Image+Classification+with+Differentiable+Earth+Mover's+Distance+and+Structured+Classifiers semantic scholar][https://github.com/icoz69/DeepEMD   project webpage]
        .. Oral presentation.
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2004.01547.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2020Yu2xxxarXiv.jpg"></a>}}*Context prior for scene segmentation*   
\n$\cdot$ /C. Yu, J. Wang, C. Gao, G. Yu, C. Shen, N. Sang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2004.01547    arXiv][data/bibtex/CVPR2020Yu2.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Context+Prior+for+Scene+Segmentation+Yu,+Changqian+and+Wang,+Jingbo+and+Gao,+Changxin+and+Yu,+Gang+and+Shen,+Chunhua+and+Sang,+Nong google scholar][https://www.semanticscholar.org/search?q=Context+Prior+for+Scene+Segmentation semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1909.13226.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2020Xie8xxxarXiv.jpg"></a>}}*PolarMask: single shot instance segmentation with polar representation*   
\n$\cdot$ /E. Xie, P. Sun, X. Song, W. Wang, X. Liu, D. Liang, C. Shen, P. Luo/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1909.13226    arXiv][data/bibtex/CVPR2020Xie8.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={PolarMask}:+Single+Shot+Instance+Segmentation+with+Polar+Representation+Xie,+Enze+and+Sun,+Peize+and+Song,+Xiaoge+and+Wang,+Wenhai+and+Liu,+Xuebo+and+Liang,+Ding+and+Shen,+Chunhua+and+Luo,+Ping google scholar][https://www.semanticscholar.org/search?q={PolarMask}:+Single+Shot+Instance+Segmentation+with+Polar+Representation semantic scholar][https://github.com/xieenze/PolarMask   project webpage]
        .. Oral presentation.
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2002.10215.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2020Wang4xxxarXiv.jpg"></a>}}*On the general value of evidence, and bilingual scene-text visual question answering*   
\n$\cdot$ /X. Wang, Y. Liu, C. Shen, C. Ng, C. Luo, L. Jin, C. Chan, A. van den Hengel, L. Wang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2002.10215    arXiv][data/bibtex/CVPR2020Wang4.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=On+the+General+Value+of+Evidence,+and+Bilingual+Scene-Text+Visual+Question+Answering+Wang,+Xinyu+and+Liu,+Yuliang+and+Shen,+Chunhua+and+Ng,+Chun+Chet+and+Luo,+Canjie+and+Jin,+Lianwen+and+Chan,+Chee+Seng+and+{van+den+Hengel},+Anton+and+Wang,+Liangwei google scholar][https://www.semanticscholar.org/search?q=On+the+General+Value+of+Evidence,+and+Bilingual+Scene-Text+Visual+Question+Answering semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1906.04423.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2020NASFCOS10xxxarXiv.jpg"></a>}}*NAS-FCOS: fast neural architecture search for object detection*   
\n$\cdot$ /N. Wang, Y. Gao, H. Chen, P. Wang, Z. Tian, C. Shen, Y. Zhang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1906.04423    arXiv][data/bibtex/CVPR2020NASFCOS10.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={NAS-FCOS}:+Fast+Neural+Architecture+Search+for+Object+Detection+Wang,+Ning+and+Gao,+Yang+and+Chen,+Hao+and+Wang,+Peng+and+Tian,+Zhi+and+Shen,+Chunhua+and+Zhang,+Yanning google scholar][https://www.semanticscholar.org/search?q={NAS-FCOS}:+Fast+Neural+Architecture+Search+for+Object+Detection semantic scholar][https://github.com/Lausannen/NAS-FCOS   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1904.10151.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2020REVERIE1xxxarXiv.jpg"></a>}}*REVERIE: remote embodied visual referring expression in real indoor environments*   
\n$\cdot$ /Y. Qi, Q. Wu, P. Anderson, X. Wang, W. Wang, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1904.10151    arXiv][data/bibtex/CVPR2020REVERIE1.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={REVERIE}:+Remote+Embodied+Visual+Referring+Expression+in+Real+Indoor+Environments+Qi,+Yuankai+and+Wu,+Qi+and+Anderson,+Peter+and+Wang,+Xin+and+Wang,+William+Yang+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q={REVERIE}:+Remote+Embodied+Visual+Referring+Expression+in+Real+Indoor+Environments semantic scholar]
        .. Oral presentation.
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2003.06780.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2020Self12xxxarXiv.jpg"></a>}}*Self-trained deep ordinal regression for end-to-end video anomaly detection*   
\n$\cdot$ /G. Pang, C. Yan, C. Shen, A. van den Hengel, X. Bai/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2003.06780    arXiv][data/bibtex/CVPR2020Self12.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Self-trained+Deep+Ordinal+Regression+for+End-to-End+Video+Anomaly+Detection+Pang,+Guansong+and+Yan,+Cheng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Bai,+Xiao google scholar][https://www.semanticscholar.org/search?q=Self-trained+Deep+Ordinal+Regression+for+End-to-End+Video+Anomaly+Detection semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2002.10200.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2020Liu6xxxarXiv.jpg"></a>}}*ABCNet: arbitrarily-shaped scene text spotting with adaptive Bezier-curve network in real time*   
\n$\cdot$ /Y. Liu, H. Chen, C. Shen, T. He, L. Jin, L. Wang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2002.10200    arXiv][data/bibtex/CVPR2020Liu6.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={ABCNet}:+Arbitrarily-Shaped+Scene+Text+Spotting+with+Adaptive+{B}ezier-Curve+Network+in+Real+Time+Liu,+Yuliang+and+Chen,+Hao+and+Shen,+Chunhua+and+He,+Tong+and+Jin,+Lianwen+and+Wang,+Liangwei google scholar][https://www.semanticscholar.org/search?q={ABCNet}:+Arbitrarily-Shaped+Scene+Text+Spotting+with+Adaptive+{B}ezier-Curve+Network+in+Real+Time semantic scholar][https://github.com/aim-uofa/AdelaiDet/   project webpage]
        .. Oral presentation.
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/2001.00309.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2020BlendMask7xxxarXiv.jpg"></a>}}*BlendMask: top-down meets bottom-up for instance segmentation*   
\n$\cdot$ /H. Chen, K. Sun, Z. Tian, C. Shen, Y. Huang, Y. Yan/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2001.00309    arXiv][data/bibtex/CVPR2020BlendMask7.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={BlendMask}:+Top-Down+Meets+Bottom-Up+for+Instance+Segmentation+Chen,+Hao+and+Sun,+Kunyang+and+Tian,+Zhi+and+Shen,+Chunhua+and+Huang,+Yongming+and+Yan,+Youliang google scholar][https://www.semanticscholar.org/search?q={BlendMask}:+Top-Down+Meets+Bottom-Up+for+Instance+Segmentation semantic scholar][https://github.com/aim-uofa/AdelaiDet/   project webpage]
        .. Oral presentation.
. {{<img class="imgP  right"   src="data/thumbnail/Yu2020RepGraphNetxxxarXiv.jpg">}}*Representative graph neural network*   
\n$\cdot$ /C. Yu, Y. Liu, C. Gao, C. Shen, N. Sang/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2008.05202    arXiv][data/bibtex/Yu2020RepGraphNet.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Representative+Graph+Neural+Network+Yu,+Changqian+and+Liu,+Yifan+and+Gao,+Changxin+and+Shen,+Chunhua+and+Sang,+Nong google scholar][https://www.semanticscholar.org/search?q=Representative+Graph+Neural+Network semantic scholar][https://github.com/ycszen/RepGraph   project webpage]
. *Segmenting transparent objects in the wild*   
\n$\cdot$ /E. Xie, W. Wang, W. Wang, M. Ding, C. Shen, P. Luo/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2003.13948    arXiv][data/bibtex/Xie2020Segtransp.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Segmenting+Transparent+Objects+in+the+Wild+Xie,+Enze+and+Wang,+Wenjia+and+Wang,+Wenhai+and+Ding,+Mingyu+and+Shen,+Chunhua+and+Luo,+Ping google scholar][https://www.semanticscholar.org/search?q=Segmenting+Transparent+Objects+in+the+Wild semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Wang2020SOLOxxxarXiv.jpg">}}*SOLO: segmenting objects by locations*   
\n$\cdot$ /X. Wang, T. Kong, C. Shen, Y. Jiang, L. Li/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1912.04488    arXiv][data/bibtex/Wang2020SOLO.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SOLO}:+Segmenting+Objects+by+Locations+Wang,+Xinlong+and+Kong,+Tao+and+Shen,+Chunhua+and+Jiang,+Yuning+and+Li,+Lei google scholar][https://www.semanticscholar.org/search?q={SOLO}:+Segmenting+Objects+by+Locations semantic scholar][https://github.com/aim-uofa/adet   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Wang2020SuperResxxxarXiv.jpg">}}*Scene text image super-resolution in the wild*   
\n$\cdot$ /W. Wang, E. Xie, X. Liu, W. Wang, D. Liang, C. Shen, X. Bai/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2005.03341    arXiv][data/bibtex/Wang2020SuperRes.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Scene+Text+Image+Super-Resolution+in+the+Wild+Wang,+Wenjia+and+Xie,+Enze+and+Liu,+Xuebo+and+Wang,+Wenhai+and+Liang,+Ding+and+Shen,+Chunhua+and+Bai,+Xiang google scholar][https://www.semanticscholar.org/search?q=Scene+Text+Image+Super-Resolution+in+the+Wild semantic scholar]
. *AE TextSpotter: learning visual and linguistic representation for ambiguous text spotting*   
\n$\cdot$ /W. Wang, X. Liu, X. Ji, E. Xie, D. Liang, Z. Yang, T. Lu, C. Shen, P. Luo/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'20), 2020/.
\n$\cdot$ [data/bibtex/Wang2020AET.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={AE+TextSpotter}:+Learning+Visual+and+Linguistic+Representation+for+Ambiguous+Text+Spotting+Wang,+Wenhai+and+Liu,+Xuebo+and+Ji,+Xiaozhong+and+Xie,+Enze+and+Liang,+Ding+and+Yang,+ZhiBo+and+Lu,+Tong+and+Shen,+Chunhua+and+Luo,+Ping google scholar][https://www.semanticscholar.org/search?q={AE+TextSpotter}:+Learning+Visual+and+Linguistic+Representation+for+Ambiguous+Text+Spotting semantic scholar]
. *Soft expert reward learning for vision-and-language navigation*   
\n$\cdot$ /H. Wang, Q. Wu, C. Shen/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'20), 2020/.
\n$\cdot$ [data/bibtex/Wang2020Soft.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Soft+Expert+Reward+Learning+for+Vision-and-Language+Navigation+Wang,+Hu+and+Wu,+Qi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Soft+Expert+Reward+Learning+for+Vision-and-Language+Navigation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Tian2020CondInstxxxarXiv.jpg">}}*Conditional convolutions for instance segmentation*   
\n$\cdot$ /Z. Tian, C. Shen, H. Chen/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2003.05664    arXiv][data/bibtex/Tian2020CondInst.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Conditional+Convolutions+for+Instance+Segmentation+Tian,+Zhi+and+Shen,+Chunhua+and+Chen,+Hao google scholar][https://www.semanticscholar.org/search?q=Conditional+Convolutions+for+Instance+Segmentation semantic scholar][https://github.com/aim-uofa/adet   project webpage]
        .. Oral presentation.
. {{<img class="imgP  right"   src="data/thumbnail/Liu2020EfficientSemanticxxxarXiv.jpg">}}*Efficient semantic video segmentation with per-frame inference*   
\n$\cdot$ /Y. Liu, C. Shen, C. Yu, J. Wang/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2002.11433    arXiv][data/bibtex/Liu2020EfficientSemantic.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Efficient+Semantic+Video+Segmentation+with+Per-frame+Inference+Liu,+Yifan+and+Shen,+Chunhua+and+Yu,+Changqian+and+Wang,+Jingdong google scholar][https://www.semanticscholar.org/search?q=Efficient+Semantic+Video+Segmentation+with+Per-frame+Inference semantic scholar][https://tinyurl.com/segment-video   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Liu2020WeightingRLxxxarXiv.jpg">}}*Weighing counts: sequential crowd counting by reinforcement learning*   
\n$\cdot$ /L. Liu, H. Lu, H. Zou, H. Xiong, Z. Cao, C. Shen/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2007.08260    arXiv][data/bibtex/Liu2020WeightingRL.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Weighing+Counts:+Sequential+Crowd+Counting+by+Reinforcement+Learning+Liu,+Liang+and+Lu,+Hao+and+Zou,+Hongwei+and+Xiong,+Haipeng+and+Cao,+Zhiguo+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Weighing+Counts:+Sequential+Crowd+Counting+by+Reinforcement+Learning semantic scholar][https://github.com/poppinace/libranet   project webpage]
. *Instance-aware embedding for point cloud instance segmentation*   
\n$\cdot$ /T. He, Y. Liu, C. Shen, X. Wang, C. Sun/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'20), 2020/.
\n$\cdot$ [data/bibtex/He2020InstanceAware.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Instance-Aware+Embedding+for+Point+Cloud+Instance+Segmentation+He,+Tong+and+Liu,+Yifan+and+Shen,+Chunhua+and+Wang,+Xinlong+and+Sun,+Changming google scholar][https://www.semanticscholar.org/search?q=Instance-Aware+Embedding+for+Point+Cloud+Instance+Segmentation semantic scholar]
. *Learning and memorizing representative prototypes for 3D point cloud semantic and instance segmentation*   
\n$\cdot$ /T. He, D. Gong, Z. Tian, C. Shen/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'20), 2020/.
\n$\cdot$ [data/bibtex/He2020PC1.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+and+Memorizing+Representative+Prototypes+for+{3D}+Point+Cloud+Semantic+and+Instance+Segmentation+He,+Tong+and+Gong,+Dong+and+Tian,+Zhi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Learning+and+Memorizing+Representative+Prototypes+for+{3D}+Point+Cloud+Semantic+and+Instance+Segmentation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Wang2020IJCAIxxxarXiv.jpg">}}*Unsupervised representation learning by predicting random distances*   
\n$\cdot$ /H. Wang, G. Pang, C. Shen, C. Ma/.
\n$\cdot$ /Proc. International Joint Conferences on Artificial Intelligence (IJCAI'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/1912.12186    arXiv][data/bibtex/Wang2020IJCAI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Unsupervised+Representation+Learning+by+Predicting+Random+Distances+Wang,+Hu+and+Pang,+Guansong+and+Shen,+Chunhua+and+Ma,+Congbo google scholar][https://www.semanticscholar.org/search?q=Unsupervised+Representation+Learning+by+Predicting+Random+Distances semantic scholar]
. *Pairwise relation learning for semi-supervised gland segmentation*   
\n$\cdot$ /Y. Xie, J. Zhang, Z. Liao, C. Shen, J. Verjans, Y. Xia/.
\n$\cdot$ /Proc. International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI'20), 2020/.
\n$\cdot$ [data/bibtex/YXie2020MICCAI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Pairwise+Relation+Learning+for+Semi-supervised+Gland+Segmentation+Xie,+Yutong+and+Zhang,+Jianpeng+and+Liao,+Zhibin+and+Shen,+Chunhua+and+Verjans,+Johan+and+Xia,+Yong google scholar][https://www.semanticscholar.org/search?q=Pairwise+Relation+Learning+for+Semi-supervised+Gland+Segmentation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/SoloV22020xxxarXiv.jpg">}}*SOLOv2: dynamic and fast instance segmentation*   
\n$\cdot$ /X. Wang, R. Zhang, T. Kong, L. Li, C. Shen/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'20), 2020/.
\n$\cdot$ [http://arxiv.org/abs/2003.10152    arXiv][data/bibtex/SoloV22020.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={SOLOv2}:+Dynamic+and+Fast+Instance+Segmentation+Wang,+Xinlong+and+Zhang,+Rufeng+and+Kong,+Tao+and+Li,+Lei+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={SOLOv2}:+Dynamic+and+Fast+Instance+Segmentation semantic scholar][https://git.io/AdelaiDet   project webpage]

= 2019
== Journal
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1806.01576.pdf"><img class="imgP  right"   src="data/thumbnail/Adaptive2019ZhangxxxarXiv.jpg"></a>}}*Adaptive importance learning for improving lightweight image super-resolution network*   
\n$\cdot$ /L. Zhang, P. Wang, C. Shen, L. Liu, W. Wei, Y. Zhang, A. van den Hengel/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1806.01576    arXiv][data/bibtex/Adaptive2019Zhang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Adaptive+Importance+Learning+for+Improving+Lightweight+Image+Super-resolution+Network+Zhang,+Lei+and+Wang,+Peng+and+Shen,+Chunhua+and+Liu,+Lingqiao+and+Wei,+Wei+and+Zhang,+Yanning+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Adaptive+Importance+Learning+for+Improving+Lightweight+Image+Super-resolution+Network semantic scholar][https://tinyurl.com/Super-resolution-Network   project webpage]
. *Accurate imagery recovery using a multi-observation patch model*   
\n$\cdot$ /L. Zhang, W. Wei, Q. Shen, C. Shen, A. van den Hengel/.
\n$\cdot$ /Information Sciences (IS), 2019/.
\n$\cdot$ [data/bibtex/Zhang2019Accurate.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Accurate+Imagery+Recovery+Using+a+Multi-Observation+Patch+Model+Zhang,+Lei+and+Wei,+Wei+and+Shen,+Qiang+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Accurate+Imagery+Recovery+Using+a+Multi-Observation+Patch+Model semantic scholar]
. *Heritage image annotation via collective knowledge*   
\n$\cdot$ /J. Zhang, Q. Wu, J. Zhang, C. Shen, J. Lu, Q. Wu/.
\n$\cdot$ /Pattern Recognition (PR), 2019/.
\n$\cdot$ [data/bibtex/Zhang2019PR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Heritage+Image+Annotation+via+Collective+Knowledge+Zhang,+Junjie+and+Wu,+Qi+and+Zhang,+Jian+and+Shen,+Chunhua+and+Lu,+Jianfeng+and+Wu,+Qiang google scholar][https://www.semanticscholar.org/search?q=Heritage+Image+Annotation+via+Collective+Knowledge semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Wu2019PRxxxarXiv.jpg">}}*Wider or deeper: revisiting the ResNet model for visual recognition*   
\n$\cdot$ /Z. Wu, C. Shen, A. van den Hengel/.
\n$\cdot$ /Pattern Recognition (PR), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1611.10080    arXiv][data/bibtex/Wu2019PR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Wider+or+Deeper:+Revisiting+the+{ResNet}+Model+for+Visual+Recognition+Wu,+Zifeng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Wider+or+Deeper:+Revisiting+the+{ResNet}+Model+for+Visual+Recognition semantic scholar]
. *Order-aware convolutional pooling for video based action recognition*   
\n$\cdot$ /P. Wang, L. Liu, C. Shen, H. Shen/.
\n$\cdot$ /Pattern Recognition (PR), 2019/.
\n$\cdot$ [data/bibtex/Wang2019PR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Order-aware+Convolutional+Pooling+for+Video+Based+Action+Recognition+Wang,+Peng+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+Shen,+Heng+Tao google scholar][https://www.semanticscholar.org/search?q=Order-aware+Convolutional+Pooling+for+Video+Based+Action+Recognition semantic scholar]
. *Structural analysis of attributes for vehicle re-identification and retrieval*   
\n$\cdot$ /Y. Zhao, C. Shen, H. Wang, S. Chen/.
\n$\cdot$ /IEEE Transactions on Intelligent Transportation Systems (T-ITS), 2019/.
\n$\cdot$ [data/bibtex/Zhao2019Structural.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Structural+Analysis+of+Attributes+for+Vehicle+Re-identification+and+Retrieval+Zhao,+Yanzhu+and+Shen,+Chunhua+and+Wang,+Huibing+and+Chen,+Shengyong google scholar][https://www.semanticscholar.org/search?q=Structural+Analysis+of+Attributes+for+Vehicle+Re-identification+and+Retrieval semantic scholar]
. *Human detection aided by deeply learned semantic masks*   
\n$\cdot$ /X. Wang, C. Shen, H. Li, S. Xu/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2019/.
\n$\cdot$ [data/bibtex/Wangxy2019CSVT.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Human+Detection+Aided+by+Deeply+Learned+Semantic+Masks+Wang,+Xinyu+and+Shen,+Chunhua+and+Li,+Hanxi+and+Xu,+Shugong google scholar][https://www.semanticscholar.org/search?q=Human+Detection+Aided+by+Deeply+Learned+Semantic+Masks semantic scholar]
. *Embedding bilateral filter in least squares for efficient edge-preserving image smoothing*   
\n$\cdot$ /W. Liu, P. Zhang, X. Chen, C. Shen, X. Huang, J. Yang/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2019/.
\n$\cdot$ [data/bibtex/Liu2019CSVT.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Embedding+Bilateral+Filter+in+Least+Squares+for+Efficient+Edge-preserving+Image+Smoothing+Liu,+Wei+and+Zhang,+Pingping+and+Chen,+Xiaogang+and+Shen,+Chunhua+and+Huang,+Xiaolin+and+Yang,+Jie google scholar][https://www.semanticscholar.org/search?q=Embedding+Bilateral+Filter+in+Least+Squares+for+Efficient+Edge-preserving+Image+Smoothing semantic scholar]
. *Counting objects by blockwise classification*   
\n$\cdot$ /L. Liu, H. Lu, H. Xiong, K. Xian, Z. Cao, C. Shen/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2019/.
\n$\cdot$ [data/bibtex/Counting2019CSVT.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Counting+Objects+by+Blockwise+Classification+Liu,+Liang+and+Lu,+Hao+and+Xiong,+Haipeng+and+Xian,+Ke+and+Cao,+Zhiguo+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Counting+Objects+by+Blockwise+Classification semantic scholar]
. *Hyperspectral classification based on lightweight 3D-CNN with transfer learning*   
\n$\cdot$ /H. Zhang, Y. Li, Y. Jiang, P. Wang, Q. Shen, C. Shen/.
\n$\cdot$ /IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2019/.
\n$\cdot$ [data/bibtex/Zhang2019Lightweight.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Hyperspectral+Classification+Based+on+Lightweight+{3D-CNN}+With+Transfer+Learning+Zhang,+Haokui+and+Li,+Ying+and+Jiang,+Yenan+and+Wang,+Peng+and+Shen,+Qiang+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Hyperspectral+Classification+Based+on+Lightweight+{3D-CNN}+With+Transfer+Learning semantic scholar]
. *Salient object detection with lossless feature reflection and weighted structural loss*   
\n$\cdot$ /P. Zhang, W. Liu, H. Lu, C. Shen/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2019/.
\n$\cdot$ [data/bibtex/Zhang2019Salient.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Salient+Object+Detection+with+Lossless+Feature+Reflection+and+Weighted+Structural+Loss+Zhang,+Pingping+and+Liu,+Wei+and+Lu,+Huchuan+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Salient+Object+Detection+with+Lossless+Feature+Reflection+and+Weighted+Structural+Loss semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Wei2019TIPxxxarXiv.jpg">}}*Piecewise classifier mappings: learning fine-grained learners for novel categories with few examples*   
\n$\cdot$ /X. Wei, P. Wang, L. Liu, C. Shen, J. Wu/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1805.04288    arXiv][data/bibtex/Wei2019TIP.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Piecewise+classifier+mappings:+Learning+fine-grained+learners+for+novel+categories+with+few+examples+Wei,+Xiu-Shen+and+Wang,+Peng+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+Wu,+Jianxin google scholar][https://www.semanticscholar.org/search?q=Piecewise+classifier+mappings:+Learning+fine-grained+learners+for+novel+categories+with+few+examples semantic scholar]
. *Multiple instance learning with emerging novel class*   
\n$\cdot$ /X. Wei, H. Ye, X. Mu, J. Wu, C. Shen, Z. Zhou/.
\n$\cdot$ /IEEE Transactions on Knowledge and Data Engineering (TKDE), 2019/.
\n$\cdot$ [data/bibtex/Wei2019TKDE.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Multiple+Instance+Learning+with+Emerging+Novel+Class+Wei,+Xiu-Shen+and+Ye,+Han-Jia+and+Mu,+Xin+and+Wu,+Jianxin+and+Shen,+Chunhua+and+Zhou,+Zhi-Hua google scholar][https://www.semanticscholar.org/search?q=Multiple+Instance+Learning+with+Emerging+Novel+Class semantic scholar]
. *Attention residual learning for skin lesion classification*   
\n$\cdot$ /J. Zhang, Y. Xie, Y. Xia, C. Shen/.
\n$\cdot$ /IEEE Transactions on Medical Imaging (TMI), 2019/.
\n$\cdot$ [data/bibtex/Zhang2019Attn.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Attention+residual+learning+for+skin+lesion+classification+Zhang,+Jianpeng+and+Xie,+Yutong+and+Xia,+Yong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Attention+residual+learning+for+skin+lesion+classification semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/TZhang2019TMMxxxarXiv.jpg">}}*Decoupled spatial neural attention for weakly supervised semantic segmentation*   
\n$\cdot$ /T. Zhang, G. Lin, J. Cai, T. Shen, C. Shen, A. Kot/.
\n$\cdot$ /IEEE Transactions on Multimedia (TMM), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1803.02563    arXiv][data/bibtex/TZhang2019TMM.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Decoupled+Spatial+Neural+Attention+for+Weakly+Supervised+Semantic+Segmentation+Zhang,+Tianyi+and+Lin,+Guosheng+and+Cai,+Jianfei+and+Shen,+Tong+and+Shen,+Chunhua+and+Kot,+Alex+C. google scholar][https://www.semanticscholar.org/search?q=Decoupled+Spatial+Neural+Attention+for+Weakly+Supervised+Semantic+Segmentation semantic scholar]
. *RefineNet: multi-path refinement networks for dense prediction*   
\n$\cdot$ /G. Lin, F. Liu, A. Milan, C. Shen, I. Reid/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2019/.
\n$\cdot$ [https://doi.org/10.1109/TPAMI.2019.2893630  link][data/bibtex/Fayao2019PAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={RefineNet}:+Multi-Path+Refinement+Networks+for+Dense+Prediction+Lin,+Guosheng+and+Liu,+Fayao+and+Milan,+Anton+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q={RefineNet}:+Multi-Path+Refinement+Networks+for+Dense+Prediction semantic scholar][https://github.com/guosheng/refinenet   project webpage]
        .. Pytorch code is [https://github.com/DrSleep/refinenet-pytorch here].
== Conference
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1811.00751.pdf"><img class="imgP  right"   src="data/thumbnail/AAAI19LixxxarXiv.jpg"></a>}}*Show, attend and read: a simple and strong baseline for irregular text recognition*   
\n$\cdot$ /H. Li, P. Wang, C. Shen, G. Zhang/.
\n$\cdot$ /Proc. AAAI Conference on Artificial Intelligence (AAAI'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1811.00751    arXiv][data/bibtex/AAAI19Li.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Show,+attend+and+read:+a+simple+and+strong+baseline+for+irregular+text+recognition+Li,+Hui+and+Wang,+Peng+and+Shen,+Chunhua+and+Zhang,+Guyu google scholar][https://www.semanticscholar.org/search?q=Show,+attend+and+read:+a+simple+and+strong+baseline+for+irregular+text+recognition semantic scholar]
. *Deep hashing by discriminating hard examples*   
\n$\cdot$ /C. Yan, G. Pang, X. Bai, C. Shen, J. Zhou, E. Hancock/.
\n$\cdot$ /Proc. ACM International Conference on Multimedia (ACMMM'19), 2019/.
\n$\cdot$ [data/bibtex/MM2019Yan.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+Hashing+by+Discriminating+Hard+Examples+Yan,+Cheng+and+Pang,+Guansong+and+Bai,+Xiao+and+Shen,+Chunhua+and+Zhou,+Jun+and+Hancock,+Edwin google scholar][https://www.semanticscholar.org/search?q=Deep+Hashing+by+Discriminating+Hard+Examples semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1811.10413.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR19Zhuang3xxxarXiv.jpg"></a>}}*Structured binary neural networks for accurate image classification and semantic segmentation*   
\n$\cdot$ /B. Zhuang, C. Shen, M. Tan, L. Liu, I. Reid/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1811.10413    arXiv][data/bibtex/CVPR19Zhuang3.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Structured+Binary+Neural+Networks+for+Accurate+Image+Classification+and+Semantic+Segmentation+Zhuang,+Bohan+and+Shen,+Chunhua+and+Tan,+Mingkui+and+Liu,+Lingqiao+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Structured+Binary+Neural+Networks+for+Accurate+Image+Classification+and+Semantic+Segmentation semantic scholar][https://bitbucket.org/jingruixiaozhuang/group-net-image-classification/   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/CVPR19Zhang6xxxPDF.jpg">}}*Mind your neighbours: image annotation with metadata neighbourhood graph co-attention networks*   
\n$\cdot$ /J. Zhang, Q. Wu, J. Zhang, C. Shen, J. Lu/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'19), 2019/.
\n$\cdot$ [http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Mind_Your_Neighbours_Image_Annotation_With_Metadata_Neighbourhood_Graph_Co-Attention_CVPR_2019_paper.pdf  link][data/bibtex/CVPR19Zhang6.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Mind+Your+Neighbours:+Image+Annotation+with+Metadata+Neighbourhood+Graph+Co-Attention+Networks+Zhang,+Junjie+and+Wu,+Qi+and+Zhang,+Jian+and+Shen,+Chunhua+and+Lu,+Jianfeng google scholar][https://www.semanticscholar.org/search?q=Mind+Your+Neighbours:+Image+Annotation+with+Metadata+Neighbourhood+Graph+Co-Attention+Networks semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1903.02351.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR19Zhang5xxxarXiv.jpg"></a>}}*CANet: class-agnostic segmentation networks with iterative refinement and attentive few-shot learning*   
\n$\cdot$ /C. Zhang, G. Lin, F. Liu, R. Yao, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1903.02351    arXiv][data/bibtex/CVPR19Zhang5.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={CANet}:+Class-Agnostic+Segmentation+Networks+with+Iterative+Refinement+and+Attentive+Few-Shot+Learning+Zhang,+Chi+and+Lin,+Guosheng+and+Liu,+Fayao+and+Yao,+Rui+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={CANet}:+Class-Agnostic+Segmentation+Networks+with+Iterative+Refinement+and+Attentive+Few-Shot+Learning semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1904.10293.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR19Yan9xxxarXiv.jpg"></a>}}*Attention-guided network for ghost-free high dynamic range imaging*   
\n$\cdot$ /Q. Yan, D. Gong, Q. Shi, A. van den Hengel, C. Shen, I. Reid, Y. Zhang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1904.10293    arXiv][data/bibtex/CVPR19Yan9.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Attention-guided+Network+for+Ghost-free+High+Dynamic+Range+Imaging+Yan,+Qingsen+and+Gong,+Dong+and+Shi,+Qinfeng+and+{van+den+Hengel},+Anton+and+Shen,+Chunhua+and+Reid,+Ian+and+Zhang,+Yanning google scholar][https://www.semanticscholar.org/search?q=Attention-guided+Network+for+Ghost-free+High+Dynamic+Range+Imaging semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1902.09852.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR19Wang4xxxarXiv.jpg"></a>}}*Associatively segmenting instances and semantics in point clouds*   
\n$\cdot$ /X. Wang, S. Liu, X. Shen, C. Shen, J. Jia/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1902.09852    arXiv][data/bibtex/CVPR19Wang4.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Associatively+Segmenting+Instances+and+Semantics+in+Point+Clouds+Wang,+Xinlong+and+Liu,+Shu+and+Shen,+Xiaoyong+and+Shen,+Chunhua+and+Jia,+Jiaya google scholar][https://www.semanticscholar.org/search?q=Associatively+Segmenting+Instances+and+Semantics+in+Point+Clouds semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1812.04794.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR19PengWang0xxxarXiv.jpg"></a>}}*Neighbourhood watch: referring expression comprehension via language-guided graph attention networks*   
\n$\cdot$ /P. Wang, Q. Wu, J. Cao, C. Shen, L. Gao, A. vanden Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1812.04794    arXiv][data/bibtex/CVPR19PengWang0.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Neighbourhood+Watch:+Referring+Expression+Comprehension+via+Language-guided+Graph+Attention+Networks+Wang,+Peng+and+Wu,+Qi+and+Cao,+Jiewei+and+Shen,+Chunhua+and+Gao,+Lianli+and+{vanden+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Neighbourhood+Watch:+Referring+Expression+Comprehension+via+Language-guided+Graph+Attention+Networks semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1903.02120.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR19Tian7xxxarXiv.jpg"></a>}}*Decoders matter for semantic segmentation: data-dependent decoding enables flexible feature aggregation*   
\n$\cdot$ /Z. Tian, T. He, C. Shen, Y. Yan/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1903.02120    arXiv][data/bibtex/CVPR19Tian7.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Decoders+Matter+for+Semantic+Segmentation:+Data-Dependent+Decoding+Enables+Flexible+Feature+Aggregation+Tian,+Zhi+and+He,+Tong+and+Shen,+Chunhua+and+Yan,+Youliang google scholar][https://www.semanticscholar.org/search?q=Decoders+Matter+for+Semantic+Segmentation:+Data-Dependent+Decoding+Enables+Flexible+Feature+Aggregation semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1810.10804.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR19Nekrasov1xxxarXiv.jpg"></a>}}*Fast neural architecture search of compact semantic segmentation models via auxiliary cells*   
\n$\cdot$ /V. Nekrasov, H. Chen, C. Shen, I. Reid/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1810.10804    arXiv][data/bibtex/CVPR19Nekrasov1.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fast+Neural+Architecture+Search+of+Compact+Semantic+Segmentation+Models+via+Auxiliary+Cells+Nekrasov,+Vladimir+and+Chen,+Hao+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Fast+Neural+Architecture+Search+of+Compact+Semantic+Segmentation+Models+via+Auxiliary+Cells semantic scholar]
. *Visual question answering as reading comprehension*   
\n$\cdot$ /H. Li, P. Wang, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1811.11903    arXiv][data/bibtex/CVPR19HuiLi2.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Visual+Question+Answering+as+Reading+Comprehension+Li,+Hui+and+Wang,+Peng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Visual+Question+Answering+as+Reading+Comprehension semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1903.04688.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR19He8xxxarXiv.jpg"></a>}}*Knowledge adaptation for efficient semantic segmentation*   
\n$\cdot$ /T. He, C. Shen, Z. Tian, D. Gong, C. Sun, Y. Yan/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1903.04688    arXiv][data/bibtex/CVPR19He8.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Knowledge+Adaptation+for+Efficient+Semantic+Segmentation+He,+Tong+and+Shen,+Chunhua+and+Tian,+Zhi+and+Gong,+Dong+and+Sun,+Changming+and+Yan,+Youliang google scholar][https://www.semanticscholar.org/search?q=Knowledge+Adaptation+for+Efficient+Semantic+Segmentation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/PersonReID2019ZhangxxxarXiv.jpg">}}*Self-training with progressive augmentation for unsupervised cross-domain person re-identification*   
\n$\cdot$ /X. Zhang, J. Cao, C. Shen, M. You/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1907.13315    arXiv][data/bibtex/PersonReID2019Zhang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Self-Training+with+Progressive+Augmentation+for+Unsupervised+Cross-Domain+Person+Re-Identification+Zhang,+Xinyu+and+Cao,+Jiewei+and+Shen,+Chunhua+and+You,+Mingyu google scholar][https://www.semanticscholar.org/search?q=Self-Training+with+Progressive+Augmentation+for+Unsupervised+Cross-Domain+Person+Re-Identification semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Temporal2019ZhangxxxarXiv.jpg">}}*Exploiting temporal consistency for real-time video depth estimation*   
\n$\cdot$ /H. Zhang, C. Shen, Y. Li, Y. Cao, Y. Liu, Y. Yan/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1908.03706    arXiv][data/bibtex/Temporal2019Zhang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Exploiting+temporal+consistency+for+real-time+video+depth+estimation+Zhang,+Haokui+and+Shen,+Chunhua+and+Li,+Ying+and+Cao,+Yuanzhouhan+and+Liu,+Yu+and+Yan,+Youliang google scholar][https://www.semanticscholar.org/search?q=Exploiting+temporal+consistency+for+real-time+video+depth+estimation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/VNL2019YinxxxarXiv.jpg">}}*Enforcing geometric constraints of virtual normal for depth prediction*   
\n$\cdot$ /W. Yin, Y. Liu, C. Shen, Y. Yan/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1907.12209    arXiv][data/bibtex/VNL2019Yin.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Enforcing+geometric+constraints+of+virtual+normal+for+depth+prediction+Yin,+Wei+and+Liu,+Yifan+and+Shen,+Chunhua+and+Yan,+Youliang google scholar][https://www.semanticscholar.org/search?q=Enforcing+geometric+constraints+of+virtual+normal+for+depth+prediction semantic scholar][https://github.com/YvanYin/VNL_Monocular_Depth_Prediction   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/OpenSet2019XiongxxxarXiv.jpg">}}*From open set to closed set: counting objects by spatial divide-and-conquer*   
\n$\cdot$ /H. Xiong, H. Lu, C. Liu, L. Liu, Z. Cao, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1908.06473    arXiv][data/bibtex/OpenSet2019Xiong.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=From+Open+Set+to+Closed+Set:+Counting+Objects+by+Spatial+Divide-and-Conquer+Xiong,+Haipeng+and+Lu,+Hao+and+Liu,+Chengxin+and+Liu,+Liang+and+Cao,+Zhiguo+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=From+Open+Set+to+Closed+Set:+Counting+Objects+by+Spatial+Divide-and-Conquer semantic scholar][https://github.com/xhp-hust-2018-2011/S-DCNet   project webpage]
. *Efficient and accurate arbitrary-shaped text detection with pixel aggregation network*   
\n$\cdot$ /W. Wang, E. Xie, X. Song, Y. Zang, W. Wang, T. Lu, G. Yu, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'19), 2019/.
\n$\cdot$ [data/bibtex/TextDet2019Wang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Efficient+and+Accurate+Arbitrary-Shaped+Text+Detection+with+Pixel+Aggregation+Network+Wang,+Wenhai+and+Xie,+Enze+and+Song,+Xiaoge+and+Zang,+Yuhang+and+Wang,+Wenjia+and+Lu,+Tong+and+Yu,+Gang+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Efficient+and+Accurate+Arbitrary-Shaped+Text+Detection+with+Pixel+Aggregation+Network semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1904.01355.pdf"><img class="imgP  right"   src="data/thumbnail/FCOS2019TianxxxarXiv.jpg"></a>}}*FCOS: fully convolutional one-stage object detection*   
\n$\cdot$ /Z. Tian, C. Shen, H. Chen, T. He/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1904.01355    arXiv][data/bibtex/FCOS2019Tian.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={FCOS}:+Fully+Convolutional+One-Stage+Object+Detection+Tian,+Zhi+and+Shen,+Chunhua+and+Chen,+Hao+and+He,+Tong google scholar][https://www.semanticscholar.org/search?q={FCOS}:+Fully+Convolutional+One-Stage+Object+Detection semantic scholar][https://tinyurl.com/FCOSv1   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Matting2019LuxxxarXiv.jpg">}}*Indices matter: learning to index for deep image matting*   
\n$\cdot$ /H. Lu, Y. Dai, C. Shen, S. Xu/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1908.00672    arXiv][data/bibtex/Matting2019Lu.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Indices+Matter:+Learning+to+Index+for+Deep+Image+Matting+Lu,+Hao+and+Dai,+Yutong+and+Shen,+Chunhua+and+Xu,+Songcen google scholar][https://www.semanticscholar.org/search?q=Indices+Matter:+Learning+to+Index+for+Deep+Image+Matting semantic scholar]
. *Real-time joint semantic segmentation and depth estimation using asymmetric annotations*   
\n$\cdot$ /V. Nekrasov, T. Dharmasiri, A. Spek, T. Drummond, C. Shen, I. Reid/.
\n$\cdot$ /Proc. International Conference on Robotics and Automation (ICRA'19), 2019/.
\n$\cdot$ [data/bibtex/ICRA19Nekrasov.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Real-Time+Joint+Semantic+Segmentation+and+Depth+Estimation+Using+Asymmetric+Annotations+Nekrasov,+Vladimir+and+Dharmasiri,+Thanuja+and+Spek,+Andrew+and+Drummond,+Tom+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Real-Time+Joint+Semantic+Segmentation+and+Depth+Estimation+Using+Asymmetric+Annotations semantic scholar]
. *Light-weight hybrid convolutional network for liver tumor segmentation*   
\n$\cdot$ /J. Zhang, Y. Xie, P. Zhang, H. Chen, Y. Xia, C. Shen/.
\n$\cdot$ /Proc. International Joint Conference on Artificial Intelligence (IJCAI'19), 2019/.
\n$\cdot$ [data/bibtex/IJCAI19Zhang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Light-Weight+Hybrid+Convolutional+Network+for+Liver+Tumor+Segmentation+Zhang,+Jianpeng+and+Xie,+Yutong+and+Zhang,+Pingping+and+Chen,+Hao+and+Xia,+Yong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Light-Weight+Hybrid+Convolutional+Network+for+Liver+Tumor+Segmentation semantic scholar]
. *Deep anomaly detection with deviation networks*   
\n$\cdot$ /G. Pang, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'19), 2019/.
\n$\cdot$ [data/bibtex/KDD19Pang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+Anomaly+Detection+with+Deviation+Networks+Pang,+Guansong+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Deep+Anomaly+Detection+with+Deviation+Networks semantic scholar]
. *Deep segmentation-emendation model for gland instance segmentation*   
\n$\cdot$ /Y. Xie, H. Lu, J. Zhang, C. Shen, Y. Xia/.
\n$\cdot$ /Proc. International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI'19), 2019/.
\n$\cdot$ [data/bibtex/MICCAI2019Xie.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+Segmentation-Emendation+Model+for+Gland+Instance+Segmentation+Xie,+Yutong+and+Lu,+Hao+and+Zhang,+Jianpeng+and+Shen,+Chunhua+and+Xia,+Yong google scholar][https://www.semanticscholar.org/search?q=Deep+Segmentation-Emendation+Model+for+Gland+Instance+Segmentation semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1911.00888.pdf"><img class="imgP  right"   src="data/thumbnail/Cao2019GANxxxarXiv.jpg"></a>}}*Multi-marginal wasserstein GAN*   
\n$\cdot$ /J. Cao, L. Mo, Y. Zhang, K. Jia, C. Shen, M. Tan/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1911.00888    arXiv][data/bibtex/Cao2019GAN.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Multi-marginal+Wasserstein+{GAN}+Cao,+Jiezhang+and+Mo,+Langyuan+and+Zhang,+Yifan+and+Jia,+Kui+and+Shen,+Chunhua+and+Tan,+Mingkui google scholar][https://www.semanticscholar.org/search?q=Multi-marginal+Wasserstein+{GAN} semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Scale2019BianxxxarXiv.jpg">}}*Unsupervised scale-consistent depth and ego-motion learning from monocular video*   
\n$\cdot$ /J. Bian, Z. Li, N. Wang, H. Zhan, C. Shen, M. Cheng, I. Reid/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'19), 2019/.
\n$\cdot$ [http://arxiv.org/abs/1908.10553    arXiv][data/bibtex/Scale2019Bian.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Unsupervised+Scale-consistent+Depth+and+Ego-motion+Learning+from+Monocular+Video+Bian,+Jia-Wang+and+Li,+Zhichao+and+Wang,+Naiyan+and+Zhan,+Huangying+and+Shen,+Chunhua+and+Cheng,+Ming-Ming+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Unsupervised+Scale-consistent+Depth+and+Ego-motion+Learning+from+Monocular+Video semantic scholar][https://github.com/JiawangBian/SC-SfMLearner-Release   project webpage]

= 2018
== Journal
. *Cluster sparsity field: an internal hyperspectral imagery prior for reconstruction*   
\n$\cdot$ /L. Zhang, W. Wei, Y. Zhang, C. Shen, A. van den Hengel, Q. Shi/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2018/.
\n$\cdot$ [https://www.researchgate.net/publication/323914969_Cluster_Sparsity_Field_An_Internal_Hyperspectral_Imagery_Prior_for_Reconstruction  pdf][data/bibtex/Zhang2018IJCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Cluster+Sparsity+Field:+An+Internal+Hyperspectral+Imagery+Prior+for+Reconstruction+Zhang,+Lei+and+Wei,+Wei+and+Zhang,+Yanning+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Shi,+Qinfeng google scholar][https://www.semanticscholar.org/search?q=Cluster+Sparsity+Field:+An+Internal+Hyperspectral+Imagery+Prior+for+Reconstruction semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Li2018IVCxxxarXiv.jpg">}}*Reading car license plates using deep neural networks*   
\n$\cdot$ /H. Li, P. Wang, M. You, C. Shen/.
\n$\cdot$ /Image and Vision Computing (IVC), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1601.05610    arXiv][data/bibtex/Li2018IVC.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Reading+Car+License+Plates+Using+Deep+Neural+Networks+Li,+Hui+and+Wang,+Peng+and+You,+Mingyu+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Reading+Car+License+Plates+Using+Deep+Neural+Networks semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Zhuang2018PRxxxarXiv.jpg">}}*Multi-label learning based deep transfer neural network for facial attribute classification*   
\n$\cdot$ /N. Zhuang, Y. Yan, S. Chen, H. Wang, C. Shen/.
\n$\cdot$ /Pattern Recognition (PR), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1805.01282    arXiv][data/bibtex/Zhuang2018PR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Multi-label+Learning+Based+Deep+Transfer+Neural+Network+for+Facial+Attribute+Classification+Zhuang,+Ni+and+Yan,+Yan+and+Chen,+Si+and+Wang,+Hanzi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Multi-label+Learning+Based+Deep+Transfer+Neural+Network+for+Facial+Attribute+Classification semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Wei2018PRxxxarXiv.jpg">}}*Unsupervised object discovery and co-localization by deep descriptor transforming*   
\n$\cdot$ /X. Wei, C. Zhang, J. Wu, C. Shen, Z. Zhou/.
\n$\cdot$ /Pattern Recognition (PR), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1707.06397    arXiv][data/bibtex/Wei2018PR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Unsupervised+Object+Discovery+and+Co-Localization+by+Deep+Descriptor+Transforming+Wei,+Xiu-Shen+and+Zhang,+Chen-Lin+and+Wu,+Jianxin+and+Shen,+Chunhua+and+Zhou,+Zhi-Hua google scholar][https://www.semanticscholar.org/search?q=Unsupervised+Object+Discovery+and+Co-Localization+by+Deep+Descriptor+Transforming semantic scholar]
. *An extended filtered channel framework for pedestrian detection*   
\n$\cdot$ /M. You, Y. Zhang, C. Shen, X. Zhang/.
\n$\cdot$ /IEEE Transactions on Intelligent Transportation Systems (T-ITS), 2018/.
\n$\cdot$ [data/bibtex/You2018T-ITS.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=An+extended+filtered+channel+framework+for+pedestrian+detection+You,+Minyu+and+Zhang,+Yubin+and+Shen,+Chunhua+and+Zhang,+Xinyu google scholar][https://www.semanticscholar.org/search?q=An+extended+filtered+channel+framework+for+pedestrian+detection semantic scholar]
. *Towards end-to-end car license plates detection and recognition with deep neural networks*   
\n$\cdot$ /H. Li, P. Wang, C. Shen/.
\n$\cdot$ /IEEE Transactions on Intelligent Transportation Systems (T-ITS), 2018/.
\n$\cdot$ [data/bibtex/Li2018T-ITSa.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Towards+End-to-End+Car+License+Plates+Detection+and+Recognition+with+Deep+Neural+Networks+Li,+Hui+and+Wang,+Peng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Towards+End-to-End+Car+License+Plates+Detection+and+Recognition+with+Deep+Neural+Networks semantic scholar]
. *Unsupervised domain adaptation using robust class-wise matching*   
\n$\cdot$ /L. Zhang, P. Wang, W. Wei, H. Lu, C. Shen, A. van den Hengel, Y. Zhang/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2018/.
\n$\cdot$ [data/bibtex/Zhang2018TCSVT.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Unsupervised+Domain+Adaptation+Using+Robust+Class-Wise+Matching+Zhang,+Lei+and+Wang,+Peng+and+Wei,+Wei+and+Lu,+Hao+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Zhang,+Yanning google scholar][https://www.semanticscholar.org/search?q=Unsupervised+Domain+Adaptation+Using+Robust+Class-Wise+Matching semantic scholar]
. *Semantics-aware visual object tracking*   
\n$\cdot$ /R. Yao, G. Lin, C. Shen, Y. Zhang, Q. Shi/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2018/.
\n$\cdot$ [data/bibtex/Yao2018TCSVT.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Semantics-Aware+Visual+Object+Tracking+Yao,+Rui+and+Lin,+Guosheng+and+Shen,+Chunhua+and+Zhang,+Yanning+and+Shi,+Qinfeng google scholar][https://www.semanticscholar.org/search?q=Semantics-Aware+Visual+Object+Tracking semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/TCSVT2017HuxxxarXiv.jpg">}}*Pushing the limits of deep CNNs for pedestrian detection*   
\n$\cdot$ /Q. Hu, P. Wang, C. Shen, A. van den Hengel, F. Porikli/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1603.04525    arXiv][data/bibtex/TCSVT2017Hu.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Pushing+the+Limits+of+Deep+{CNNs}+for+Pedestrian+Detection+Hu,+Qichang+and+Wang,+Peng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Porikli,+Fatih google scholar][https://www.semanticscholar.org/search?q=Pushing+the+Limits+of+Deep+{CNNs}+for+Pedestrian+Detection semantic scholar]
. *An embarrassingly simple approach to visual domain adaptation*   
\n$\cdot$ /H. Lu, C. Shen, Z. Cao, Y. Xiao, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2018/.
\n$\cdot$ [data/bibtex/Lu2018TIP.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=An+Embarrassingly+Simple+Approach+to+Visual+Domain+Adaptation+Lu,+Hao+and+Shen,+Chunhua+and+Cao,+Zhiguo+and+Xiao,+Yang+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=An+Embarrassingly+Simple+Approach+to+Visual+Domain+Adaptation semantic scholar][https://github.com/poppinace/ldada   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Zhang2018TMMxxxarXiv.jpg">}}*Multi-label image classification with regional latent semantic dependencies*   
\n$\cdot$ /J. Zhang, Q. Wu, C. Shen, J. Zhang, J. Lu/.
\n$\cdot$ /IEEE Transactions on Multimedia (TMM), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1612.01082    arXiv][data/bibtex/Zhang2018TMM.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Multi-Label+Image+Classification+with+Regional+Latent+Semantic+Dependencies+Zhang,+Junjie+and+Wu,+Qi+and+Shen,+Chunhua+and+Zhang,+Jian+and+Lu,+Jianfeng google scholar][https://www.semanticscholar.org/search?q=Multi-Label+Image+Classification+with+Regional+Latent+Semantic+Dependencies semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1712.09048.pdf"><img class="imgP  right"   src="data/thumbnail/Guo2018TMMxxxarXiv.jpg"></a>}}*Automatic image cropping for visual aesthetic enhancement using deep neural networks and cascaded regression*   
\n$\cdot$ /G. Guo, H. Wang, C. Shen, Y. Yan, H. Liao/.
\n$\cdot$ /IEEE Transactions on Multimedia (TMM), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1712.09048    arXiv][data/bibtex/Guo2018TMM.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Automatic+image+cropping+for+visual+aesthetic+enhancement+using+deep+neural+networks+and+cascaded+regression+Guo,+Guanjun+and+Wang,+Hanzi+and+Shen,+Chunhua+and+Yan,+Yan+and+Liao,+Hong-Yuan google scholar][https://www.semanticscholar.org/search?q=Automatic+image+cropping+for+visual+aesthetic+enhancement+using+deep+neural+networks+and+cascaded+regression semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Wang2017FVQAxxxarXiv.jpg">}}*FVQA: fact-based visual question answering*   
\n$\cdot$ /P. Wang, Q. Wu, C. Shen, A. Dick, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1606.05433    arXiv][data/bibtex/Wang2017FVQA.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={FVQA}:+Fact-based+Visual+Question+Answering+Wang,+Peng+and+Wu,+Qi+and+Shen,+Chunhua+and+Dick,+Anthony+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q={FVQA}:+Fact-based+Visual+Question+Answering semantic scholar]
. *Ordinal constraint binary coding for approximate nearest neighbor search*   
\n$\cdot$ /H. Liu, R. Ji, J. Wang, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2018/.
\n$\cdot$ [https://www.researchgate.net/publication/324053386_Ordinal_Constraint_Binary_Coding_for_Approximate_Nearest_Neighbor_Search  pdf][data/bibtex/HLiu2018TPAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Ordinal+Constraint+Binary+Coding+for+Approximate+Nearest+Neighbor+Search+Liu,+Hong+and+Ji,+Rongrong+and+Wang,+Jingdong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Ordinal+Constraint+Binary+Coding+for+Approximate+Nearest+Neighbor+Search semantic scholar]
== Conference
. *HCVRD: a benchmark for large-scale human-centered visual relationship detection*   
\n$\cdot$ /B. Zhuang, Q. Wu, C. Shen, I. Reid, A. van den Hengel/.
\n$\cdot$ /Proc. AAAI Conference on Artificial Intelligence (AAAI'18), 2018/.
\n$\cdot$ [data/bibtex/AAAI2018Zhuang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={HCVRD}:+a+benchmark+for+large-scale+Human-Centered+Visual+Relationship+Detection+Zhuang,+Bohan+and+Wu,+Qi+and+Shen,+Chunhua+and+Reid,+Ian+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q={HCVRD}:+a+benchmark+for+large-scale+Human-Centered+Visual+Relationship+Detection semantic scholar]
. *Kill two birds with one stone: weakly-supervised neural network for image annotation and tag refinement*   
\n$\cdot$ /J. Zhang, Q. Wu, J. Zhang, C. Shen, J. Lu/.
\n$\cdot$ /Proc. AAAI Conference on Artificial Intelligence (AAAI'18), 2018/.
\n$\cdot$ [data/bibtex/AAAI2018Zhang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Kill+Two+Birds+with+One+Stone:+Weakly-Supervised+Neural+Network+for+Image+Annotation+and+Tag+Refinement+Zhang,+Junjie+and+Wu,+Qi+and+Zhang,+Jian+and+Shen,+Chunhua+and+Lu,+Jianfeng google scholar][https://www.semanticscholar.org/search?q=Kill+Two+Birds+with+One+Stone:+Weakly-Supervised+Neural+Network+for+Image+Annotation+and+Tag+Refinement semantic scholar]
. *Coarse-to-fine: a RNN-based hierarchical attention model for vehicle re-identification*   
\n$\cdot$ /X. Wei, C. Zhang, L. Liu, C. Shen, J. Wu/.
\n$\cdot$ /Proc. Asian Conference on Computer Vision (ACCV'18), 2018/.
\n$\cdot$ [data/bibtex/ACCV18Wei.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Coarse-to-fine:+A+{RNN}-based+hierarchical+attention+model+for+vehicle+re-identification+Wei,+Xiu-Shen+and+Zhang,+Chen-Lin+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+Wu,+Jianxin google scholar][https://www.semanticscholar.org/search?q=Coarse-to-fine:+A+{RNN}-based+hierarchical+attention+model+for+vehicle+re-identification semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1807.03959.pdf"><img class="imgP  right"   src="data/thumbnail/ACCV18LixxxarXiv.jpg"></a>}}*Deep attention-based classification network for robust depth prediction*   
\n$\cdot$ /R. Li, K. Xian, C. Shen, Z. Cao, H. Lu, L. Hang/.
\n$\cdot$ /Proc. Asian Conference on Computer Vision (ACCV'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1807.03959    arXiv][data/bibtex/ACCV18Li.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+attention-based+classification+network+for+robust+depth+prediction+Li,+Ruibo+and+Xian,+Ke+and+Shen,+Chunhua+and+Cao,+Zhiguo+and+Lu,+Hao+and+Hang,+Lingxiao google scholar][https://www.semanticscholar.org/search?q=Deep+attention-based+classification+network+for+robust+depth+prediction semantic scholar]
. *Light-weight refinenet for real-time semantic segmentation*   
\n$\cdot$ /V. Nekrasov, C. Shen, I. Reid/.
\n$\cdot$ /Proc. British Machine Vision Conference (BMVC'18), 2018/.
\n$\cdot$ [data/bibtex/BMVC18Nekrasov.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Light-Weight+RefineNet+for+Real-Time+Semantic+Segmentation+Nekrasov,+Vladimir+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Light-Weight+RefineNet+for+Real-Time+Semantic+Segmentation semantic scholar][https://github.com/DrSleep/light-weight-refinenet   project webpage]
. *A hybrid probabilistic model for camera relocalization*   
\n$\cdot$ /M. Cai, C. Shen, I. Reid/.
\n$\cdot$ /Proc. British Machine Vision Conference (BMVC'18), 2018/.
\n$\cdot$ [data/bibtex/BMVC18Cai.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Hybrid+Probabilistic+Model+for+Camera+Relocalization+Cai,+Ming+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=A+Hybrid+Probabilistic+Model+for+Camera+Relocalization semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Zhuang2018CVPR_axxxarXiv.jpg">}}*Parallel attention: a unified framework for visual object discovery through dialogs and queries*   
\n$\cdot$ /B. Zhuang, Q. Wu, C. Shen, I. Reid, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1711.06370    arXiv][data/bibtex/Zhuang2018CVPR_a.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Parallel+Attention:+A+Unified+Framework+for+Visual+Object+Discovery+through+Dialogs+and+Queries+Zhuang,+Bohan+and+Wu,+Qi+and+Shen,+Chunhua+and+Reid,+Ian+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Parallel+Attention:+A+Unified+Framework+for+Visual+Object+Discovery+through+Dialogs+and+Queries semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Zhuang2018CVPR_bxxxarXiv.jpg">}}*Towards effective low-bitwidth convolutional neural networks*   
\n$\cdot$ /B. Zhuang, C. Shen, M. Tan, L. Liu, I. Reid/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1711.00205    arXiv][data/bibtex/Zhuang2018CVPR_b.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Towards+Effective+Low-bitwidth+Convolutional+Neural+Networks+Zhuang,+Bohan+and+Shen,+Chunhua+and+Tan,+Mingkui+and+Liu,+Lingqiao+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Towards+Effective+Low-bitwidth+Convolutional+Neural+Networks semantic scholar]
. *Monocular relative depth perception with web stereo data supervision*   
\n$\cdot$ /K. Xian, C. Shen, Z. Cao, H. Lu, Y. Xiao, R. Li, Z. Luo/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'18), 2018/.
\n$\cdot$ [data/bibtex/Xian2018CVPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Monocular+Relative+Depth+Perception+with+Web+Stereo+Data+Supervision+Xian,+Ke+and+Shen,+Chunhua+and+Cao,+Zhiguo+and+Lu,+Hao+and+Xiao,+Yang+and+Li,+Ruibo+and+Luo,+Zhenbo google scholar][https://www.semanticscholar.org/search?q=Monocular+Relative+Depth+Perception+with+Web+Stereo+Data+Supervision semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/QWu2018CVPRxxxarXiv.jpg">}}*Are you talking to me? reasoned visual dialog generation through adversarial learning*   
\n$\cdot$ /Q. Wu, P. Wang, C. Shen, I. Reid, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1711.07613    arXiv][data/bibtex/QWu2018CVPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Are+You+Talking+to+Me?+Reasoned+Visual+Dialog+Generation+through+Adversarial+Learning+Wu,+Qi+and+Wang,+Peng+and+Shen,+Chunhua+and+Reid,+Ian+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Are+You+Talking+to+Me?+Reasoned+Visual+Dialog+Generation+through+Adversarial+Learning semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Wang2018CVPRxxxarXiv.jpg">}}*Repulsion loss: detecting pedestrians in a crowd*   
\n$\cdot$ /X. Wang, T. Xiao, Y. Jiang, S. Shao, J. Sun, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1711.07752    arXiv][data/bibtex/Wang2018CVPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Repulsion+Loss:+Detecting+Pedestrians+in+a+Crowd+Wang,+Xinlong+and+Xiao,+Tete+and+Jiang,+Yuning+and+Shao,+Shuai+and+Sun,+Jian+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Repulsion+Loss:+Detecting+Pedestrians+in+a+Crowd semantic scholar]
        .. Others have implemented our paper: [https://github.com/bailvwangzi/repulsion_loss_ssd Repulsion loss in SSD] and [https://github.com/rainofmine/Repulsion_Loss Repulsion loss in RetinaNet].
. {{<img class="imgP  right"   src="data/thumbnail/Song2018CVPRxxxarXiv.jpg">}}*VITAL: visual tracking via adversarial learning*   
\n$\cdot$ /Y. Song, C. Ma, X. Wu, L. Gong, L. Bao, W. Zuo, C. Shen, R. Lau, M. Yang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1804.04273    arXiv][data/bibtex/Song2018CVPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={VITAL}:+VIsual+Tracking+via+Adversarial+Learning+Song,+Yibing+and+Ma,+Chao+and+Wu,+Xiaohe+and+Gong,+Lijun+and+Bao,+Linchao+and+Zuo,+Wangmeng+and+Shen,+Chunhua+and+Lau,+Rynson+and+Yang,+Ming-Hsuan google scholar][https://www.semanticscholar.org/search?q={VITAL}:+VIsual+Tracking+via+Adversarial+Learning semantic scholar][https://ybsong00.github.io/cvpr18_tracking/index   project webpage]
. *Bootstrapping the performance of webly supervised semantic segmentation*   
\n$\cdot$ /T. Shen, G. Lin, C. Shen, I. Reid/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'18), 2018/.
\n$\cdot$ [data/bibtex/TongShen2018CVPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Bootstrapping+the+Performance+of+Webly+Supervised+Semantic+Segmentation+Shen,+Tong+and+Lin,+Guosheng+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Bootstrapping+the+Performance+of+Webly+Supervised+Semantic+Segmentation semantic scholar][https://github.com/ascust/BDWSS   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Ma2018CVPR_axxxarXiv.jpg">}}*Visual question answering with memory-augmented networks*   
\n$\cdot$ /C. Ma, C. Shen, A. Dick, Q. Wu, P. Wang, A. van den Hengel, I. Reid/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1707.04968    arXiv][data/bibtex/Ma2018CVPR_a.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Visual+Question+Answering+with+Memory-Augmented+Networks+Ma,+Chao+and+Shen,+Chunhua+and+Dick,+Anthony+and+Wu,+Qi+and+Wang,+Peng+and+{van+den+Hengel},+Anton+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Visual+Question+Answering+with+Memory-Augmented+Networks semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/He2018CVPRxxxarXiv.jpg">}}*An end-to-end textspotter with explicit alignment and attention*   
\n$\cdot$ /T. He, Z. Tian, W. Huang, C. Shen, Y. Qiao, C. Sun/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1803.03474    arXiv][data/bibtex/He2018CVPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=An+end-to-end+TextSpotter+with+Explicit+Alignment+and+Attention+He,+Tong+and+Tian,+Zhi+and+Huang,+Weilin+and+Shen,+Chunhua+and+Qiao,+Yu+and+Sun,+Changming google scholar][https://www.semanticscholar.org/search?q=An+end-to-end+TextSpotter+with+Explicit+Alignment+and+Attention semantic scholar][https://github.com/tonghe90/textspotter   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1711.10703.pdf"><img class="imgP  right"   src="data/thumbnail/Chen2018CVPRxxxarXiv.jpg"></a>}}*FSRNet: end-to-end learning face super-resolution with facial priors*   
\n$\cdot$ /Y. Chen, Y. Tai, X. Liu, C. Shen, J. Yang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1711.10703    arXiv][data/bibtex/Chen2018CVPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={FSRNet}:+End-to-End+Learning+Face+Super-Resolution+with+Facial+Priors+Chen,+Yu+and+Tai,+Ying+and+Liu,+Xiaoming+and+Shen,+Chunhua+and+Yang,+Jian google scholar][https://www.semanticscholar.org/search?q={FSRNet}:+End-to-End+Learning+Face+Super-Resolution+with+Facial+Priors semantic scholar][https://github.com/tyshiwo/FSRNet   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Zhang2018ECCVxxxarXiv.jpg">}}*Goal-oriented visual question generation via intermediate rewards*   
\n$\cdot$ /J. Zhang, Q. Wu, C. Shen, J. Zhang, J. Lu, A. van den Hengel/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1711.07614    arXiv][data/bibtex/Zhang2018ECCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Goal-Oriented+Visual+Question+Generation+via+Intermediate+Rewards+Zhang,+Junjie+and+Wu,+Qi+and+Shen,+Chunhua+and+Zhang,+Jian+and+Lu,+Jianfeng+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Goal-Oriented+Visual+Question+Generation+via+Intermediate+Rewards semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1807.10097.pdf"><img class="imgP  right"   src="data/thumbnail/Deng2018ECCVxxxarXiv.jpg"></a>}}*Learning to predict crisp boundaries*   
\n$\cdot$ /R. Deng, C. Shen, S. Liu, H. Wang, X. Liu/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1807.10097    arXiv][data/bibtex/Deng2018ECCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+to+Predict+Crisp+Boundaries+Deng,+Ruoxi+and+Shen,+Chunhua+and+Liu,+Shengjun+and+Wang,+Huibing+and+Liu,+Xinru google scholar][https://www.semanticscholar.org/search?q=Learning+to+Predict+Crisp+Boundaries semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/ICASSP2018DongxxxarXiv.jpg">}}*Learning deep representations using convolutional auto-encoders with symmetric skip connections*   
\n$\cdot$ /L. Dong, Y. Gan, X. Mao, Y. Yang, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1611.09119    arXiv][data/bibtex/ICASSP2018Dong.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Deep+Representations+Using+Convolutional+Auto-Encoders+with+Symmetric+Skip+Connections+Dong,+Lian-Feng+and+Gan,+Yuan-Zhu+and+Mao,+Xiao-Liao+and+Yang,+Yu-Bin+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Learning+Deep+Representations+Using+Convolutional+Auto-Encoders+with+Symmetric+Skip+Connections semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1806.04895.pdf"><img class="imgP  right"   src="data/thumbnail/Cao2018ICMLxxxarXiv.jpg"></a>}}*Adversarial learning with local coordinate coding*   
\n$\cdot$ /J. Cao, Y. Guo, Q. Wu, C. Shen, J. Huang, M. Tan/.
\n$\cdot$ /Proc. International Conference on Machine Learning (ICML'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1806.04895    arXiv][data/bibtex/Cao2018ICML.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Adversarial+Learning+with+Local+Coordinate+Coding+Cao,+Jiezhang+and+Guo,+Yong+and+Wu,+Qingyao+and+Shen,+Chunhua+and+Huang,+Junzhou+and+Tan,+Mingkui google scholar][https://www.semanticscholar.org/search?q=Adversarial+Learning+with+Local+Coordinate+Coding semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Zhang2018IJCAIxxxarXiv.jpg">}}*Salient object detection by lossless feature reflection*   
\n$\cdot$ /P. Zhang, W. Liu, H. Lu, C. Shen/.
\n$\cdot$ /Proc. International Joint Conference on Artificial Intelligence (IJCAI'18), 2018/.
\n$\cdot$ [http://arxiv.org/abs/1802.06527    arXiv][data/bibtex/Zhang2018IJCAI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Salient+Object+Detection+by+Lossless+Feature+Reflection+Zhang,+Pingping+and+Liu,+Wei+and+Lu,+Huchuan+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Salient+Object+Detection+by+Lossless+Feature+Reflection semantic scholar]

= 2017
== Journal
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1607.05910.pdf"><img class="imgP  right"   src="data/thumbnail/CVIU2017VQAxxxarXiv.jpg"></a>}}*Visual question answering: a survey of methods and datasets*   
\n$\cdot$ /Q. Wu, D. Teney, P. Wang, C. Shen, A. Dick, A. van den Hengel/.
\n$\cdot$ /Computer Vision and Image Understanding (CVIU), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1607.05910    arXiv][data/bibtex/CVIU2017VQA.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Visual+question+answering:+A+survey+of+methods+and+datasets+Wu,+Qi+and+Teney,+Damien+and+Wang,+Peng+and+Shen,+Chunhua+and+Dick,+Anthony+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Visual+question+answering:+A+survey+of+methods+and+datasets semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/IJCV2017LinxxxarXiv.jpg">}}*Structured learning of binary codes with column generation for optimizing ranking measures*   
\n$\cdot$ /G. Lin, F. Liu, C. Shen, J. Wu, H. Shen/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1602.06654    arXiv][data/bibtex/IJCV2017Lin.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Structured+Learning+of+Binary+Codes+with+Column+Generation+for+Optimizing+Ranking+Measures+Lin,+Guosheng+and+Liu,+Fayao+and+Shen,+Chunhua+and+Wu,+Jianxin+and+Shen,+Heng+Tao google scholar][https://www.semanticscholar.org/search?q=Structured+Learning+of+Binary+Codes+with+Column+Generation+for+Optimizing+Ranking+Measures semantic scholar][https://bitbucket.org/guosheng/structhash   project webpage]
. *Removal of optically thick clouds from high-resolution satellite imagery using dictionary group learning and interdictionary nonlocal joint sparse coding*   
\n$\cdot$ /Y. Li, W. Li, C. Shen/.
\n$\cdot$ /IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (JSTAEORS), 2017/.
\n$\cdot$ [data/bibtex/Li2017Removal.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Removal+of+Optically+Thick+Clouds+From+High-resolution+Satellite+Imagery+Using+Dictionary+Group+Learning+and+Interdictionary+Nonlocal+Joint+Sparse+Coding+Li,+Ying+and+Li,+Wenbo+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Removal+of+Optically+Thick+Clouds+From+High-resolution+Satellite+Imagery+Using+Dictionary+Group+Learning+and+Interdictionary+Nonlocal+Joint+Sparse+Coding semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Lu2017CountingxxxarXiv.jpg">}}*TasselNet: counting maize tassels in the wild via local counts regression network*   
\n$\cdot$ /H. Lu, Z. Cao, Y. Xiao, B. Zhuang, C. Shen/.
\n$\cdot$ /Plant Methods (PLME), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1707.02290    arXiv][data/bibtex/Lu2017Counting.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={TasselNet}:+Counting+maize+tassels+in+the+wild+via+local+counts+regression+network+Lu,+Hao+and+Cao,+Zhiguo+and+Xiao,+Yang+and+Zhuang,+Bohan+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={TasselNet}:+Counting+maize+tassels+in+the+wild+via+local+counts+regression+network semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Wu2017PRxxxarXiv.jpg">}}*Deep linear discriminant analysis on Fisher networks: a hybrid architecture for person re-identification*   
\n$\cdot$ /L. Wu, C. Shen, A. van den Hengel/.
\n$\cdot$ /Pattern Recognition (PR), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1606.01595    arXiv][data/bibtex/Wu2017PR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+Linear+Discriminant+Analysis+on+{F}isher+Networks:+A+Hybrid+Architecture+for+Person+Re-identification+Wu,+Lin+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Deep+Linear+Discriminant+Analysis+on+{F}isher+Networks:+A+Hybrid+Architecture+for+Person+Re-identification semantic scholar]
. *Mask-CNN: localizing parts and selecting descriptors for bird species categorization*   
\n$\cdot$ /X. Wei, C. Xie, J. Wu, C. Shen/.
\n$\cdot$ /Pattern Recognition (PR), 2017/.
\n$\cdot$ [data/bibtex/Wei2017PR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Mask-{CNN}:+Localizing+parts+and+selecting+descriptors+for+bird+species+categorization+Wei,+Xiu-Shen+and+Xie,+Chen-Wei+and+Wu,+Jianxin+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Mask-{CNN}:+Localizing+parts+and+selecting+descriptors+for+bird+species+categorization semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/PR2017QiaoxxxarXiv.jpg">}}*Learning discriminative trajectorylet detector sets for accurate skeleton-based action recognition*   
\n$\cdot$ /R. Qiao, L. Liu, C. Shen, A. van den Hengel/.
\n$\cdot$ /Pattern Recognition (PR), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1504.04923    arXiv][data/bibtex/PR2017Qiao.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+discriminative+trajectorylet+detector+sets+for+accurate+skeleton-based+action+recognition+Qiao,+Ruizhi+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Learning+discriminative+trajectorylet+detector+sets+for+accurate+skeleton-based+action+recognition semantic scholar]
. *Deep CNNs with spatially weighted pooling for fine-grained car recognition*   
\n$\cdot$ /Q. Hu, H. Wang, T. Li, C. Shen/.
\n$\cdot$ /IEEE Transactions on Intelligent Transportation Systems (T-ITS), 2017/.
\n$\cdot$ [data/bibtex/SWP2017Hu.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+{CNNs}+with+Spatially+Weighted+Pooling+for+Fine-grained+Car+Recognition+Hu,+Qichang+and+Wang,+Huibing+and+Li,+Teng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Deep+{CNNs}+with+Spatially+Weighted+Pooling+for+Fine-grained+Car+Recognition semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/TCSVT2017ShengxxxarXiv.jpg">}}*Crowd counting via weighted VLAD on dense attribute feature maps*   
\n$\cdot$ /B. Sheng, C. Shen, G. Lin, J. Li, W. Yang, C. Sun/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1604.08660    arXiv][data/bibtex/TCSVT2017Sheng.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Crowd+Counting+via+Weighted+{VLAD}+on+Dense+Attribute+Feature+Maps+Sheng,+Biyun+and+Shen,+Chunhua+and+Lin,+Guosheng+and+Li,+Jun+and+Yang,+Wankou+and+Sun,+Changyin google scholar][https://www.semanticscholar.org/search?q=Crowd+Counting+via+Weighted+{VLAD}+on+Dense+Attribute+Feature+Maps semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1605.02305.pdf"><img class="imgP  right"   src="data/thumbnail/Cao2017xxxarXiv.jpg"></a>}}*Estimating depth from monocular images as classification using deep fully convolutional residual networks*   
\n$\cdot$ /Y. Cao, Z. Wu, C. Shen/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1605.02305    arXiv][data/bibtex/Cao2017.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Estimating+Depth+from+Monocular+Images+as+Classification+Using+Deep+Fully+Convolutional+Residual+Networks+Cao,+Yuanzhouhan+and+Wu,+Zifeng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Estimating+Depth+from+Monocular+Images+as+Classification+Using+Deep+Fully+Convolutional+Residual+Networks semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/TIP2017LiuxxxarXiv.jpg">}}*Discriminative training of deep fully-connected continuous CRF with task-specific loss*   
\n$\cdot$ /F. Liu, G. Lin, C. Shen/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1601.07649    arXiv][data/bibtex/TIP2017Liu.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Discriminative+Training+of+Deep+Fully-connected+Continuous+{CRF}+with+Task-specific+Loss+Liu,+Fayao+and+Lin,+Guosheng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Discriminative+Training+of+Deep+Fully-connected+Continuous+{CRF}+with+Task-specific+Loss semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/TIP2016CaoxxxarXiv.jpg">}}*Exploiting depth from single monocular images for object detection and semantic segmentation*   
\n$\cdot$ /Y. Cao, C. Shen, H. Shen/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1610.01706    arXiv][data/bibtex/TIP2016Cao.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Exploiting+Depth+from+Single+Monocular+Images+for+Object+Detection+and+Semantic+Segmentation+Cao,+Yuanzhouhan+and+Shen,+Chunhua+and+Shen,+Heng+Tao google scholar][https://www.semanticscholar.org/search?q=Exploiting+Depth+from+Single+Monocular+Images+for+Object+Detection+and+Semantic+Segmentation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/TNNLS2017LiuxxxarXiv.jpg">}}*Structured learning of tree potentials in CRF for image segmentation*   
\n$\cdot$ /F. Liu, G. Lin, R. Qiao, C. Shen/.
\n$\cdot$ /IEEE Transactions on Neural Networks and Learning Systems (TNN), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1703.08764    arXiv][data/bibtex/TNNLS2017Liu.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Structured+Learning+of+Tree+Potentials+in+{CRF}+for+Image+Segmentation+Liu,+Fayao+and+Lin,+Guosheng+and+Qiao,+Ruizhi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Structured+Learning+of+Tree+Potentials+in+{CRF}+for+Image+Segmentation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Wu2017ExternalxxxarXiv.jpg">}}*Image captioning and visual question answering based on attributes and external knowledge*   
\n$\cdot$ /Q. Wu, C. Shen, P. Wang, A. Dick, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1603.02814    arXiv][data/bibtex/Wu2017External.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Image+Captioning+and+Visual+Question+Answering+Based+on+Attributes+and+External+Knowledge+Wu,+Qi+and+Shen,+Chunhua+and+Wang,+Peng+and+Dick,+Anthony+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Image+Captioning+and+Visual+Question+Answering+Based+on+Attributes+and+External+Knowledge semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/TPAMI2017LiuxxxarXiv.jpg">}}*Compositional model based Fisher vector coding for image classification*   
\n$\cdot$ /L. Liu, P. Wang, C. Shen, L. Wang, A. van den Hengel, C. Wang, H. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1601.04143    arXiv][data/bibtex/TPAMI2017Liu.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Compositional+Model+based+{F}isher+Vector+Coding+for+Image+Classification+Liu,+Lingqiao+and+Wang,+Peng+and+Shen,+Chunhua+and+Wang,+Lei+and+{van+den+Hengel},+Anton+and+Wang,+Chao+and+Shen,+Heng+Tao google scholar][https://www.semanticscholar.org/search?q=Compositional+Model+based+{F}isher+Vector+Coding+for+Image+Classification semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1510.00921.pdf"><img class="imgP  right"   src="data/thumbnail/Cross2017LiuxxxarXiv.jpg"></a>}}*Cross-convolutional-layer pooling for image recognition*   
\n$\cdot$ /L. Liu, C. Shen, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1510.00921    arXiv][http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7779086  link][data/bibtex/Cross2017Liu.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Cross-convolutional-layer+Pooling+for+Image+Recognition+Liu,+Lingqiao+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Cross-convolutional-layer+Pooling+for+Image+Recognition semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Lin2017SemanticxxxarXiv.jpg">}}*Exploring context with deep structured models for semantic segmentation*   
\n$\cdot$ /G. Lin, C. Shen, A. van den Hengel, I. Reid/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1603.03183    arXiv][data/bibtex/Lin2017Semantic.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Exploring+Context+with+Deep+Structured+models+for+Semantic+Segmentation+Lin,+Guosheng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Exploring+Context+with+Deep+Structured+models+for+Semantic+Segmentation semantic scholar]
== Conference
. *Auxiliary tasks to improve trip hazard affordance detection*   
\n$\cdot$ /S. McMahon, T. Shen, N. Sunderhauf, I. Reid, C. Shen, M. Milford/.
\n$\cdot$ /Proc. Australasian Conference on Robotics and Automation (ACRA'17), 2017/.
\n$\cdot$ [data/bibtex/ACRA2017McMahon.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Auxiliary+Tasks+To+Improve+Trip+Hazard+Affordance+Detection+{McMahon},+Sean+and+Shen,+Tong+and+Sunderhauf,+Niko+and+Reid,+Ian+and+Shen,+Chunhua+and+Milford,+Michael google scholar][https://www.semanticscholar.org/search?q=Auxiliary+Tasks+To+Improve+Trip+Hazard+Affordance+Detection semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1701.07122.pdf"><img class="imgP  right"   src="data/thumbnail/BMVC2017TongxxxarXiv.jpg"></a>}}*Weakly supervised semantic segmentation based on co-segmentation*   
\n$\cdot$ /T. Shen, G. Lin, L. Liu, C. Shen, I. Reid/.
\n$\cdot$ /Proc. British Machine Vision Conference (BMVC'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1701.07122    arXiv][data/bibtex/BMVC2017Tong.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Weakly+supervised+semantic+segmentation+based+on+co-segmentation+Shen,+Tong+and+Lin,+Guosheng+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Weakly+supervised+semantic+segmentation+based+on+co-segmentation semantic scholar]
. *Visually aligned word embeddings for improving zero-shot learning*   
\n$\cdot$ /R. Qiao, L. Liu, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. British Machine Vision Conference (BMVC'17), 2017/.
\n$\cdot$ [data/bibtex/BMVC17Zeroshot.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Visually+Aligned+Word+Embeddings+for+Improving+Zero-shot+Learning+Qiao,+Ruizhi+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Visually+Aligned+Word+Embeddings+for+Improving+Zero-shot+Learning semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1611.09960.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2017ZhuangxxxarXiv.jpg"></a>}}*Attend in groups: a weakly-supervised deep learning framework for learning from web data*   
\n$\cdot$ /B. Zhuang, L. Liu, Y. Li, C. Shen, I. Reid/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1611.09960    arXiv][data/bibtex/CVPR2017Zhuang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Attend+in+groups:+a+weakly-supervised+deep+learning+framework+for+learning+from+web+data+Zhuang,+Bohan+and+Liu,+Lingqiao+and+Li,+Yao+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Attend+in+groups:+a+weakly-supervised+deep+learning+framework+for+learning+from+web+data semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1612.05386.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2017WangVQAxxxarXiv.jpg"></a>}}*The VQA-machine: learning how to use existing vision algorithms to answer new questions*   
\n$\cdot$ /P. Wang, Q. Wu, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1612.05386    arXiv][data/bibtex/CVPR2017WangVQA.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=The+{VQA}-Machine:+Learning+How+to+Use+Existing+Vision+Algorithms+to+Answer+New+Questions+Wang,+Peng+and+Wu,+Qi+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=The+{VQA}-Machine:+Learning+How+to+Use+Existing+Vision+Algorithms+to+Answer+New+Questions semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/CVPR2017WangAttendxxxPDF.jpg">}}*Multi-attention network for one shot learning*   
\n$\cdot$ /P. Wang, L. Liu, C. Shen, Z. Huang, A. van den Hengel, H. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'17), 2017/.
\n$\cdot$ [http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_Multi-Attention_Network_for_CVPR_2017_paper.pdf  pdf][data/bibtex/CVPR2017WangAttend.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Multi-attention+Network+for+One+Shot+Learning+Wang,+Peng+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+Huang,+Zi+and+{van+den+Hengel},+Anton+and+Shen,+Heng+Tao google scholar][https://www.semanticscholar.org/search?q=Multi-attention+Network+for+One+Shot+Learning semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1611.06612.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2017LinxxxarXiv.jpg"></a>}}*RefineNet: multi-path refinement networks for high-resolution semantic segmentation*   
\n$\cdot$ /G. Lin, A. Milan, C. Shen, I. Reid/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1611.06612    arXiv][data/bibtex/CVPR2017Lin.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={RefineNet}:+Multi-Path+Refinement+Networks+for+High-Resolution+Semantic+Segmentation+Lin,+Guosheng+and+Milan,+Anton+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q={RefineNet}:+Multi-Path+Refinement+Networks+for+High-Resolution+Semantic+Segmentation semantic scholar][https://github.com/guosheng/refinenet   project webpage]
        .. [https://github.com/DrSleep/light-weight-refinenet Light-weight RefineNet with Pytorch code].
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1611.09967.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2017YaoLixxxarXiv.jpg"></a>}}*Sequential person recognition in photo albums with a recurrent network*   
\n$\cdot$ /Y. Li, G. Lin, B. Zhuang, L. Liu, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1611.09967    arXiv][data/bibtex/CVPR2017YaoLi.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Sequential+Person+Recognition+in+Photo+Albums+with+a+Recurrent+Network+Li,+Yao+and+Lin,+Guosheng+and+Zhuang,+Bohan+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Sequential+Person+Recognition+in+Photo+Albums+with+a+Recurrent+Network semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1612.02583.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR2017GongxxxarXiv.jpg"></a>}}*From motion blur to motion flow: a deep learning solution for removing heterogeneous motion blur*   
\n$\cdot$ /D. Gong, J. Yang, L. Liu, Y. Zhang, I. Reid, C. Shen, A. van den Hengel, Q. Shi/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1612.02583    arXiv][data/bibtex/CVPR2017Gong.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=From+Motion+Blur+to+Motion+Flow:+a+Deep+Learning+Solution+for+Removing+Heterogeneous+Motion+Blur+Gong,+Dong+and+Yang,+Jie+and+Liu,+Lingqiao+and+Zhang,+Yanning+and+Reid,+Ian+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Shi,+Qinfeng google scholar][https://www.semanticscholar.org/search?q=From+Motion+Blur+to+Motion+Flow:+a+Deep+Learning+Solution+for+Removing+Heterogeneous+Motion+Blur semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/ICCV2017ZhuangxxxarXiv.jpg">}}*Towards context-aware interaction recognition*   
\n$\cdot$ /B. Zhuang, L. Liu, C. Shen, I. Reid/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1703.06246    arXiv][data/bibtex/ICCV2017Zhuang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Towards+Context-aware+Interaction+Recognition+Zhuang,+Bohan+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Towards+Context-aware+Interaction+Recognition semantic scholar]
. *When unsupervised domain adaptation meets tensor representations*   
\n$\cdot$ /H. Lu, L. Zhang, Z. Cao, W. Wei, K. Xian, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'17), 2017/.
\n$\cdot$ [data/bibtex/ICCV2017Haolu.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=When+Unsupervised+Domain+Adaptation+Meets+Tensor+Representations+Lu,+Hao+and+Zhang,+Lei+and+Cao,+Zhiguo+and+Wei,+Wei+and+Xian,+Ke+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=When+Unsupervised+Domain+Adaptation+Meets+Tensor+Representations semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/ICCV2017WeiLiuxxxarXiv.jpg">}}*Semi-global weighted least squares in image filtering*   
\n$\cdot$ /W. Liu, X. Chen, C. Shen, Z. Liu, J. Yang/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1705.01674    arXiv][data/bibtex/ICCV2017WeiLiu.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Semi-Global+Weighted+Least+Squares+in+Image+Filtering+Liu,+Wei+and+Chen,+Xiaogang+and+Shen,+Chuanhua+and+Liu,+Zhi+and+Yang,+Jie google scholar][https://www.semanticscholar.org/search?q=Semi-Global+Weighted+Least+Squares+in+Image+Filtering semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/ICCV2017HuiLixxxarXiv.jpg">}}*Towards end-to-end text spotting with convolutional recurrent neural networks*   
\n$\cdot$ /H. Li, P. Wang, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1707.03985    arXiv][data/bibtex/ICCV2017HuiLi.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Towards+End-to-end+Text+Spotting+with+Convolutional+Recurrent+Neural+Networks+Li,+Hui+and+Wang,+Peng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Towards+End-to-end+Text+Spotting+with+Convolutional+Recurrent+Neural+Networks semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/ICCV2017ChenxxxarXiv.jpg">}}*Adversarial PoseNet: a structure-aware convolutional network for human pose estimation*   
\n$\cdot$ /Y. Chen, C. Shen, X. Wei, L. Liu, J. Yang/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1705.00389    arXiv][data/bibtex/ICCV2017Chen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Adversarial+{PoseNet}:+A+Structure-aware+Convolutional+Network+for+Human+Pose+Estimation+Chen,+Yu+and+Shen,+Chunhua+and+Wei,+Xiu-Shen+and+Liu,+Lingqiao+and+Yang,+Jian google scholar][https://www.semanticscholar.org/search?q=Adversarial+{PoseNet}:+A+Structure-aware+Convolutional+Network+for+Human+Pose+Estimation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/ICRA2017ChenxxxarXiv.jpg">}}*Deep learning features at scale for visual place recognition*   
\n$\cdot$ /Z. Chen, A. Jacobson, N. Sunderhauf, B. Upcroft, L. Liu, C. Shen, I. Reid, M. Milford/.
\n$\cdot$ /Proc. IEEE International Conference on Robotics and Automation (ICRA'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1701.05105    arXiv][data/bibtex/ICRA2017Chen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+Learning+Features+at+Scale+for+Visual+Place+Recognition+Chen,+Zetao+and+Jacobson,+Adam+and+Sunderhauf,+Niko+and+Upcroft,+Ben+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+Reid,+Ian+and+Milford,+Michael google scholar][https://www.semanticscholar.org/search?q=Deep+Learning+Features+at+Scale+for+Visual+Place+Recognition semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/IJCAI2017WeixxxarXiv.jpg">}}*Deep descriptor transforming for image co-localization*   
\n$\cdot$ /X. Wei, C. Zhang, Y. Li, C. Xie, J. Wu, C. Shen, Z. Zhou/.
\n$\cdot$ /Proc. International Joint Conference on Artificial Intelligence (IJCAI'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1705.02758    arXiv][data/bibtex/IJCAI2017Wei.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+Descriptor+Transforming+for+Image+Co-Localization+Wei,+Xiu-Shen+and+Zhang,+Chen-Lin+and+Li,+Yao+and+Xie,+Chen-Wei+and+Wu,+Jianxin+and+Shen,+Chunhua+and+Zhou,+Zhi-Hua google scholar][https://www.semanticscholar.org/search?q=Deep+Descriptor+Transforming+for+Image+Co-Localization semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/IJCAI2017WangxxxarXiv.jpg">}}*Explicit knowledge-based reasoning for visual question answering*   
\n$\cdot$ /P. Wang, Q. Wu, C. Shen, A. van den Hengel, A. Dick/.
\n$\cdot$ /Proc. International Joint Conference on Artificial Intelligence (IJCAI'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1511.02570    arXiv][data/bibtex/IJCAI2017Wang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Explicit+Knowledge-based+Reasoning+for+Visual+Question+Answering+Wang,+Peng+and+Wu,+Qi+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Dick,+Anthony google scholar][https://www.semanticscholar.org/search?q=Explicit+Knowledge-based+Reasoning+for+Visual+Question+Answering semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/IJCAI2017TongxxxarXiv.jpg">}}*Learning multi-level region consistency with dense multi-label networks for semantic segmentation*   
\n$\cdot$ /T. Shen, G. Lin, C. Shen, I. Reid/.
\n$\cdot$ /Proc. International Joint Conference on Artificial Intelligence (IJCAI'17), 2017/.
\n$\cdot$ [http://arxiv.org/abs/1701.07122    arXiv][data/bibtex/IJCAI2017Tong.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Multi-level+Region+Consistency+with+Dense+Multi-label+Networks+for+Semantic+Segmentation+Shen,+Tong+and+Lin,+Guosheng+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Learning+Multi-level+Region+Consistency+with+Dense+Multi-label+Networks+for+Semantic+Segmentation semantic scholar]

= 2016
== Journal
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1511.08531.pdf"><img class="imgP  right"   src="data/thumbnail/CVIU2016xxxarXiv.jpg"></a>}}*Structured learning of metric ensembles with application to person re-identification*   
\n$\cdot$ /S. Paisitkriangkrai, L. Wu, C. Shen, A. van den Hengel/.
\n$\cdot$ /Computer Vision and Image Understanding (CVIU), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1511.08531    arXiv][data/bibtex/CVIU2016.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Structured+learning+of+metric+ensembles+with+application+to+person+re-identification+Paisitkriangkrai,+Sakrapee+and+Wu,+Lin+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Structured+learning+of+metric+ensembles+with+application+to+person+re-identification semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Zhang2015IJCVxxxarXiv.jpg">}}*Unsupervised feature learning for dense correspondences across scenes*   
\n$\cdot$ /C. Zhang, C. Shen, T. Shen/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1501.00642    arXiv][data/bibtex/Zhang2015IJCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Unsupervised+Feature+Learning+for+Dense+Correspondences+across+Scenes+Zhang,+Chao+and+Shen,+Chunhua+and+Shen,+Tingzhi google scholar][https://www.semanticscholar.org/search?q=Unsupervised+Feature+Learning+for+Dense+Correspondences+across+Scenes semantic scholar][https://bitbucket.org/chhshen/ufl   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1404.5009.pdf"><img class="imgP  right"   src="data/thumbnail/BnB2015WangxxxarXiv.jpg"></a>}}*Efficient semidefinite branch-and-cut for MAP-MRF inference*   
\n$\cdot$ /P. Wang, C. Shen, A. van den Hengel, P. Torr/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1404.5009    arXiv][http://doi.org/10.1007/s11263-015-0865-2  link][data/bibtex/BnB2015Wang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Efficient+Semidefinite+Branch-and-Cut+for+{MAP-MRF}+Inference+Wang,+Peng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Torr,+Philip google scholar][https://www.semanticscholar.org/search?q=Efficient+Semidefinite+Branch-and-Cut+for+{MAP-MRF}+Inference semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Yao2016IJCVxxxarXiv.jpg">}}*Mining mid-level visual patterns with deep CNN activations*   
\n$\cdot$ /Y. Li, L. Liu, C. Shen, A. van den Hengel/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1506.06343    arXiv][http://rdcu.be/j1mA  link][data/bibtex/Yao2016IJCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Mining+Mid-level+Visual+Patterns+with+Deep+{CNN}+Activations+Li,+Yao+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Mining+Mid-level+Visual+Patterns+with+Deep+{CNN}+Activations semantic scholar][https://github.com/yaoliUoA/MDPM   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Liu2016TrackingxxxarXiv.jpg">}}*Online unsupervised feature learning for visual tracking*   
\n$\cdot$ /F. Liu, C. Shen, I. Reid, A. van den Hengel/.
\n$\cdot$ /Image and Vision Computing (IVC), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1310.1690    arXiv][data/bibtex/Liu2016Tracking.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Online+Unsupervised+Feature+Learning+for+Visual+Tracking+Liu,+Fayao+and+Shen,+Chunhua+and+Reid,+Ian+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Online+Unsupervised+Feature+Learning+for+Visual+Tracking semantic scholar]
. *Canonical principal angles correlation analysis for two-view data*   
\n$\cdot$ /S. Wang, J. Lu, X. Gu, C. Shen, R. Xia, J. Yang/.
\n$\cdot$ /Journal of Visual Communication and Image Representation (JVCIR), 2016/.
\n$\cdot$ [http://dx.doi.org/10.1016/j.jvcir.2015.12.001  link][data/bibtex/Canonical2016Wang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Canonical+principal+angles+correlation+analysis+for+two-view+data+Wang,+Sheng+and+Lu,+Jianfeng+and+Gu,+Xingjian+and+Shen,+Chunhua+and+Xia,+Rui+and+Yang,+Jingyu google scholar][https://www.semanticscholar.org/search?q=Canonical+principal+angles+correlation+analysis+for+two-view+data semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/PRFace2016ShenxxxarXiv.jpg">}}*Face image classification by pooling raw features*   
\n$\cdot$ /F. Shen, C. Shen, X. Zhou, Y. Yang, H. Shen/.
\n$\cdot$ /Pattern Recognition (PR), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1406.6811    arXiv][data/bibtex/PRFace2016Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Face+Image+Classification+by+Pooling+Raw+Features+Shen,+Fumin+and+Shen,+Chunhua+and+Zhou,+Xiang+and+Yang,+Yang+and+Shen,+Heng+Tao google scholar][https://www.semanticscholar.org/search?q=Face+Image+Classification+by+Pooling+Raw+Features semantic scholar][https://github.com/bd622/FacePooling   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1110.0264.pdf"><img class="imgP  right"   src="data/thumbnail/Face2016LixxxarXiv.jpg"></a>}}*Face recognition using linear representation ensembles*   
\n$\cdot$ /H. Li, F. Shen, C. Shen, Y. Yang, Y. Gao/.
\n$\cdot$ /Pattern Recognition (PR), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1110.0264    arXiv][http://dx.doi.org/10.1016/j.patcog.2015.12.011  link][data/bibtex/Face2016Li.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Face+Recognition+Using+Linear+Representation+Ensembles+Li,+Hanxi+and+Shen,+Fumin+and+Shen,+Chunhua+and+Yang,+Yang+and+Gao,+Yongsheng google scholar][https://www.semanticscholar.org/search?q=Face+Recognition+Using+Linear+Representation+Ensembles semantic scholar]
. *Fast detection of multiple objects in traffic scenes with a common detection framework*   
\n$\cdot$ /Q. Hu, S. Paisitkriangkrai, C. Shen, A. van den Hengel, F. Porikli/.
\n$\cdot$ /IEEE Transactions on Intelligent Transportation Systems (T-ITS), 2016/.
\n$\cdot$ [data/bibtex/Hu2015T-ITS.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fast+Detection+of+Multiple+Objects+in+Traffic+Scenes+with+a+Common+Detection+Framework+Hu,+Qichang+and+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Porikli,+Fatih google scholar][https://www.semanticscholar.org/search?q=Fast+Detection+of+Multiple+Objects+in+Traffic+Scenes+with+a+Common+Detection+Framework semantic scholar]
. *Part-based robust tracking using online latent structured learning*   
\n$\cdot$ /R. Yao, Q. Shi, C. Shen, Y. Zhang, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2016/.
\n$\cdot$ [http://dx.doi.org/10.1109/TCSVT.2016.2527358  link][data/bibtex/Part2016Yao.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Part-based+robust+tracking+using+online+latent+structured+learning+Yao,+Rui+and+Shi,+Qinfeng+and+Shen,+Chunhua+and+Zhang,+Yanning+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Part-based+robust+tracking+using+online+latent+structured+learning semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Pooling2016WangxxxarXiv.jpg">}}*Temporal pyramid pooling based convolutional neural network for action recognition*   
\n$\cdot$ /P. Wang, Y. Cao, C. Shen, L. Liu, H. Shen/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1503.01224    arXiv][data/bibtex/Pooling2016Wang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Temporal+Pyramid+Pooling+Based+Convolutional+Neural+Network+for+Action+Recognition+Wang,+Peng+and+Cao,+Yuanzhouhan+and+Shen,+Chunhua+and+Liu,+Lingqiao+and+Shen,+Heng+Tao google scholar][https://www.semanticscholar.org/search?q=Temporal+Pyramid+Pooling+Based+Convolutional+Neural+Network+for+Action+Recognition semantic scholar]
. *Dictionary learning for promoting structured sparsity in hyerpsectral compressive sensing*   
\n$\cdot$ /L. Zhang, W. Wei, Y. Zhang, C. Shen, A. van den Hengel, Q. Shi/.
\n$\cdot$ /IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2016/.
\n$\cdot$ [data/bibtex/Zhang2016TGSE.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Dictionary+Learning+for+Promoting+Structured+Sparsity+in+Hyerpsectral+Compressive+Sensing+Zhang,+Lei+and+Wei,+Wei+and+Zhang,+Yanning+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Shi,+Qinfeng google scholar][https://www.semanticscholar.org/search?q=Dictionary+Learning+for+Promoting+Structured+Sparsity+in+Hyerpsectral+Compressive+Sensing semantic scholar]
. *Scalable linear visual feature learning via online parallel nonnegative matrix factorization*   
\n$\cdot$ /X. Zhao, X. Li, Z. Zhang, C. Shen, L. Gao, X. Li/.
\n$\cdot$ /IEEE Transactions on Neural Networks and Learning Systems (TNN), 2016/.
\n$\cdot$ [http://dx.doi.org/10.1109/TNNLS.2015.2499273  link][data/bibtex/Zhao2015TNN.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Scalable+Linear+Visual+Feature+Learning+via+Online+Parallel+Nonnegative+Matrix+Factorization+Zhao,+Xueyi+and+Li,+Xi+and+Zhang,+Zhongfei+and+Shen,+Chunhua+and+Gao,+Lixin+and+Li,+Xuelong google scholar][https://www.semanticscholar.org/search?q=Scalable+Linear+Visual+Feature+Learning+via+Online+Parallel+Nonnegative+Matrix+Factorization semantic scholar]
. *Large-scale binary quadratic optimization using semidefinite relaxation and applications*   
\n$\cdot$ /P. Wang, C. Shen, A. van den Hengel, P. Torr/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1411.7564    arXiv][http://dx.doi.org/10.1109/TPAMI.2016.2541146  link][data/bibtex/BQP2015Wang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Large-scale+Binary+Quadratic+Optimization+Using+Semidefinite+Relaxation+and+Applications+Wang,+Peng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Torr,+Philip+H.+S. google scholar][https://www.semanticscholar.org/search?q=Large-scale+Binary+Quadratic+Optimization+Using+Semidefinite+Relaxation+and+Applications semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Paisitkriangkrai2015TPAMIxxxarXiv.jpg">}}*Pedestrian detection with spatially pooled features and structured ensemble learning*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1409.5209    arXiv][http://doi.org/10.1109/TPAMI.2015.2474388  link][data/bibtex/Paisitkriangkrai2015TPAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Pedestrian+Detection+with+Spatially+Pooled+Features+and+Structured+Ensemble+Learning+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Pedestrian+Detection+with+Spatially+Pooled+Features+and+Structured+Ensemble+Learning semantic scholar][https://github.com/chhshen/pedestrian-detection   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Liu2015TPAMIxxxarXiv.jpg">}}*A generalized probabilistic framework for compact codebook creation*   
\n$\cdot$ /L. Liu, L. Wang, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1401.7713    arXiv][http://doi.org/10.1109/TPAMI.2015.2441069  link][data/bibtex/Liu2015TPAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Generalized+Probabilistic+Framework+for+Compact+Codebook+Creation+Liu,+Lingqiao+and+Wang,+Lei+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=A+Generalized+Probabilistic+Framework+for+Compact+Codebook+Creation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Depth2015LiuxxxarXiv.jpg">}}*Learning depth from single monocular images using deep convolutional neural fields*   
\n$\cdot$ /F. Liu, C. Shen, G. Lin, I. Reid/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1502.07411    arXiv][http://dx.doi.org/10.1109/TPAMI.2015.2505283  link][data/bibtex/Depth2015Liu.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Depth+from+Single+Monocular+Images+Using+Deep+Convolutional+Neural+Fields+Liu,+Fayao+and+Shen,+Chunhua+and+Lin,+Guosheng+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Learning+Depth+from+Single+Monocular+Images+Using+Deep+Convolutional+Neural+Fields semantic scholar][http://goo.gl/rAKWrS   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Xi2015TPAMIxxxarXiv.jpg">}}*Online metric-weighted linear representations for robust visual tracking*   
\n$\cdot$ /X. Li, C. Shen, A. Dick, Z. Zhang, Y. Zhuang/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1507.05737    arXiv][data/bibtex/Xi2015TPAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Online+Metric-Weighted+Linear+Representations+for+Robust+Visual+Tracking+Li,+Xi+and+Shen,+Chunhua+and+Dick,+Anthony+and+Zhang,+Zhongfei+and+Zhuang,+Yueting google scholar][https://www.semanticscholar.org/search?q=Online+Metric-Weighted+Linear+Representations+for+Robust+Visual+Tracking semantic scholar]
== Conference
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1603.02844.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR16BinaryxxxarXiv.jpg"></a>}}*Fast training of triplet-based deep binary embedding networks*   
\n$\cdot$ /B. Zhuang, G. Lin, C. Shen, I. Reid/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'16), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1603.02844    arXiv][data/bibtex/CVPR16Binary.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fast+Training+of+Triplet-based+Deep+Binary+Embedding+Networks+Zhuang,+Bohan+and+Lin,+Guosheng+and+Shen,+Chunhua+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Fast+Training+of+Triplet-based+Deep+Binary+Embedding+Networks semantic scholar][https://bitbucket.org/jingruixiaozhuang/fast-training-of-triplet-based-deep-binary-embedding-networks   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1511.06973.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR16AMAxxxarXiv.jpg"></a>}}*Ask me anything: free-form visual question answering based on knowledge from external sources*   
\n$\cdot$ /Q. Wu, P. Wang, C. Shen, A. Dick, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'16), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1511.06973    arXiv][data/bibtex/CVPR16AMA.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Ask+Me+Anything:+Free-form+Visual+Question+Answering+Based+on+Knowledge+from+External+Sources+Wu,+Qi+and+Wang,+Peng+and+Shen,+Chunhua+and+Dick,+Anthony+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Ask+Me+Anything:+Free-form+Visual+Question+Answering+Based+on+Knowledge+from+External+Sources semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1506.01144.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR16WhatxxxarXiv.jpg"></a>}}*What value do explicit high level concepts have in vision to language problems*   
\n$\cdot$ /Q. Wu, C. Shen, L. Liu, A. Dick, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'16), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1506.01144    arXiv][data/bibtex/CVPR16What.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=What+Value+Do+Explicit+High+Level+Concepts+Have+in+Vision+to+Language+Problems+Wu,+Qi+and+Shen,+Chunhua+and+Liu,+Lingqiao+and+Dick,+Anthony+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=What+Value+Do+Explicit+High+Level+Concepts+Have+in+Vision+to+Language+Problems semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1602.04422.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR16IrregularxxxarXiv.jpg"></a>}}*What's wrong with that object? identifying irregular object from images by modelling the detection score distribution*   
\n$\cdot$ /P. Wang, L. Liu, C. Shen, Z. Huang, A. van den Hengel, H. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'16), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1602.04422    arXiv][data/bibtex/CVPR16Irregular.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=What's+Wrong+with+that+Object?+Identifying+Irregular+Object+From+Images+by+Modelling+the+Detection+Score+Distribution+Wang,+Peng+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+Huang,+Zi+and+{van+den+Hengel},+Anton+and+Shen,+Heng+Tao google scholar][https://www.semanticscholar.org/search?q=What's+Wrong+with+that+Object?+Identifying+Irregular+Object+From+Images+by+Modelling+the+Detection+Score+Distribution semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1604.01146.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR16ZeroshotxxxarXiv.jpg"></a>}}*Less is more: zero-shot learning from online textual documents with noise suppression*   
\n$\cdot$ /R. Qiao, L. Liu, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'16), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1604.01146    arXiv][data/bibtex/CVPR16Zeroshot.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Less+is+More:+Zero-shot+Learning+from+Online+Textual+Documents+with+Noise+Suppression+Qiao,+Ruizhi+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Less+is+More:+Zero-shot+Learning+from+Online+Textual+Documents+with+Noise+Suppression semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1504.01013.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR16labellingxxxarXiv.jpg"></a>}}*Efficient piecewise training of deep structured models for semantic segmentation*   
\n$\cdot$ /G. Lin, C. Shen, A. van dan Hengel, I. Reid/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'16), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1504.01013    arXiv][data/bibtex/CVPR16labelling.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Efficient+piecewise+training+of+deep+structured+models+for+semantic+segmentation+Lin,+Guosheng+and+Shen,+Chunhua+and+{van+dan+Hengel},+Anton+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Efficient+piecewise+training+of+deep+structured+models+for+semantic+segmentation semantic scholar]
. *Cluster sparsity field for hyperspectral imagery denoising*   
\n$\cdot$ /L. Zhang, W. Wei, Y. Zhang, C. Shen, A. van den Hengel, Q. Shi/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'16), 2016/.
\n$\cdot$ [data/bibtex/ECCV16hyperspectral.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Cluster+Sparsity+Field+for+Hyperspectral+Imagery+Denoising+Zhang,+Lei+and+Wei,+Wei+and+Zhang,+Yanning+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Shi,+Qinfeng google scholar][https://www.semanticscholar.org/search?q=Cluster+Sparsity+Field+for+Hyperspectral+Imagery+Denoising semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/ECCV16LixxxarXiv.jpg">}}*Image co-localization by mimicking a good detector's confidence score distribution*   
\n$\cdot$ /Y. Li, L. Liu, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'16), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1603.04619    arXiv][data/bibtex/ECCV16Li.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Image+Co-localization+by+Mimicking+a+Good+Detector's+Confidence+Score+Distribution+Li,+Yao+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Image+Co-localization+by+Mimicking+a+Good+Detector's+Confidence+Score+Distribution semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/NeurIPS2016xxxPDF.jpg">}}*Image restoration using very deep fully convolutional encoder-decoder networks with symmetric skip connections*   
\n$\cdot$ /X. Mao, C. Shen, Y. Yang/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'16), 2016/.
\n$\cdot$ [http://arxiv.org/abs/1603.09056    arXiv][http://papers.NeurIPS.cc/paper/6172-image-restoration-using-very-deep-convolutional-encoder-decoder-networks-with-symmetric-skip-connections.pdf  link][data/bibtex/NeurIPS2016.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Image+Restoration+Using+Very+Deep+Fully+Convolutional+Encoder-Decoder+Networks+with+Symmetric+Skip+Connections+Mao,+Xiao-Jiao+and+Shen,+Chunhua+and+Yang,+Yu-Bin google scholar][https://www.semanticscholar.org/search?q=Image+Restoration+Using+Very+Deep+Fully+Convolutional+Encoder-Decoder+Networks+with+Symmetric+Skip+Connections semantic scholar][https://bitbucket.org/chhshen/image-denoising/   project webpage]
        .. Others have [https://github.com/titu1994/Image-Super-Resolution implemented our paper].

= 2015
== Journal
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1401.8126.pdf"><img class="imgP  right"   src="data/thumbnail/Harandi2015IJCVxxxarXiv.jpg"></a>}}*Extrinsic methods for coding and dictionary learning on Grassmann manifolds*   
\n$\cdot$ /M. Harandi, R. Hartley, C. Shen, B. Lovell, C. Sanderson/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2015/.
\n$\cdot$ [http://arxiv.org/abs/1401.8126    arXiv][data/bibtex/Harandi2015IJCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Extrinsic+Methods+for+Coding+and+Dictionary+Learning+on+{G}rassmann+Manifolds+Harandi,+Mehrtash+and+Hartley,+Richard+and+Shen,+Chunhua+and+Lovell,+Brian+and+Sanderson,+Conrad google scholar][https://www.semanticscholar.org/search?q=Extrinsic+Methods+for+Coding+and+Dictionary+Learning+on+{G}rassmann+Manifolds semantic scholar][https://github.com/chhshen/Grassmann/   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Liu2015CRFPRxxxarXiv.jpg">}}*CRF learning with CNN features for image segmentation*   
\n$\cdot$ /F. Liu, G. Lin, C. Shen/.
\n$\cdot$ /Pattern Recognition (PR), 2015/.
\n$\cdot$ [http://arxiv.org/abs/1503.08263    arXiv][data/bibtex/Liu2015CRFPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={CRF}+Learning+with+{CNN}+Features+for+Image+Segmentation+Liu,+Fayao+and+Lin,+Guosheng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q={CRF}+Learning+with+{CNN}+Features+for+Image+Segmentation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Hashing2015ShenxxxarXiv.jpg">}}*Hashing on nonlinear manifolds*   
\n$\cdot$ /F. Shen, C. Shen, Q. Shi, A. van den Hengel, Z. Tang, H. Shen/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2015/.
\n$\cdot$ [http://arxiv.org/abs/1412.0826    arXiv][data/bibtex/Hashing2015Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Hashing+on+Nonlinear+Manifolds+Shen,+Fumin+and+Shen,+Chunhua+and+Shi,+Qinfeng+and+{van+den+Hengel},+Anton+and+Tang,+Zhenmin+and+Shen,+Heng+Tao google scholar][https://www.semanticscholar.org/search?q=Hashing+on+Nonlinear+Manifolds semantic scholar][https://github.com/chhshen/Hashing-on-Nonlinear-Manifolds   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/TIP2014ShortcutxxxarXiv.jpg">}}*A computational model of the short-cut rule for 2D shape decomposition*   
\n$\cdot$ /L. Luo, C. Shen, X. Liu, C. Zhang/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2015/.
\n$\cdot$ [http://arxiv.org/abs/1409.2104    arXiv][data/bibtex/TIP2014Shortcut.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Computational+Model+of+the+Short-Cut+Rule+for+{2D}+Shape+Decomposition+Luo,+Lei+and+Shen,+Chunhua+and+Liu,+Xinwang+and+Zhang,+Chunyuan google scholar][https://www.semanticscholar.org/search?q=A+Computational+Model+of+the+Short-Cut+Rule+for+{2D}+Shape+Decomposition semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/SDP2015LixxxarXiv.jpg">}}*Worst-case linear discriminant analysis as scalable semidefinite feasibility problems*   
\n$\cdot$ /H. Li, C. Shen, A. van den Hengel, Q. Shi/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2015/.
\n$\cdot$ [http://arxiv.org/abs/1411.7450    arXiv][data/bibtex/SDP2015Li.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Worst-Case+Linear+Discriminant+Analysis+as+Scalable+Semidefinite+Feasibility+Problems+Li,+Hui+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Shi,+Qinfeng google scholar][https://www.semanticscholar.org/search?q=Worst-Case+Linear+Discriminant+Analysis+as+Scalable+Semidefinite+Feasibility+Problems semantic scholar][https://github.com/chhshen/SDP-WLDA   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1408.5574.pdf"><img class="imgP  right"   src="data/thumbnail/FastHash2015LinxxxarXiv.jpg"></a>}}*Supervised hashing using graph cuts and boosted decision trees*   
\n$\cdot$ /G. Lin, C. Shen, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2015/.
\n$\cdot$ [http://arxiv.org/abs/1408.5574    arXiv][http://dx.doi.org/10.1109/TPAMI.2015.2404776  link][data/bibtex/FastHash2015Lin.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Supervised+Hashing+Using+Graph+Cuts+and+Boosted+Decision+Trees+Lin,+Guosheng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Supervised+Hashing+Using+Graph+Cuts+and+Boosted+Decision+Trees semantic scholar][https://bitbucket.org/chhshen/fasthash/   project webpage]
== Conference
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1504.01492.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR15exxxarXiv.jpg"></a>}}*Efficient SDP inference for fully-connected CRFs based on low-rank decomposition*   
\n$\cdot$ /P. Wang, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'15), 2015/.
\n$\cdot$ [http://arxiv.org/abs/1504.01492    arXiv][data/bibtex/CVPR15e.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Efficient+{SDP}+Inference+for+Fully-connected+{CRFs}+Based+on+Low-rank+Decomposition+Wang,+Peng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Efficient+{SDP}+Inference+for+Fully-connected+{CRFs}+Based+on+Low-rank+Decomposition semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/CVPR15gxxxPDF.jpg">}}*Learning graph structure for multi-label image classification via clique generation*   
\n$\cdot$ /M. Tan, Q. Shi, A. van den Hengel, C. Shen, J. Gao, F. Hu, Z. Zhang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'15), 2015/.
\n$\cdot$ [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Tan_Learning_Graph_Structure_2015_CVPR_paper.pdf  pdf][data/bibtex/CVPR15g.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Graph+Structure+for+Multi-label+Image+Classification+via+Clique+Generation+Tan,+Mingkui+and+Shi,+Qinfeng+and+{van+den+Hengel},+Anton+and+Shen,+Chunhua+and+Gao,+Junbin+and+Hu,+Fuyuan+and+Zhang,+Zhen google scholar][https://www.semanticscholar.org/search?q=Learning+Graph+Structure+for+Multi-label+Image+Classification+via+Clique+Generation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/CVPR15cxxxPDF.jpg">}}*Supervised discrete hashing*   
\n$\cdot$ /F. Shen, C. Shen, W. Liu, H. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'15), 2015/.
\n$\cdot$ [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Shen_Supervised_Discrete_Hashing_2015_CVPR_paper.pdf  pdf][data/bibtex/CVPR15c.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Supervised+Discrete+Hashing+Shen,+Fumin+and+Shen,+Chunhua+and+Liu,+Wei+and+Shen,+Heng+Tao google scholar][https://www.semanticscholar.org/search?q=Supervised+Discrete+Hashing semantic scholar][https://github.com/bd622/DiscretHashing/   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1503.01543.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR15fxxxarXiv.jpg"></a>}}*Learning to rank in person re-identification with metric ensembles*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'15), 2015/.
\n$\cdot$ [http://arxiv.org/abs/1503.01543    arXiv][data/bibtex/CVPR15f.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+to+rank+in+person+re-identification+with+metric+ensembles+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Learning+to+rank+in+person+re-identification+with+metric+ensembles semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1411.7466.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR15dxxxarXiv.jpg"></a>}}*The treasure beneath convolutional layers: cross convolutional layer pooling for image classification*   
\n$\cdot$ /L. Liu, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'15), 2015/.
\n$\cdot$ [http://arxiv.org/abs/1411.7466    arXiv][data/bibtex/CVPR15d.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=The+Treasure+beneath+Convolutional+Layers:+Cross+convolutional+layer+Pooling+for+Image+Classification+Liu,+Lingqiao+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=The+Treasure+beneath+Convolutional+Layers:+Cross+convolutional+layer+Pooling+for+Image+Classification semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1411.6387.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR15bxxxarXiv.jpg"></a>}}*Deep convolutional neural fields for depth estimation from a single image*   
\n$\cdot$ /F. Liu, C. Shen, G. Lin/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'15), 2015/.
\n$\cdot$ [http://arxiv.org/abs/1411.6387    arXiv][data/bibtex/CVPR15b.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deep+Convolutional+Neural+Fields+for+Depth+Estimation+from+a+Single+Image+Liu,+Fayao+and+Shen,+Chunhua+and+Lin,+Guosheng google scholar][https://www.semanticscholar.org/search?q=Deep+Convolutional+Neural+Fields+for+Depth+Estimation+from+a+Single+Image semantic scholar][http://goo.gl/rAKWrS   project webpage]
. *Mid-level deep pattern mining*   
\n$\cdot$ /Y. Li, L. Liu, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'15), 2015/.
\n$\cdot$ [http://arxiv.org/abs/1411.6382    arXiv][data/bibtex/CVPR15a.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Mid-level+Deep+Pattern+Mining+Li,+Yao+and+Liu,+Lingqiao+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Mid-level+Deep+Pattern+Mining semantic scholar][https://github.com/yaoliUoA/MDPM   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/CVPR15hxxxPDF.jpg">}}*Depth and surface normal estimation from monocular images using regression on deep features and hierarchical CRFs*   
\n$\cdot$ /B. Li, C. Shen, Y. Dai, A. van den Hengel, M. He/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'15), 2015/.
\n$\cdot$ [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Li_Depth_and_Surface_2015_CVPR_paper.pdf  pdf][data/bibtex/CVPR15h.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Depth+and+Surface+Normal+Estimation+from+Monocular+Images+Using+Regression+on+Deep+Features+and+Hierarchical+{CRFs}+Li,+Bo+and+Shen,+Chunhua+and+Dai,+Yuchao+and+{van+den+Hengel},+Anton+and+He,+Mingyi google scholar][https://www.semanticscholar.org/search?q=Depth+and+Surface+Normal+Estimation+from+Monocular+Images+Using+Regression+on+Deep+Features+and+Hierarchical+{CRFs} semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/ICCV15ZhangxxxPDF.jpg">}}*Hyperspectral compressive sensing using manifold-structured sparsity prior*   
\n$\cdot$ /L. Zhang, W. Wei, Y. Zhang, F. Li, C. Shen, Q. Shi/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'15), 2015/.
\n$\cdot$ [http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zhang_Hyperspectral_Compressive_Sensing_ICCV_2015_paper.pdf  pdf][data/bibtex/ICCV15Zhang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Hyperspectral+Compressive+Sensing+Using+Manifold-Structured+Sparsity+Prior+Zhang,+Lei+and+Wei,+Wei+and+Zhang,+Yanning+and+Li,+Fei+and+Shen,+Chunhua+and+Shi,+Qinfeng google scholar][https://www.semanticscholar.org/search?q=Hyperspectral+Compressive+Sensing+Using+Manifold-Structured+Sparsity+Prior semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/NeurIPS15LinxxxPDF.jpg">}}*Deeply learning the messages in message passing inference*   
\n$\cdot$ /G. Lin, C. Shen, I. Reid, A. van den Hengel/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'15), 2015/.
\n$\cdot$ [http://arxiv.org/abs/1506.02108    arXiv][http://papers.NeurIPS.cc/paper/5791-deeply-learning-the-messages-in-message-passing-inference.pdf  pdf][data/bibtex/NeurIPS15Lin.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Deeply+Learning+the+Messages+in+Message+Passing+Inference+Lin,+Guosheng+and+Shen,+Chunhua+and+Reid,+Ian+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Deeply+Learning+the+Messages+in+Message+Passing+Inference semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/CVPR15workshopxxxPDF.jpg">}}*Sequence searching with deep-learnt depth for condition- and viewpoint-invariant route-based place recognition*   
\n$\cdot$ /M. Milford, C. Shen, S. Lowry, N. Suenderhauf, S. Shirazi, G. Lin, F. Liu, E. Pepperell, C. Lerma, B. Upcroft, I. Reid/.
\n$\cdot$ /Proc. 6th International Workshop on Computer Vision in Vehicle Technology, in conjunction with IEEE Conference on Computer Vision and Pattern Recognition (CVVT'15), 2015/.
\n$\cdot$ [http://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W11/papers/Milford_Sequence_Searching_With_2015_CVPR_paper.pdf  pdf][data/bibtex/CVPR15workshop.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Sequence+searching+with+Deep-Learnt+Depth+for+Condition-+and+Viewpoint-Invariant+Route-Based+Place+Recognition+Milford,+Michael+and+Shen,+Chunhua+and+Lowry,+Stephanie+and+Suenderhauf,+Niko+and+Shirazi,+Sareh+and+Lin,+Guosheng+and+Liu,+Fayao+and+Pepperell,+Edward+and+Lerma,+Cesar+and+Upcroft,+Ben+and+Reid,+Ian google scholar][https://www.semanticscholar.org/search?q=Sequence+searching+with+Deep-Learnt+Depth+for+Condition-+and+Viewpoint-Invariant+Route-Based+Place+Recognition semantic scholar]
        .. Best paper award (Sponsored by NVIDIA).

= 2014
== Journal
. {{<img class="imgP  right"   src="data/thumbnail/Shen2014OutlierxxxarXiv.jpg">}}*Fast approximate $l_\infty$ minimization: Speeding up robust regression*   
\n$\cdot$ /F. Shen, C. Shen, R. Hill, A. van den Hengel, Z. Tang/.
\n$\cdot$ /Computational Statistics and Data Analysis (CSDA), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1304.1250    arXiv][data/bibtex/Shen2014Outlier.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fast+approximate+L_\infty+minimization:+{S}peeding+up+robust+regression+Shen,+Fumin+and+Shen,+Chunhua+and+Hill,+Rhys+and+{van+den+Hengel},+Anton+and+Tang,+Zhenmin google scholar][https://www.semanticscholar.org/search?q=Fast+approximate+L_\infty+minimization:+{S}peeding+up+robust+regression semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Liu2014MKLxxxarXiv.jpg">}}*Multiple kernel learning in the primal for multi-modal Alzheimer's disease classification*   
\n$\cdot$ /F. Liu, L. Zhou, C. Shen, J. Yin/.
\n$\cdot$ /IEEE Journal of Biomedical and Health Informatics (JBHI), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1310.0890    arXiv][http://dx.doi.org/10.1109/JBHI.2013.2285378  link][data/bibtex/Liu2014MKL.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Multiple+Kernel+Learning+in+the+Primal+for+Multi-modal+{A}lzheimer's+Disease+Classification+Liu,+Fayao+and+Zhou,+Luping+and+Shen,+Chunhua+and+Yin,+Jianping google scholar][https://www.semanticscholar.org/search?q=Multiple+Kernel+Learning+in+the+Primal+for+Multi-modal+{A}lzheimer's+Disease+Classification semantic scholar]
        .. Online published at IEEE: 10 October 2013.
. *Multiple kernel clustering based on centered kernel alignment*   
\n$\cdot$ /Y. Lu, L. Wang, J. Lu, J. Yang, C. Shen/.
\n$\cdot$ /Pattern Recognition (PR), 2014/.
\n$\cdot$ [data/bibtex/MKL2014.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Multiple+kernel+clustering+based+on+centered+kernel+alignment+Lu,+Yanting+and+Wang,+Liantao+and+Lu,+Jianfeng+and+Yang,+Jingyu+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Multiple+kernel+clustering+based+on+centered+kernel+alignment semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Yan2014TIPaxxxarXiv.jpg">}}*Efficient semidefinite spectral clustering via Lagrange duality*   
\n$\cdot$ /Y. Yan, C. Shen, H. Wang/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1402.5497    arXiv][data/bibtex/Yan2014TIPa.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Efficient+Semidefinite+Spectral+Clustering+via+{L}agrange+Duality+Yan,+Yan+and+Shen,+Chunhua+and+Wang,+Hanzi google scholar][https://www.semanticscholar.org/search?q=Efficient+Semidefinite+Spectral+Clustering+via+{L}agrange+Duality semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Paul2014TIPbxxxarXiv.jpg">}}*Large-margin learning of compact binary image encodings*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1402.6383    arXiv][data/bibtex/Paul2014TIPb.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Large-margin+Learning+of+Compact+Binary+Image+Encodings+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Large-margin+Learning+of+Compact+Binary+Image+Encodings semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Li2014TIPxxxarXiv.jpg">}}*Characterness: An indicator of text in the wild*   
\n$\cdot$ /Y. Li, W. Jia, C. Shen, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1309.6691    arXiv][http://dx.doi.org/10.1109/TIP.2014.2302896  link][data/bibtex/Li2014TIP.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Characterness:+{A}n+Indicator+of+Text+in+the+Wild+Li,+Yao+and+Jia,+Wenjing+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Characterness:+{A}n+Indicator+of+Text+in+the+Wild semantic scholar][https://github.com/yaoliUoA/characterness   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Li2013HyperxxxarXiv.jpg">}}*Context-aware hypergraph construction for robust spectral clustering*   
\n$\cdot$ /X. Li, W. Hu, C. Shen, A. Dick, Z. Zhang/.
\n$\cdot$ /IEEE Transactions on Knowledge and Data Engineering (TKDE), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1401.0764    arXiv][http://doi.ieeecomputersociety.org/10.1109/TKDE.2013.126  link][data/bibtex/Li2013Hyper.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Context-aware+hypergraph+construction+for+robust+spectral+clustering+Li,+Xi+and+Hu,+Weiming+and+Shen,+Chunhua+and+Dick,+Anthony+and+Zhang,+Zhongfei google scholar][https://www.semanticscholar.org/search?q=Context-aware+hypergraph+construction+for+robust+spectral+clustering semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Paul2013TMMxxxarXiv.jpg">}}*Asymmetric pruning for learning cascade detectors*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Multimedia (TMM), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1303.6066    arXiv][http://dx.doi.org/10.1109/TMM.2014.2308723  link][data/bibtex/Paul2013TMM.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Asymmetric+pruning+for+learning+cascade+detectors+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Asymmetric+pruning+for+learning+cascade+detectors semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Shen2014MetricxxxarXiv.jpg">}}*Efficient dual approach to distance metric learning*   
\n$\cdot$ /C. Shen, J. Kim, F. Liu, L. Wang, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Neural Networks and Learning Systems (TNN), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1302.3219    arXiv][data/bibtex/Shen2014Metric.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Efficient+Dual+Approach+to+Distance+Metric+Learning+Shen,+Chunhua+and+Kim,+Junae+and+Liu,+Fayao+and+Wang,+Lei+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Efficient+Dual+Approach+to+Distance+Metric+Learning semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Paul2013FastboostingxxxPDF.jpg">}}*A scalable stage-wise approach to large-margin multi-class loss based boosting*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Neural Networks and Learning Systems (TNN), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1307.5497    arXiv][http://dx.doi.org/10.1109/TNNLS.2013.2282369  link][https://bytebucket.org/chhshen/data/raw/7e2f958b104603e54e9d8376a8e1672363f742a3/papers/Paisitkriangkrai2014TNNLS.pdf  pdf][data/bibtex/Paul2013Fastboosting.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+scalable+stage-wise+approach+to+large-margin+multi-class+loss+based+boosting+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=A+scalable+stage-wise+approach+to+large-margin+multi-class+loss+based+boosting semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Paisitkriangkrai2013RandomBoostxxxarXiv.jpg">}}*RandomBoost: Simplified multi-class boosting through randomization*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, Q. Shi, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Neural Networks and Learning Systems (TNN), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1302.0963    arXiv][http://dx.doi.org/10.1109/TNNLS.2013.2281214  link][data/bibtex/Paisitkriangkrai2013RandomBoost.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={RandomBoost}:+{S}implified+Multi-class+Boosting+through+Randomization+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+Shi,+Qinfeng+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q={RandomBoost}:+{S}implified+Multi-class+Boosting+through+Randomization semantic scholar]
. *A hierarchical word-merging algorithm with class separability measure*   
\n$\cdot$ /L. Wang, L. Zhou, C. Shen, L. Liu, H. Liu/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2014/.
\n$\cdot$ [https://bitbucket.org/chhshen/chhshen.bitbucket.org/src/be12d4ef8deb6207ec97f0fdac6efbe2df151b59/_download/TPAMI14Wang.pdf  pdf][data/bibtex/Wang2014PAMI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Hierarchical+Word-merging+Algorithm+with+Class+Separability+Measure+Wang,+Lei+and+Zhou,+Luping+and+Shen,+Chunhua+and+Liu,+Lingqiao+and+Liu,+Huan google scholar][https://www.semanticscholar.org/search?q=A+Hierarchical+Word-merging+Algorithm+with+Class+Separability+Measure semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Shen2014SBoostingxxxarXiv.jpg">}}*StructBoost: Boosting methods for predicting structured output variables*   
\n$\cdot$ /C. Shen, G. Lin, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1302.3283    arXiv][http://dx.doi.org/10.1109/TPAMI.2014.2315792  link][http://goo.gl/goCVLK  pdf][data/bibtex/Shen2014SBoosting.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={StructBoost}:+{B}oosting+Methods+for+Predicting+Structured+Output+Variables+Shen,+Chunhua+and+Lin,+Guosheng+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q={StructBoost}:+{B}oosting+Methods+for+Predicting+Structured+Output+Variables semantic scholar]
== Conference
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1404.1561.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR14LinxxxarXiv.jpg"></a>}}*Fast supervised hashing with decision trees for high-dimensional data*   
\n$\cdot$ /G. Lin, C. Shen, Q. Shi, A. van den Hengel, D. Suter/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'14), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1404.1561    arXiv][https://bitbucket.org/chhshen/fasthash/src  link][data/bibtex/CVPR14Lin.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fast+Supervised+Hashing+with+Decision+Trees+for+High-Dimensional+Data+Lin,+Guosheng+and+Shen,+Chunhua+and+Shi,+Qinfeng+and+{van+den+Hengel},+Anton+and+Suter,+David google scholar][https://www.semanticscholar.org/search?q=Fast+Supervised+Hashing+with+Decision+Trees+for+High-Dimensional+Data semantic scholar][https://bitbucket.org/chhshen/fasthash/   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1407.0786.pdf"><img class="imgP  right"   src="data/thumbnail/ECCV14PaulxxxarXiv.jpg"></a>}}*Strengthening the effectiveness of pedestrian detection with spatially pooled features*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'14), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1407.0786    arXiv][data/bibtex/ECCV14Paul.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Strengthening+the+Effectiveness+of+Pedestrian+Detection+with+Spatially+Pooled+Features+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Strengthening+the+Effectiveness+of+Pedestrian+Detection+with+Spatially+Pooled+Features semantic scholar][https://github.com/chhshen/pedestrian-detection   project webpage]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1407.1151.pdf"><img class="imgP  right"   src="data/thumbnail/ECCV14LinxxxarXiv.jpg"></a>}}*Optimizing ranking measures for compact binary code learning*   
\n$\cdot$ /G. Lin, C. Shen, J. Wu/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'14), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1407.1151    arXiv][data/bibtex/ECCV14Lin.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Optimizing+Ranking+Measures+for+Compact+Binary+Code+Learning+Lin,+Guosheng+and+Shen,+Chunhua+and+Wu,+Jianxin google scholar][https://www.semanticscholar.org/search?q=Optimizing+Ranking+Measures+for+Compact+Binary+Code+Learning semantic scholar][https://bitbucket.org/guosheng/structhash   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/Liu2014FisherxxxarXiv.jpg">}}*Encoding high dimensional local features by sparse coding based Fisher vectors*   
\n$\cdot$ /L. Liu, C. Shen, L. Wang, A. van den Hengel, C. Wang/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'14), 2014/.
\n$\cdot$ [http://arxiv.org/abs/1411.6406    arXiv][data/bibtex/Liu2014Fisher.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Encoding+High+Dimensional+Local+Features+by+Sparse+Coding+Based+{F}isher+Vectors+Liu,+Lingqiao+and+Shen,+Chunhua+and+Wang,+Lei+and+{van+den+Hengel},+Anton+and+Wang,+Chao google scholar][https://www.semanticscholar.org/search?q=Encoding+High+Dimensional+Local+Features+by+Sparse+Coding+Based+{F}isher+Vectors semantic scholar]

= 2013
== Journal
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1301.2032.pdf"><img class="imgP  right"   src="data/thumbnail/FisherBoost2013IJCVxxxarXiv.jpg"></a>}}*Training effective node classifiers for cascade classification*   
\n$\cdot$ /C. Shen, P. Wang, S. Paisitkriangkrai, A. van den Hengel/.
\n$\cdot$ /International Journal of Computer Vision (IJCV), 2013/.
\n$\cdot$ [http://arxiv.org/abs/1301.2032    arXiv][http://link.springer.com/article/10.1007%2Fs11263-013-0608-1  link][data/bibtex/FisherBoost2013IJCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Training+Effective+Node+Classifiers+for+Cascade+Classification+Shen,+Chunhua+and+Wang,+Peng+and+Paisitkriangkrai,+Sakrapee+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Training+Effective+Node+Classifiers+for+Cascade+Classification semantic scholar]
. *Fully corrective boosting with arbitrary loss and regularization*   
\n$\cdot$ /C. Shen, H. Li, A. van den Hengel/.
\n$\cdot$ /Neural Networks (NN), 2013/.
\n$\cdot$ [http://hdl.handle.net/2440/78929  pdf][data/bibtex/Shen2013NN.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fully+Corrective+Boosting+with+Arbitrary+Loss+and+Regularization+Shen,+Chunhua+and+Li,+Hanxi+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Fully+Corrective+Boosting+with+Arbitrary+Loss+and+Regularization semantic scholar]
. *Approximate least trimmed sum of squares fitting and applications in image analysis*   
\n$\cdot$ /F. Shen, C. Shen, A. van den Hengel, Z. Tang/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2013/.
\n$\cdot$ [http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6408142  link][http://hdl.handle.net/2440/79428  pdf][data/bibtex/LMS2013TIP.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Approximate+Least+Trimmed+Sum+of+Squares+Fitting+and+Applications+in+Image+Analysis+Shen,+Fumin+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Tang,+Zhenmin google scholar][https://www.semanticscholar.org/search?q=Approximate+Least+Trimmed+Sum+of+Squares+Fitting+and+Applications+in+Image+Analysis semantic scholar]
. *Visual tracking with spatio-temporal Dempster-Shafer information fusion*   
\n$\cdot$ /X. Li, A. Dick, C. Shen, Z. Zhang, A. van den Hengel, H. Wang/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2013/.
\n$\cdot$ [http://hdl.handle.net/2440/77448  pdf][data/bibtex/Xi2013TIP.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Visual+Tracking+with+Spatio-Temporal+{Dempster-Shafer}+Information+Fusion+Li,+Xi+and+Dick,+Anthony+and+Shen,+Chunhua+and+Zhang,+Zhongfei+and+{van+den+Hengel},+Anton+and+Wang,+Hanzi google scholar][https://www.semanticscholar.org/search?q=Visual+Tracking+with+Spatio-Temporal+{Dempster-Shafer}+Information+Fusion semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Xi2013SurveyxxxarXiv.jpg">}}*A survey of appearance models in visual object tracking*   
\n$\cdot$ /X. Li, W. Hu, C. Shen, Z. Zhang, A. Dick, A. van den Hengel/.
\n$\cdot$ /ACM Transactions on Intelligent Systems and Technology (TIST), 2013/.
\n$\cdot$ [http://arxiv.org/abs/1303.4803    arXiv][data/bibtex/Xi2013Survey.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Survey+of+Appearance+Models+in+Visual+Object+Tracking+Li,+Xi+and+Hu,+Weiming+and+Shen,+Chunhua+and+Zhang,+Zhongfei+and+Dick,+Anthony+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=A+Survey+of+Appearance+Models+in+Visual+Object+Tracking semantic scholar]
. *Shape similarity analysis by self-tuning locally constrained mixed-diffusion*   
\n$\cdot$ /L. Luo, C. Shen, C. Zhang, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Multimedia (TMM), 2013/.
\n$\cdot$ [http://hdl.handle.net/2440/73304  pdf][data/bibtex/TMM2013Shape.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Shape+Similarity+Analysis+by+Self-Tuning+Locally+Constrained+Mixed-Diffusion+Luo,+Lei+and+Shen,+Chunhua+and+Zhang,+Chunyuan+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Shape+Similarity+Analysis+by+Self-Tuning+Locally+Constrained+Mixed-Diffusion semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/TPAMI2013XixxxarXiv.jpg">}}*Incremental learning of 3D-DCT compact representations for robust visual tracking*   
\n$\cdot$ /X. Li, A. Dick, C. Shen, A. van den Hengel, H. Wang/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2013/.
\n$\cdot$ [http://arxiv.org/abs/1207.3389    arXiv][http://dx.doi.org/10.1109/TPAMI.2012.166  link][https://sites.google.com/site/chhshen/publication/tpami12xi.pdf?attredirects=1  pdf][data/bibtex/TPAMI2013Xi.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Incremental+Learning+of+{3D-DCT}+Compact+Representations+for+Robust+Visual+Tracking+Li,+Xi+and+Dick,+Anthony+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Wang,+Hanzi google scholar][https://www.semanticscholar.org/search?q=Incremental+Learning+of+{3D-DCT}+Compact+Representations+for+Robust+Visual+Tracking semantic scholar][https://github.com/chhshen/DCT-Tracking/   project webpage]
== Conference
. {{<img class="imgP  right"   src="data/thumbnail/CVPR13eYaoxxxPDF.jpg">}}*Part-based visual tracking with online latent structural learning*   
\n$\cdot$ /R. Yao, Q. Shi, C. Shen, Y. Zhang, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'13), 2013/.
\n$\cdot$ [http://hdl.handle.net/2440/77413  link][http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Yao_Part-Based_Visual_Tracking_2013_CVPR_paper.pdf  pdf][data/bibtex/CVPR13eYao.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Part-based+Visual+Tracking+with+Online+Latent+Structural+Learning+Yao,+Rui+and+Shi,+Qinfeng+and+Shen,+Chunhua+and+Zhang,+Yanning+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Part-based+Visual+Tracking+with+Online+Latent+Structural+Learning semantic scholar][https://github.com/chhshen/PartTracking   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/CVPR13cWangxxxPDF.jpg">}}*Bilinear programming for human activity recognition with unknown MRF graphs*   
\n$\cdot$ /Z. Wang, Q. Shi, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'13), 2013/.
\n$\cdot$ [http://hdl.handle.net/2440/77411  link][http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Wang_Bilinear_Programming_for_2013_CVPR_paper.pdf  pdf][data/bibtex/CVPR13cWang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Bilinear+Programming+for+Human+Activity+Recognition+with+unknown+{MRF}+graphs+Wang,+Zhenhua+and+Shi,+Qinfeng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Bilinear+Programming+for+Human+Activity+Recognition+with+unknown+{MRF}+graphs semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1304.0840.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR13dWangxxxarXiv.jpg"></a>}}*A fast semidefinite approach to solving binary quadratic problems*   
\n$\cdot$ /P. Wang, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'13), 2013/.
\n$\cdot$ [http://arxiv.org/abs/1304.0840    arXiv][data/bibtex/CVPR13dWang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Fast+Semidefinite+Approach+to+Solving+Binary+Quadratic+Problems+Wang,+Peng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=A+Fast+Semidefinite+Approach+to+Solving+Binary+Quadratic+Problems semantic scholar][./projects/BQP/   project webpage]
        .. Oral presentation, 60 out of 1870 submissions.
. *Inductive hashing on manifolds*   
\n$\cdot$ /F. Shen, C. Shen, Q. Shi, A. van den Hengel, Z. Tang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'13), 2013/.
\n$\cdot$ [http://arxiv.org/abs/1303.7043    arXiv][data/bibtex/CVPR13aShen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Inductive+Hashing+on+Manifolds+Shen,+Fumin+and+Shen,+Chunhua+and+Shi,+Qinfeng+and+{van+den+Hengel},+Anton+and+Tang,+Zhenmin google scholar][https://www.semanticscholar.org/search?q=Inductive+Hashing+on+Manifolds semantic scholar][https://github.com/chhshen/Hashing-on-Nonlinear-Manifolds   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/CVPR13bLixxxPDF.jpg">}}*Learning compact binary codes for visual tracking*   
\n$\cdot$ /X. Li, C. Shen, A. Dick, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'13), 2013/.
\n$\cdot$ [http://hdl.handle.net/2440/77412  link][http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Li_Learning_Compact_Binary_2013_CVPR_paper.pdf  pdf][data/bibtex/CVPR13bLi.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Compact+Binary+Codes+for+Visual+Tracking+Li,+Xi+and+Shen,+Chunhua+and+Dick,+Anthony+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Learning+Compact+Binary+Codes+for+Visual+Tracking semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/ICCV2013HarandixxxarXiv.jpg">}}*Dictionary learning and sparse coding on Grassmann manifolds: an extrinsic solution*   
\n$\cdot$ /M. Harandi, C. Sanderson, C. Shen, B. Lovell/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'13), 2013/.
\n$\cdot$ [http://arxiv.org/abs/1310.4891    arXiv][data/bibtex/ICCV2013Harandi.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Dictionary+Learning+and+Sparse+Coding+on+{G}rassmann+Manifolds:+An+Extrinsic+Solution+{Harandi},+Mehrtash+and+{Sanderson},+Conrad+and+Shen,+Chunhua+and+Lovell,+Brian google scholar][https://www.semanticscholar.org/search?q=Dictionary+Learning+and+Sparse+Coding+on+{G}rassmann+Manifolds:+An+Extrinsic+Solution semantic scholar][https://github.com/chhshen/Grassmann/   project webpage]
. {{<img class="imgP  right"   src="data/thumbnail/ICCV13PaixxxarXiv.jpg">}}*Efficient pedestrian detection by directly optimizing the partial area under the ROC curve*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'13), 2013/.
\n$\cdot$ [http://arxiv.org/abs/1310.0900    arXiv][http://hdl.handle.net/2440/83158  pdf][data/bibtex/ICCV13Pai.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Efficient+pedestrian+detection+by+directly+optimizing+the+partial+area+under+the+{ROC}+curve+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Efficient+pedestrian+detection+by+directly+optimizing+the+partial+area+under+the+{ROC}+curve semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/ICCV13LinxxxarXiv.jpg">}}*A general two-step approach to learning-based hashing*   
\n$\cdot$ /G. Lin, C. Shen, D. Suter, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'13), 2013/.
\n$\cdot$ [http://arxiv.org/abs/1309.1853    arXiv][data/bibtex/ICCV13Lin.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+General+Two-step+Approach+to+Learning-Based+Hashing+Lin,+Guosheng+and+Shen,+Chunhua+and+Suter,+David+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=A+General+Two-step+Approach+to+Learning-Based+Hashing semantic scholar][https://bitbucket.org/guosheng/two-step-hashing/   project webpage]
. *Contextual hypergraph modeling for salient object detection*   
\n$\cdot$ /X. Li, Y. Li, C. Shen, A. Dick, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'13), 2013/.
\n$\cdot$ [http://arxiv.org/abs/1310.5767    arXiv][data/bibtex/ICCV13Li.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Contextual+Hypergraph+Modeling+for+Salient+Object+Detection+Li,+Xi+and+Li,+Yao+and+Shen,+Chunhua+and+Dick,+Anthony+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Contextual+Hypergraph+Modeling+for+Salient+Object+Detection semantic scholar][https://bitbucket.org/chhshen/saliency-detection   project webpage]
. *Extended depth-of-field via focus stacking and graph cuts*   
\n$\cdot$ /C. Zhang, J. Bastian, C. Shen, A. van den Hengel, T. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Image Processing (ICIP'13), 2013/.
\n$\cdot$ [data/bibtex/ICIP13cShen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Extended+depth-of-field+via+focus+stacking+and+graph+cuts+Zhang,+Chao+and+Bastian,+John+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Shen,+Tingzhi google scholar][https://www.semanticscholar.org/search?q=Extended+depth-of-field+via+focus+stacking+and+graph+cuts semantic scholar]
. *Approximate constraint generation for efficient structured boosting*   
\n$\cdot$ /G. Lin, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Image Processing (ICIP'13), 2013/.
\n$\cdot$ [data/bibtex/ICIP13aShen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Approximate+constraint+generation+for+efficient+structured+boosting+Lin,+Guosheng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Approximate+constraint+generation+for+efficient+structured+boosting semantic scholar]
. *Leveraging surrounding context for scene text detection*   
\n$\cdot$ /Y. Li, C. Shen, W. Jia, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Image Processing (ICIP'13), 2013/.
\n$\cdot$ [data/bibtex/ICIP13bShen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Leveraging+surrounding+context+for+scene+text+detection+Li,+Yao+and+Shen,+Chunhua+and+Jia,+Wenjing+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Leveraging+surrounding+context+for+scene+text+detection semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/ICML13axxxPDF.jpg">}}*Learning hash functions using column generation*   
\n$\cdot$ /X. Li, G. Lin, C. Shen, A. van den Hengel, A. Dick/.
\n$\cdot$ /Proc. International Conference on Machine Learning (ICML'13), 2013/.
\n$\cdot$ [http://arxiv.org/abs/1303.0339    arXiv][http://jmlr.csail.mit.edu/proceedings/papers/v28/li13a.pdf  pdf][data/bibtex/ICML13a.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Hash+Functions+Using+Column+Generation+Li,+Xi+and+Lin,+Guosheng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Dick,+Anthony google scholar][https://www.semanticscholar.org/search?q=Learning+Hash+Functions+Using+Column+Generation semantic scholar][https://bitbucket.org/guosheng/column-generation-hashing/   project webpage]
        .. Oral presentation.

= 2012
== Journal
. {{<img class="imgP  right"   src="data/thumbnail/JMLR2012ShenxxxarXiv.jpg">}}*Positive semidefinite metric learning using boosting-like algorithms*   
\n$\cdot$ /C. Shen, J. Kim, L. Wang, A. van den Hengel/.
\n$\cdot$ /Journal of Machine Learning Research (JMLR), 2012/.
\n$\cdot$ [http://arxiv.org/abs/1104.4704    arXiv][http://jmlr.csail.mit.edu/papers/v13/shen12a.html  link][data/bibtex/JMLR2012Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Positive+Semidefinite+Metric+Learning+Using+Boosting-like+Algorithms+Shen,+Chunhua+and+Kim,+Junae+and+Wang,+Lei+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Positive+Semidefinite+Metric+Learning+Using+Boosting-like+Algorithms semantic scholar][https://code.google.com/archive/p/boosting/downloads   project webpage]
. *Fast and robust object detection using asymmetric totally-corrective boosting*   
\n$\cdot$ /P. Wang, C. Shen, N. Barnes, H. Zheng/.
\n$\cdot$ /IEEE Transactions on Neural Networks and Learning Systems (TNN), 2012/.
\n$\cdot$ [http://hdl.handle.net/2440/66763  pdf][data/bibtex/AsymBoost2011Wang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fast+and+Robust+Object+Detection+Using+Asymmetric+Totally-corrective+Boosting+Wang,+Peng+and+Shen,+Chunhua+and+Barnes,+Nick+and+Zheng,+Hong google scholar][https://www.semanticscholar.org/search?q=Fast+and+Robust+Object+Detection+Using+Asymmetric+Totally-corrective+Boosting semantic scholar]
. *UBoost: Boosting with the Universum*   
\n$\cdot$ /C. Shen, P. Wang, F. Shen, H. Wang/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2012/.
\n$\cdot$ [http://hdl.handle.net/2440/67027  pdf][data/bibtex/UBoost2011Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={UBoost}:+{B}oosting+with+the+{U}niversum+Shen,+Chunhua+and+Wang,+Peng+and+Shen,+Fumin+and+Wang,+Hanzi google scholar][https://www.semanticscholar.org/search?q={UBoost}:+{B}oosting+with+the+{U}niversum semantic scholar]
== Conference
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1311.5947.pdf"><img class="imgP  right"   src="data/thumbnail/ACCV12xxxarXiv.jpg"></a>}}*Fast training of effective multi-class boosting using coordinate descent optimization*   
\n$\cdot$ /G. Lin, C. Shen, A. van den Hengel, D. Suter/.
\n$\cdot$ /Proc. Asian Conference on Computer Vision (ACCV'12), 2012/.
\n$\cdot$ [http://arxiv.org/abs/1311.5947    arXiv][data/bibtex/ACCV12.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fast+Training+of+Effective+Multi-class+Boosting+Using+Coordinate+Descent+Optimization+Lin,+Guosheng+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Suter,+David google scholar][https://www.semanticscholar.org/search?q=Fast+Training+of+Effective+Multi-class+Boosting+Using+Coordinate+Descent+Optimization semantic scholar]
. *Sharing features in multi-class boosting via group sparsity*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'12), 2012/.
\n$\cdot$ [http://hdl.handle.net/2440/69851  pdf][data/bibtex/CVPR12b.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Sharing+Features+in+Multi-class+Boosting+via+Group+Sparsity+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Sharing+Features+in+Multi-class+Boosting+via+Group+Sparsity semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/1204.2912.pdf"><img class="imgP  right"   src="data/thumbnail/CVPR12axxxarXiv.jpg"></a>}}*Non-sparse linear representations for visual tracking with online reservoir metric learning*   
\n$\cdot$ /X. Li, C. Shen, Q. Shi, A. Dick, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'12), 2012/.
\n$\cdot$ [http://arxiv.org/abs/1204.2912    arXiv][http://hdl.handle.net/2440/70244  pdf][data/bibtex/CVPR12a.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Non-sparse+Linear+Representations+for+Visual+Tracking+with+Online+Reservoir+Metric+Learning+Li,+Xi+and+Shen,+Chunhua+and+Shi,+Qinfeng+and+Dick,+Anthony+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Non-sparse+Linear+Representations+for+Visual+Tracking+with+Online+Reservoir+Metric+Learning semantic scholar]
. *Robust tracking with weighted online structured learning*   
\n$\cdot$ /R. Yao, Q. Shi, C. Shen, Y. Zhang, A. van den Hengel/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'12), 2012/.
\n$\cdot$ [https://sites.google.com/site/chhshen/publication/weighted_tracking_eccv12.pdf?attredirects=1  pdf][data/bibtex/ECCV12.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Robust+Tracking+with+Weighted+Online+Structured+Learning+Yao,+Rui+and+Shi,+Qinfeng+and+Shen,+Chunhua+and+Zhang,+Yanning+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Robust+Tracking+with+Weighted+Online+Structured+Learning semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/ICML12xxxarXiv.jpg">}}*Is margin preserved after random projection?*   
\n$\cdot$ /Q. Shi, C. Shen, R. Hill, A. van den Hengel/.
\n$\cdot$ /Proc. International Conference on Machine Learning (ICML'12), 2012/.
\n$\cdot$ [http://arxiv.org/abs/1206.4651    arXiv][http://hdl.handle.net/2440/71063  link][data/bibtex/ICML12.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Is+margin+preserved+after+random+projection?+Shi,+Qinfeng+and+Shen,+Chunhua+and+Hill,+Rhys+and+van+den+Hengel,+Anton google scholar][https://www.semanticscholar.org/search?q=Is+margin+preserved+after+random+projection? semantic scholar]
        .. This work provides an analysis of margin distortion under random projections, the conditions under which margins are preserved, and presents bounds on the margin distortion.
== Other
. *Semidefinite programming (book chapter in: encyclopedia of computer vision, springer)*   
\n$\cdot$ /C. Shen, A. van den Hengel/.
\n$\cdot$   /2012/.
\n$\cdot$ [data/bibtex/SDP2012.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Semidefinite+programming+(Book+chapter+in:+Encyclopedia+of+Computer+Vision,+Springer)+Shen,+Chunhua+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Semidefinite+programming+(Book+chapter+in:+Encyclopedia+of+Computer+Vision,+Springer) semantic scholar]

= 2011
== Journal
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/0903.3103.pdf"><img class="imgP  right"   src="data/thumbnail/GSLDA2010ShenxxxarXiv.jpg"></a>}}*Efficiently learning a detection cascade with sparse eigenvectors*   
\n$\cdot$ /C. Shen, S. Paisitkriangkrai, J. Zhang/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2011/.
\n$\cdot$ [http://arxiv.org/abs/0903.3103    arXiv][http://dx.doi.org/10.1109/TIP.2010.2055880  link][data/bibtex/GSLDA2010Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Efficiently+Learning+a+Detection+Cascade+with+Sparse+Eigenvectors+Shen,+Chunhua+and+Paisitkriangkrai,+Sakrapee+and+Zhang,+Jian google scholar][https://www.semanticscholar.org/search?q=Efficiently+Learning+a+Detection+Cascade+with+Sparse+Eigenvectors semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Incremental2010ShenxxxarXiv.jpg">}}*Incremental training of a detector using online sparse eigen-decomposition*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, J. Zhang/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2011/.
\n$\cdot$ [http://arxiv.org/abs/1005.4118    arXiv][http://dx.doi.org/10.1109/TIP.2010.2053548  link][data/bibtex/Incremental2010Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Incremental+Training+of+a+Detector+Using+Online+Sparse+Eigen-decomposition+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+Zhang,+Jian google scholar][https://www.semanticscholar.org/search?q=Incremental+Training+of+a+Detector+Using+Online+Sparse+Eigen-decomposition semantic scholar]
== Conference
. *Efficiently learning a distance metric for large margin nearest neighbor classification*   
\n$\cdot$ /K. Park, C. Shen, Z. Hao, J. Kim/.
\n$\cdot$ /Proc. AAAI Conference on Artificial Intelligence (AAAI'11), 2011/.
\n$\cdot$ [data/bibtex/AAAI2011.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Efficiently+learning+a+distance+metric+for+large+margin+nearest+neighbor+classification+Park,+Kyoungup+and+Shen,+Chunhua+and+Hao,+Zhihui+and+Kim,+Junae google scholar][https://www.semanticscholar.org/search?q=Efficiently+learning+a+distance+metric+for+large+margin+nearest+neighbor+classification semantic scholar]
. *Is face recognition really a compressive sensing problem?*   
\n$\cdot$ /Q. Shi, A. Eriksson, A. van den Hengel, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'11), 2011/.
\n$\cdot$ [http://hdl.handle.net/2440/67036  pdf][data/bibtex/Shi2011CVPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Is+face+recognition+really+a+Compressive+Sensing+problem?+Shi,+Qinfeng+and+Eriksson,+Anders+and+van+den+Hengel,+Anton+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Is+face+recognition+really+a+Compressive+Sensing+problem? semantic scholar]
. *A scalable dual approach to semidefinite metric learning*   
\n$\cdot$ /C. Shen, J. Kim, L. Wang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'11), 2011/.
\n$\cdot$ [http://goo.gl/UyVdEc  pdf][data/bibtex/Shen2011CVPRb.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Scalable+Dual+Approach+to+Semidefinite+Metric+Learning+Shen,+Chunhua+and+Kim,+Junae+and+Wang,+Lei google scholar][https://www.semanticscholar.org/search?q=A+Scalable+Dual+Approach+to+Semidefinite+Metric+Learning semantic scholar]
. *A direct formulation for totally-corrective multi-class boosting*   
\n$\cdot$ /C. Shen, Z. Hao/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'11), 2011/.
\n$\cdot$ [http://hdl.handle.net/2440/62919  pdf][data/bibtex/Shen2011CVPRa.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+direct+formulation+for+totally-corrective+multi-class+boosting+Shen,+Chunhua+and+Hao,+Zhihui google scholar][https://www.semanticscholar.org/search?q=A+direct+formulation+for+totally-corrective+multi-class+boosting semantic scholar]
. *A generalized probabilistic framework for compact codebook creation*   
\n$\cdot$ /L. Liu, L. Wang, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'11), 2011/.
\n$\cdot$ [http://hdl.handle.net/2440/63014  pdf][data/bibtex/Liu2011CVPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+generalized+probabilistic+framework+for+compact+codebook+creation+Liu,+Lingqiao+and+Wang,+Lei+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=A+generalized+probabilistic+framework+for+compact+codebook+creation semantic scholar]
. *Real-time visual tracking using compressive sensing*   
\n$\cdot$ /H. Li, C. Shen, Q. Shi/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'11), 2011/.
\n$\cdot$ [http://goo.gl/dsjsoM  pdf][data/bibtex/Li2011CVPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Real-time+visual+tracking+Using+compressive+sensing+Li,+Hanxi+and+Shen,+Chunhua+and+Shi,+Qinfeng google scholar][https://www.semanticscholar.org/search?q=Real-time+visual+tracking+Using+compressive+sensing semantic scholar]
. *Laplacian margin distribution boosting for learning from sparsely labeled data*   
\n$\cdot$ /T. Wang, X. He, C. Shen, N. Barnes/.
\n$\cdot$ /Proc. International Conference on Digital Image Computing: Techniques and Applications (DICTA'11), 2011/.
\n$\cdot$ [data/bibtex/DICTA2011a.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Laplacian+margin+distribution+boosting+for+learning+from+sparsely+labeled+data+Wang,+Tao+and+He,+Xuming+and+Shen,+Chunhua+and+Barnes,+Nick google scholar][https://www.semanticscholar.org/search?q=Laplacian+margin+distribution+boosting+for+learning+from+sparsely+labeled+data semantic scholar]
. *On the optimality of sequential forward feature selection using class separability measure*   
\n$\cdot$ /L. Wang, C. Shen, R. Hartley/.
\n$\cdot$ /Proc. International Conference on Digital Image Computing: Techniques and Applications (DICTA'11), 2011/.
\n$\cdot$ [data/bibtex/DICTA2011b.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=On+The+Optimality+of+Sequential+Forward+Feature+Selection+Using+Class+Separability+Measure+Wang,+Lei+and+Shen,+Chunhua+and+Hartley,+Richard google scholar][https://www.semanticscholar.org/search?q=On+The+Optimality+of+Sequential+Forward+Feature+Selection+Using+Class+Separability+Measure semantic scholar]
. *Graph mode-based contextual kernels for robust SVM tracking*   
\n$\cdot$ /X. Li, A. Dick, H. Wang, C. Shen, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'11), 2011/.
\n$\cdot$ [http://goo.gl/GzpBVb  pdf][data/bibtex/ICCV2011.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Graph+mode-based+contextual+kernels+for+robust+{SVM}+tracking+Li,+Xi+and+Dick,+Anthony+and+Wang,+Hanzi+and+Shen,+Chunhua+and+van+den+Hengel,+Anton google scholar][https://www.semanticscholar.org/search?q=Graph+mode-based+contextual+kernels+for+robust+{SVM}+tracking semantic scholar]

= 2010
== Journal
. *Interactive color image segmentation with linear programming*   
\n$\cdot$ /H. Li, C. Shen/.
\n$\cdot$ /Machine Vision and Applications (MVA), 2010/.
\n$\cdot$ [http://www.springerlink.com/content/b254775776114226  link][http://sites.google.com/site/chhshen/publication/MVA2010LP.pdf  pdf][data/bibtex/Li2010Interactive.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Interactive+Color+Image+Segmentation+with+Linear+Programming+Li,+Hongdong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Interactive+Color+Image+Segmentation+with+Linear+Programming semantic scholar]
. {{<a class="imglink"  target="_blank" href="https://arxiv.org/pdf/0905.2463.pdf"><img class="imgP  right"   src="data/thumbnail/Generalized2010ShenxxxarXiv.jpg"></a>}}*Generalized kernel-based visual tracking*   
\n$\cdot$ /C. Shen, J. Kim, H. Wang/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2010/.
\n$\cdot$ [http://arxiv.org/abs/0905.2463    arXiv][http://dx.doi.org/10.1109/TCSVT.2009.2031393  link][http://sites.google.com/site/chhshen/publication/TCSVT2010.pdf  pdf][data/bibtex/Generalized2010Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Generalized+Kernel-based+Visual+Tracking+Shen,+Chunhua+and+Kim,+Junae+and+Wang,+Hanzi google scholar][https://www.semanticscholar.org/search?q=Generalized+Kernel-based+Visual+Tracking semantic scholar][https://github.com/chhshen/KernelTracking   project webpage]
. *Feature selection with redundancy-constrained class separability*   
\n$\cdot$ /L. Zhou, L. Wang, C. Shen/.
\n$\cdot$ /IEEE Transactions on Neural Networks (TNN), 2010/.
\n$\cdot$ [http://dx.doi.org/10.1109/TNN.2010.2044189  link][data/bibtex/Zhou2010FS.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Feature+Selection+With+Redundancy-Constrained+Class+Separability+Zhou,+Luping+and+Wang,+Lei+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Feature+Selection+With+Redundancy-Constrained+Class+Separability semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/MDBoost2010ShenxxxarXiv.jpg">}}*Boosting through optimization of margin distributions*   
\n$\cdot$ /C. Shen, H. Li/.
\n$\cdot$ /IEEE Transactions on Neural Networks (TNN), 2010/.
\n$\cdot$ [http://arxiv.org/abs/0904.2037    arXiv][http://dx.doi.org/10.1109/TNN.2010.2040484  link][data/bibtex/MDBoost2010Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Boosting+through+optimization+of+margin+distributions+Shen,+Chunhua+and+Li,+Hanxi google scholar][https://www.semanticscholar.org/search?q=Boosting+through+optimization+of+margin+distributions semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Scalable2010ShenxxxarXiv.jpg">}}*Scalable large-margin Mahalanobis distance metric learning*   
\n$\cdot$ /C. Shen, J. Kim, L. Wang/.
\n$\cdot$ /IEEE Transactions on Neural Networks (TNN), 2010/.
\n$\cdot$ [http://arxiv.org/abs/1003.0487    arXiv][http://dx.doi.org/10.1109/TNN.2010.2052630  link][data/bibtex/Scalable2010Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Scalable+Large-Margin+{M}ahalanobis+Distance+Metric+Learning+Shen,+Chunhua+and+Kim,+Junae+and+Wang,+Lei google scholar][https://www.semanticscholar.org/search?q=Scalable+Large-Margin+{M}ahalanobis+Distance+Metric+Learning semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Dual2010ShenxxxarXiv.jpg">}}*On the dual formulation of boosting algorithms*   
\n$\cdot$ /C. Shen, H. Li/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2010/.
\n$\cdot$ [http://arxiv.org/abs/0901.3590    arXiv][http://dx.doi.org/10.1109/TPAMI.2010.47  link][data/bibtex/Dual2010Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=On+the+Dual+Formulation+of+Boosting+Algorithms+Shen,+Chunhua+and+Li,+Hanxi google scholar][https://www.semanticscholar.org/search?q=On+the+Dual+Formulation+of+Boosting+Algorithms semantic scholar]
== Conference
. *Pyramid center-symmetric local binary, trinary patterns for effective pedestrian detection*   
\n$\cdot$ /Y. Zheng, C. Shen, R. Hartley, X. Huang/.
\n$\cdot$ /Proc. Asian Conference on Computer Vision (ACCV'10), 2010/.
\n$\cdot$ [http://goo.gl/5Cthse  pdf][data/bibtex/Zheng2010ACCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Pyramid+Center-symmetric+Local+Binary,+Trinary+Patterns+for+Effective+Pedestrian+Detection+Zheng,+Yongbin+and+Shen,+Chunhua+and+Hartley,+Richard+and+Huang,+Xinsheng google scholar][https://www.semanticscholar.org/search?q=Pyramid+Center-symmetric+Local+Binary,+Trinary+Patterns+for+Effective+Pedestrian+Detection semantic scholar]
. *Asymmetric totally-corrective boosting for real-time object detection*   
\n$\cdot$ /P. Wang, C. Shen, N. Barnes, H. Zheng, Z. Ren/.
\n$\cdot$ /Proc. Asian Conference on Computer Vision (ACCV'10), 2010/.
\n$\cdot$ [data/bibtex/Wang2010ACCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Asymmetric+Totally-corrective+Boosting+for+Real-time+Object+Detection+Wang,+Peng+and+Shen,+Chunhua+and+Barnes,+Nick+and+Zheng,+Hong+and+Ren,+Zhang google scholar][https://www.semanticscholar.org/search?q=Asymmetric+Totally-corrective+Boosting+for+Real-time+Object+Detection semantic scholar]
        .. Oral presentation.
. *Face detection with effective feature extraction*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, J. Zhang/.
\n$\cdot$ /Proc. Asian Conference on Computer Vision (ACCV'10), 2010/.
\n$\cdot$ [data/bibtex/Paul2010ACCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Face+Detection+with+Effective+Feature+Extraction+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+Zhang,+Jian google scholar][https://www.semanticscholar.org/search?q=Face+Detection+with+Effective+Feature+Extraction semantic scholar]
. *Totally-corrective multi-class boosting*   
\n$\cdot$ /Z. Hao, C. Shen, N. Barnes, B. Wang/.
\n$\cdot$ /Proc. Asian Conference on Computer Vision (ACCV'10), 2010/.
\n$\cdot$ [data/bibtex/Hao2010ACCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Totally-corrective+Multi-class+Boosting+Hao,+Zhihui+and+Shen,+Chunhua+and+Barnes,+Nick+and+Wang,+Bo google scholar][https://www.semanticscholar.org/search?q=Totally-corrective+Multi-class+Boosting semantic scholar]
. *Rapid face recognition using hashing*   
\n$\cdot$ /Q. Shi, H. Li, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'10), 2010/.
\n$\cdot$ [http://sites.google.com/site/chhshen/publication/cvpr10.pdf?attredirects=1  pdf][data/bibtex/Shi2010CVPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Rapid+face+recognition+using+hashing+Shi,+Qinfeng+and+Li,+Hanxi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Rapid+face+recognition+using+hashing semantic scholar]
. *Robust face recognition via accurate face alignment and sparse representation*   
\n$\cdot$ /H. Li, P. Wang, C. Shen/.
\n$\cdot$ /Proc. International Conference on on Digital Image Computing: Techniques and Applications (DICTA'10), 2010/.
\n$\cdot$ [data/bibtex/Face2010Li.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Robust+Face+Recognition+via+Accurate+Face+Alignment+and+Sparse+Representation+Li,+Hanxi+and+Wang,+Peng+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Robust+Face+Recognition+via+Accurate+Face+Alignment+and+Sparse+Representation semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Shen2010ECCVxxxarXiv.jpg">}}*LACBoost and FisherBoost: optimally building cascade classifiers*   
\n$\cdot$ /C. Shen, P. Wang, H. Li/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'10), 2010/.
\n$\cdot$ [http://arxiv.org/abs/1005.4103    arXiv][http://dx.doi.org/10.1007/978-3-642-15552-9_44  link][data/bibtex/Shen2010ECCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={LACBoost}+and+{FisherBoost}:+Optimally+Building+Cascade+Classifiers+Shen,+Chunhua+and+Wang,+Peng+and+Li,+Hanxi google scholar][https://www.semanticscholar.org/search?q={LACBoost}+and+{FisherBoost}:+Optimally+Building+Cascade+Classifiers semantic scholar]
. *Improved human detection and classification in thermal images*   
\n$\cdot$ /W. Wang, J. Zhang, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Image Processing (ICIP'10), 2010/.
\n$\cdot$ [data/bibtex/Human2010.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Improved+Human+Detection+and+Classification+in+Thermal+Images+Wang,+Weihong+and+Zhang,+Jian+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Improved+Human+Detection+and+Classification+in+Thermal+Images semantic scholar]
. *Training a multi-exit cascade with linear asymmetric classification for efficient object detection*   
\n$\cdot$ /P. Wang, C. Shen, H. Zheng, Z. Ren/.
\n$\cdot$ /Proc. IEEE International Conference on Image Processing (ICIP'10), 2010/.
\n$\cdot$ [data/bibtex/Multiexit2010Wang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Training+a+multi-exit+cascade+with+linear+asymmetric+classification+for+efficient+object+detection+Wang,+Peng+and+Shen,+Chunhua+and+Zheng,+Hong+and+Ren,+Zhang google scholar][https://www.semanticscholar.org/search?q=Training+a+multi-exit+cascade+with+linear+asymmetric+classification+for+efficient+object+detection semantic scholar]
. *Hippocampal shape classification using redundancy constrained feature selection*   
\n$\cdot$ /L. Zhou, L. Wang, C. Shen, N. Barnes/.
\n$\cdot$ /Proc. International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI'10), 2010/.
\n$\cdot$ [data/bibtex/Zhou2010MICCAI.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Hippocampal+shape+classification+using+redundancy+constrained+feature+selection+Zhou,+Luping+and+Wang,+Lei+and+Shen,+Chunhua+and+Barnes,+Nick google scholar][https://www.semanticscholar.org/search?q=Hippocampal+shape+classification+using+redundancy+constrained+feature+selection semantic scholar]
== Other
. *Proceedings of international conference on digital image computing: techniques and applications*   
\n$\cdot$ /J. Zhang, C. Shen, G. Geers, Q. Wu/.
\n$\cdot$   /Editors, IEEE, 2010/.
\n$\cdot$ [data/bibtex/DICTA2010.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Proceedings+of+International+Conference+on+Digital+Image+Computing:+Techniques+and+Applications+Zhang,+Jian+and+Shen,+Chunhua+and+Geers,+Glen+and+Wu,+Qiang google scholar][https://www.semanticscholar.org/search?q=Proceedings+of+International+Conference+on+Digital+Image+Computing:+Techniques+and+Applications semantic scholar]

= 2009
== Conference
. *A variant of the trace quotient formulation for dimensionality reduction*   
\n$\cdot$ /P. Wang, C. Shen, H. Zheng, Z. Ren/.
\n$\cdot$ /Proc. 9th Asian Conference on Computer Vision (ACCV'09), 2009/.
\n$\cdot$ [data/bibtex/Wang2009ACCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Variant+of+the+Trace+Quotient+Formulation+for+Dimensionality+Reduction+Wang,+Peng+and+Shen,+Chunhua+and+Zheng,+Hong+and+Ren,+Zhang google scholar][https://www.semanticscholar.org/search?q=A+Variant+of+the+Trace+Quotient+Formulation+for+Dimensionality+Reduction semantic scholar]
. *A scalable algorithm for learning a Mahalanobis distance metric*   
\n$\cdot$ /J. Kim, C. Shen, L. Wang/.
\n$\cdot$ /Proc. 9th Asian Conference on Computer Vision (ACCV'09), 2009/.
\n$\cdot$ [data/bibtex/Kim2009ACCV.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Scalable+Algorithm+for+Learning+a+{M}ahalanobis+Distance+Metric+Kim,+Junae+and+Shen,+Chunhua+and+Wang,+Lei google scholar][https://www.semanticscholar.org/search?q=A+Scalable+Algorithm+for+Learning+a+{M}ahalanobis+Distance+Metric semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Paisitkriangkrai2009CVPRxxxarXiv.jpg">}}*Efficiently training a better visual detector with sparse eigenvectors*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, J. Zhang/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'09), 2009/.
\n$\cdot$ [http://arxiv.org/abs/0903.3103    arXiv][http://sites.google.com/site/chhshen/publication/CVPR2009GSLDA.pdf?attredirects=1  link][data/bibtex/Paisitkriangkrai2009CVPR.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Efficiently+Training+a+Better+Visual+Detector+with+Sparse+Eigenvectors+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+Zhang,+Jian google scholar][https://www.semanticscholar.org/search?q=Efficiently+Training+a+Better+Visual+Detector+with+Sparse+Eigenvectors semantic scholar]
. *A two-layer night-time vehicle detector*   
\n$\cdot$ /W. Wang, C. Shen, J. Zhang, S. Paisitkriangkrai/.
\n$\cdot$ /Proc. International Conference on Digital Image Computing - Techniques and Applications (DICTA'09), 2009/.
\n$\cdot$ [data/bibtex/Wang2009DICTA.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Two-Layer+Night-time+Vehicle+Detector+Wang,+Weihong+and+Shen,+Chunhua+and+Zhang,+Jian+and+Paisitkriangkrai,+Sakrapee google scholar][https://www.semanticscholar.org/search?q=A+Two-Layer+Night-time+Vehicle+Detector semantic scholar]
. *Smooth approximation of $l_\infty$-norm for multi-view geometry*   
\n$\cdot$ /Y. Dai, H. Li, M. He, C. Shen/.
\n$\cdot$ /Proc. International Conference on Digital Image Computing - Techniques and Applications (DICTA'09), 2009/.
\n$\cdot$ [data/bibtex/Dai2009DICTA.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Smooth+Approximation+of+L_\infty-Norm+for+Multi-view+Geometry+Dai,+Yuchao+and+Li,+Hongdong+and+He,+Mingyi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Smooth+Approximation+of+L_\infty-Norm+for+Multi-view+Geometry semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Shen2009PSDxxxPDF.jpg">}}*Positive semidefinite metric learning with boosting*   
\n$\cdot$ /C. Shen, J. Kim, L. Wang, A. van den Hengel/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'09), 2009/.
\n$\cdot$ [http://arxiv.org/abs/0910.2279    arXiv][http://papers.NeurIPS.cc/paper/3658-positive-semidefinite-metric-learning-with-boosting.pdf  pdf][data/bibtex/Shen2009PSD.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Positive+semidefinite+metric+learning+with+Boosting+Shen,+Chunhua+and+Kim,+Junae+and+Wang,+Lei+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Positive+semidefinite+metric+learning+with+Boosting semantic scholar][https://code.google.com/archive/p/boosting/downloads   project webpage]

= 2008
== Journal
. *Performance evaluation of local features in human classification and detection*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, J. Zhang/.
\n$\cdot$ /IET Computer Vision (IETCV), 2008/.
\n$\cdot$ [http://dx.doi.org/10.1049/iet-cvi:20080026  link][http://sites.google.com/site/chhshen/publication/Huam2009IET.pdf  pdf][data/bibtex/Performance2008Paul.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Performance+Evaluation+of+Local+Features+in+Human+Classification+and+Detection+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+Zhang,+Jian google scholar][https://www.semanticscholar.org/search?q=Performance+Evaluation+of+Local+Features+in+Human+Classification+and+Detection semantic scholar]
        .. Invited submission, special issue of DICTA2007.
. *Supervised dimensionality reduction via sequential semidefinite programming*   
\n$\cdot$ /C. Shen, H. Li, M. Brooks/.
\n$\cdot$ /Pattern Recognition (PR), 2008/.
\n$\cdot$ [http://dx.doi.org/10.1016/j.patcog.2008.06.015  link][http://sites.google.com/site/chhshen/publication/PR1.pdf  pdf][data/bibtex/SDP2008Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Supervised+Dimensionality+Reduction+via+Sequential+Semidefinite+Programming+Shen,+Chunhua+and+Li,+Hongdong+and+Brooks,+Michael+J. google scholar][https://www.semanticscholar.org/search?q=Supervised+Dimensionality+Reduction+via+Sequential+Semidefinite+Programming semantic scholar]
. *Fast pedestrian detection using a cascade of boosted covariance features*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, J. Zhang/.
\n$\cdot$ /IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2008/.
\n$\cdot$ [http://dx.doi.org/10.1109/TCSVT.2008.928213  link][http://goo.gl/lgpDJB  pdf][data/bibtex/Human2008Paul.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fast+Pedestrian+Detection+Using+a+Cascade+of+Boosted+Covariance+Features+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+Zhang,+Jian google scholar][https://www.semanticscholar.org/search?q=Fast+Pedestrian+Detection+Using+a+Cascade+of+Boosted+Covariance+Features semantic scholar]
== Conference
. *Self-calibrating cameras using semidefinite programming*   
\n$\cdot$ /C. Shen, H. Li, M. Brooks/.
\n$\cdot$ /Proc. International Conference on Digital Image Computing - Techniques and Applications (DICTA'08), 2008/.
\n$\cdot$ [http://dx.doi.org/10.1109/DICTA.2008.46  link][data/bibtex/Shen2008Self.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Self-Calibrating+Cameras+Using+Semidefinite+Programming+Shen,+Chunhua+and+Li,+Hongdong+and+Brooks,+Michael+J. google scholar][https://www.semanticscholar.org/search?q=Self-Calibrating+Cameras+Using+Semidefinite+Programming semantic scholar]
. *Multi-view human motion capture with an improved deformation skin model*   
\n$\cdot$ /Y. Lu, L. Wang, R. Hartley, H. Li, C. Shen/.
\n$\cdot$ /Proc. International Conference on Digital Image Computing - Techniques and Applications (DICTA'08), 2008/.
\n$\cdot$ [data/bibtex/Lu2008Human.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Multi-view+Human+Motion+Capture+with+An+Improved+Deformation+Skin+Model+Lu,+Yifan+and+Wang,+Lei+and+Hartley,+Richard+and+Li,+Hongdong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Multi-view+Human+Motion+Capture+with+An+Improved+Deformation+Skin+Model semantic scholar]
. *Boosting the minimum margin: LPBoost vs. AdaBoost*   
\n$\cdot$ /H. Li, C. Shen/.
\n$\cdot$ /Proc. International Conference on Digital Image Computing - Techniques and Applications (DICTA'08), 2008/.
\n$\cdot$ [data/bibtex/Li2008Boosting.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Boosting+the+minimum+margin:+{LPBoost}+vs.+{AdaBoost}+Li,+Hanxi+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Boosting+the+minimum+margin:+{LPBoost}+vs.+{AdaBoost} semantic scholar]
. *Learning cascaded reduced-set SVMs using linear programming*   
\n$\cdot$ /J. Kim, C. Shen, L. Wang/.
\n$\cdot$ /Proc. International Conference on Digital Image Computing - Techniques and Applications (DICTA'08), 2008/.
\n$\cdot$ [data/bibtex/Junae2008SVM.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Learning+Cascaded+Reduced-set+{SVM}s+Using+Linear+Programming+Kim,+Junae+and+Shen,+Chunhua+and+Wang,+Lei google scholar][https://www.semanticscholar.org/search?q=Learning+Cascaded+Reduced-set+{SVM}s+Using+Linear+Programming semantic scholar]
. *A fast algorithm for creating a compact and discriminative visual codebook*   
\n$\cdot$ /L. Wang, L. Zhou, C. Shen/.
\n$\cdot$ /Proc. European Conference on Computer Vision (ECCV'08), 2008/.
\n$\cdot$ [http://dx.doi.org/10.1007/978-3-540-88693-8_53  link][http://sites.google.com/site/chhshen/publication/ECCV2008Wang.pdf?attredirects=1  pdf][data/bibtex/Fast2008Wang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+Fast+Algorithm+for+Creating+a+Compact+and+Discriminative+Visual+Codebook+Wang,+Lei+and+Zhou,+Luping+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=A+Fast+Algorithm+for+Creating+a+Compact+and+Discriminative+Visual+Codebook semantic scholar]
. *Face detection from few training examples*   
\n$\cdot$ /C. Shen, S. Paisitkriangkrai, J. Zhang/.
\n$\cdot$ /Proc. IEEE International Conference on Image Processing (ICIP'08), 2008/.
\n$\cdot$ [http://dx.doi.org/10.1109/ICIP.2008.4712367  link][data/bibtex/Face2008Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Face+Detection+From+Few+Training+Examples+Shen,+Chunhua+and+Paisitkriangkrai,+Sakrapee+and+Zhang,+Jian google scholar][https://www.semanticscholar.org/search?q=Face+Detection+From+Few+Training+Examples semantic scholar]
. {{<img class="imgP  right"   src="data/thumbnail/Shen2008PSDxxxPDF.jpg">}}*PSDBoost: matrix-generation linear programming for positive semidefinite matrices learning*   
\n$\cdot$ /C. Shen, A. Welsh, L. Wang/.
\n$\cdot$ /Proc. Advances in Neural Information Processing Systems (NeurIPS'08), 2008/.
\n$\cdot$ [http://papers.NeurIPS.cc/paper/3611-psdboost-matrix-generation-linear-programming-for-positive-semidefinite-matrices-learning.pdf  pdf][data/bibtex/Shen2008PSD.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={PSDB}oost:+Matrix-generation+linear+programming+for+positive+semidefinite+matrices+learning+Shen,+Chunhua+and+Welsh,+Alan+and+Wang,+Lei google scholar][https://www.semanticscholar.org/search?q={PSDB}oost:+Matrix-generation+linear+programming+for+positive+semidefinite+matrices+learning semantic scholar]
. *Real-time pedestrian detection using a boosted multi-layer classifier*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, J. Zhang/.
\n$\cdot$ /Proc. 8th IEEE International Workshop on Visual Surveillance, in conjunction with European Conference on Computer Vision (ECCVW'08), 2008/.
\n$\cdot$ [data/bibtex/Realtime2008Paisitkriangkrai.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Real-time+Pedestrian+Detection+Using+a+Boosted+Multi-layer+Classifier+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+Zhang,+Jian google scholar][https://www.semanticscholar.org/search?q=Real-time+Pedestrian+Detection+Using+a+Boosted+Multi-layer+Classifier semantic scholar]

= 2007
== Journal
. *Fast global kernel density mode seeking: applications to localization and tracking*   
\n$\cdot$ /C. Shen, M. Brooks, A. van den Hengel/.
\n$\cdot$ /IEEE Transactions on Image Processing (TIP), 2007/.
\n$\cdot$ [http://dx.doi.org/10.1109/TIP.2007.894233  link][http://sites.google.com/site/chhshen/publication/TIP2007Shen.pdf  pdf][data/bibtex/Fast2007Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fast+global+kernel+density+mode+seeking:+applications+to+localization+and+tracking+Shen,+Chunhua+and+Brooks,+Michael+J.+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Fast+global+kernel+density+mode+seeking:+applications+to+localization+and+tracking semantic scholar]
. *Adaptive object tracking based on an effective appearance filter*   
\n$\cdot$ /H. Wang, D. Suter, K. Schindler, C. Shen/.
\n$\cdot$ /IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2007/.
\n$\cdot$ [http://dx.doi.org/10.1109/TPAMI.2007.1112  link][http://goo.gl/6rQTA1  pdf][data/bibtex/Adaptive2007Wang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Adaptive+object+tracking+based+on+an+effective+appearance+filter+Wang,+Hanzi+and+Suter,+David+and+Schindler,+Konrad+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Adaptive+object+tracking+based+on+an+effective+appearance+filter semantic scholar]
        .. Featured article of September issue 2007.
== Conference
. *A convex programming approach to the trace quotient problem*   
\n$\cdot$ /C. Shen, H. Li, M. Brooks/.
\n$\cdot$ /Proc. 8th Asian Conference on Computer Vision (ACCV'07), 2007/.
\n$\cdot$ [http://dx.doi.org/10.1007/978-3-540-76390-1_23  link][data/bibtex/Convex2007Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=A+convex+programming+approach+to+the+trace+quotient+problem+Shen,+Chunhua+and+Li,+Hongdong+and+Brooks,+Michael+J. google scholar][https://www.semanticscholar.org/search?q=A+convex+programming+approach+to+the+trace+quotient+problem semantic scholar]
. *Kernel-based tracking from a probabilistic viewpoint*   
\n$\cdot$ /Q. Nguyen, A. Robles-Kelly, C. Shen/.
\n$\cdot$ /Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'07), 2007/.
\n$\cdot$ [http://dx.doi.org/10.1109/CVPR.2007.383240  link][http://goo.gl/1QNmaq  pdf][data/bibtex/Kernel2007Quang.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Kernel-based+tracking+from+a+probabilistic+viewpoint+Nguyen,+Quang+and+Robles-Kelly,+Antonio+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Kernel-based+tracking+from+a+probabilistic+viewpoint semantic scholar]
. *Feature extraction using sequential semidefinite programming*   
\n$\cdot$ /C. Shen, H. Li, M. Brooks/.
\n$\cdot$ /Proc. International Conference on Digital Image Computing - Techniques and Applications (DICTA'07), 2007/.
\n$\cdot$ [http://dx.doi.org/10.1109/DICTA.2007.4426829  link][data/bibtex/Feature2007Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Feature+extraction+using+sequential+semidefinite+programming+Shen,+Chunhua+and+Li,+Hongdong+and+Brooks,+Michael+J. google scholar][https://www.semanticscholar.org/search?q=Feature+extraction+using+sequential+semidefinite+programming semantic scholar]
. *An experimental evaluation of local features for pedestrian classification*   
\n$\cdot$ /S. Paisitkriangkrai, C. Shen, J. Zhang/.
\n$\cdot$ /Proc. International Conference on Digital Image Computing - Techniques and Applications (DICTA'07), 2007/.
\n$\cdot$ [http://dx.doi.org/10.1109/DICTA.2007.4426775  link][data/bibtex/Experimental2007Paul.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=An+Experimental+Evaluation+of+Local+Features+for+Pedestrian+Classification+Paisitkriangkrai,+Sakrapee+and+Shen,+Chunhua+and+Zhang,+Jian google scholar][https://www.semanticscholar.org/search?q=An+Experimental+Evaluation+of+Local+Features+for+Pedestrian+Classification semantic scholar]
        .. Best Paper Award.
. *Color image labelling using linear programming*   
\n$\cdot$ /H. Li, C. Shen, Z. Wen/.
\n$\cdot$ /Proc. International Conference on Digital Image Computing - Techniques and Applications (DICTA'07), 2007/.
\n$\cdot$ [http://dx.doi.org/10.1109/DICTA.2007.4426802  link][data/bibtex/Color2007Li.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Color+image+labelling+using+linear+programming+Li,+Hongdong+and+Shen,+Chunhua+and+Wen,+Zhiying google scholar][https://www.semanticscholar.org/search?q=Color+image+labelling+using+linear+programming semantic scholar]
. *Object-respecting colour image segmentation: an LP approach*   
\n$\cdot$ /H. Li, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Image Processing (ICIP'07), 2007/.
\n$\cdot$ [http://dx.doi.org/10.1109/ICIP.2007.4379141  link][data/bibtex/Object2007Li.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Object-respecting+colour+image+segmentation:+An+{LP}+approach+Li,+Hongdong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Object-respecting+colour+image+segmentation:+An+{LP}+approach semantic scholar]

= 2006
== Conference
. *Classification-based likelihood functions for Bayesian tracking*   
\n$\cdot$ /C. Shen, H. Li, M. Brooks/.
\n$\cdot$ /Proc. IEEE International Conference on Advanced Video and Signal based Surveillance (AVSS'06), 2006/.
\n$\cdot$ [http://dx.doi.org/10.1109/AVSS.2006.33  link][data/bibtex/Classification2006Shen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Classification-based+likelihood+functions+for+{B}ayesian+tracking+Shen,+Chunhua+and+Li,+Hongdong+and+Brooks,+Michael+J. google scholar][https://www.semanticscholar.org/search?q=Classification-based+likelihood+functions+for+{B}ayesian+tracking semantic scholar]
. *Enhanced kernel-based tracking for monochromatic and thermographic video*   
\n$\cdot$ /Q. Nguyen, A. Robles-Kelly, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Advanced Video and Signal based Surveillance (AVSS'06), 2006/.
\n$\cdot$ [http://dx.doi.org/10.1109/AVSS.2006.47  link][data/bibtex/Enhanced2006Nguyen.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Enhanced+kernel-based+tracking+for+monochromatic+and+thermographic+video+Nguyen,+Quang+and+Robles-Kelly,+Antonio+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=Enhanced+kernel-based+tracking+for+monochromatic+and+thermographic+video semantic scholar]
. *An LMI approach for reliable PTZ camera self-calibration*   
\n$\cdot$ /H. Li, C. Shen/.
\n$\cdot$ /Proc. IEEE International Conference on Advanced Video and Signal based Surveillance (AVSS'06), 2006/.
\n$\cdot$ [http://dx.doi.org/10.1109/AVSS.2006.21  link][data/bibtex/LMI2006Li.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=An+{LMI}+approach+for+reliable+{PTZ}+camera+self-calibration+Li,+Hongdong+and+Shen,+Chunhua google scholar][https://www.semanticscholar.org/search?q=An+{LMI}+approach+for+reliable+{PTZ}+camera+self-calibration semantic scholar]

= 2005
== Conference
. *Fast global kernel density mode seeking with application to localisation and tracking*   
\n$\cdot$ /C. Shen, M. Brooks, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE International Conference on Computer Vision (ICCV'05), 2005/.
\n$\cdot$ [http://dx.doi.org/10.1109/ICCV.2005.94  link][http://goo.gl/UHzjWW  pdf][data/bibtex/Shen2005Fast.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Fast+global+kernel+density+mode+seeking+with+application+to+localisation+and+tracking+Shen,+Chunhua+and+Brooks,+Michael+J.+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Fast+global+kernel+density+mode+seeking+with+application+to+localisation+and+tracking semantic scholar]
        .. Oral presentation, 45 out of 1200 submissions.
. *Visual tracking via efficient kernel discriminant subspace learning*   
\n$\cdot$ /C. Shen, A. van den Hengel, M. Brooks/.
\n$\cdot$ /Proc. IEEE International Conference on Image Processing (ICIP'05), 2005/.
\n$\cdot$ [http://dx.doi.org/10.1109/ICIP.2005.1530124  link][data/bibtex/Shen2005Visual.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Visual+tracking+via+efficient+kernel+discriminant+subspace+learning+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Brooks,+Michael+J. google scholar][https://www.semanticscholar.org/search?q=Visual+tracking+via+efficient+kernel+discriminant+subspace+learning semantic scholar]
. *Augmented particle filtering for efficient visual tracking*   
\n$\cdot$ /C. Shen, M. Brooks, A. van den Hengel/.
\n$\cdot$ /Proc. IEEE International Conference on Image Processing (ICIP'05), 2005/.
\n$\cdot$ [http://dx.doi.org/10.1109/ICIP.2005.1530527  link][data/bibtex/Shen2005Augmented.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Augmented+particle+filtering+for+efficient+visual+tracking+Shen,+Chunhua+and+Brooks,+Michael+J.+and+{van+den+Hengel},+Anton google scholar][https://www.semanticscholar.org/search?q=Augmented+particle+filtering+for+efficient+visual+tracking semantic scholar]
. *Adaptive over-relaxed mean shift*   
\n$\cdot$ /C. Shen, M. Brooks/.
\n$\cdot$ /Proc. 8th International Symposium on Signal Processing and Its Applications (ISSPA'05), 2005/.
\n$\cdot$ [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1581003  link][data/bibtex/Shen2005Adaptive.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Adaptive+over-relaxed+mean+shift+Shen,+Chunhua+and+Brooks,+Michael+J. google scholar][https://www.semanticscholar.org/search?q=Adaptive+over-relaxed+mean+shift semantic scholar]
        .. Errata: in figure 3 square marker and circle marker should be swapped.

= 2004
== Journal
. *Active control of radiation from a piston set in a rigid sphere*   
\n$\cdot$ /Z. Lin, J. Lu, C. Shen, X. Qiu, B. Xu/.
\n$\cdot$ /Journal of Acoustical Society of America (JASA), 2004/.
\n$\cdot$ [http://dx.doi.org/10.1121/1.1736654  link][http://goo.gl/nc4SjU  pdf][data/bibtex/Lin2004Active.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Active+control+of+radiation+from+a+piston+set+in+a+rigid+sphere+Lin,+Zhibin+and+Lu,+Jing+and+Shen,+Chunhua+and+Qiu,+Xiaojun+and+Xu,+Boling google scholar][https://www.semanticscholar.org/search?q=Active+control+of+radiation+from+a+piston+set+in+a+rigid+sphere semantic scholar]
== Conference
. *Enhanced importance sampling: unscented auxiliary particle filtering for visual tracking*   
\n$\cdot$ /C. Shen, A. van den Hengel, A. Dick, M. Brooks/.
\n$\cdot$ /Proc. Australian Joint Conference on Artificial Intelligence (AI'04), 2004/.
\n$\cdot$ [http://digital.library.adelaide.edu.au/dspace/handle/2440/29538  link][data/bibtex/Shen2004Enhanced.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Enhanced+importance+sampling:+unscented+auxiliary+particle+filtering+for+visual+tracking+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Dick,+Anthony+and+Brooks,+Michael+J. google scholar][https://www.semanticscholar.org/search?q=Enhanced+importance+sampling:+unscented+auxiliary+particle+filtering+for+visual+tracking semantic scholar]
. *2D articulated tracking with dynamic Bayesian networks*   
\n$\cdot$ /C. Shen, A. van den Hengel, A. Dick, M. Brooks/.
\n$\cdot$ /Proc. International Conference on Computer and Information Technology (CIT'04), 2004/.
\n$\cdot$ [http://dx.doi.org/10.1109/CIT.2004.1357185  link][data/bibtex/Shen2004Articulated.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q={2D}+articulated+tracking+with+dynamic+{B}ayesian+networks+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Dick,+Anthony+and+Brooks,+Michael+J. google scholar][https://www.semanticscholar.org/search?q={2D}+articulated+tracking+with+dynamic+{B}ayesian+networks semantic scholar]

= 2003
== Journal
. *Lattice form adaptive infinite impulse response filtering algorithm for active noise control*   
\n$\cdot$ /J. Lu, C. Shen, X. Qiu, B. Xu/.
\n$\cdot$ /Journal of Acoustical Society of America (JASA), 2003/.
\n$\cdot$ [http://dx.doi.org/10.1121/1.1529665  link][http://sites.google.com/site/chhshen/publication/Lattice2003JASA.pdf?attredirects=1  pdf][data/bibtex/Lu2003Lattice.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Lattice+form+adaptive+infinite+impulse+response+filtering+algorithm+for+active+noise+control+Lu,+Jing+and+Shen,+Chunhua+and+Qiu,+Xiaojun+and+Xu,+Boling google scholar][https://www.semanticscholar.org/search?q=Lattice+form+adaptive+infinite+impulse+response+filtering+algorithm+for+active+noise+control semantic scholar]
== Conference
. *Probabilistic multiple cue integration for particle filter based tracking*   
\n$\cdot$ /C. Shen, A. van den Hengel, A. Dick/.
\n$\cdot$ /Proc. International Conference on Digital Image Computing - Techniques and Applications (DICTA'03), 2003/.
\n$\cdot$ [http://sites.google.com/site/chhshen/publication/DICTA2003.pdf?attredirects=1  pdf][data/bibtex/Shen2003Probabilistic.bib    bibtex][https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Probabilistic+multiple+cue+integration+for+particle+filter+based+tracking+Shen,+Chunhua+and+{van+den+Hengel},+Anton+and+Dick,+Anthony google scholar][https://www.semanticscholar.org/search?q=Probabilistic+multiple+cue+integration+for+particle+filter+based+tracking semantic scholar]
        .. Nominated for Best Student Paper Award.
